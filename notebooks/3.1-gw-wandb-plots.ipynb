{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load wandb metrics and create nicer plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import dotenv\n",
    "import molfeat\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.utils import instantiate\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "\n",
    "import wandb\n",
    "from src import utils\n",
    "from src.models.jump_cl import BasicJUMPModule\n",
    "from src.utils import instantiate_evaluator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounting cpjump1...\n",
      "Mounting cpjump2...\n",
      "Mounting cpjump3...\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    if not Path(f\"../cpjump{i}/jump/\").exists():\n",
    "        print(f\"Mounting cpjump{i}...\")\n",
    "        os.system(f\"sshfs bioclust:/projects/cpjump{i}/ ../cpjump{i}\")\n",
    "    else:\n",
    "        print(f\"cpjump{i} already mounted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = \"2023-08-17_13-32-50/0\"\n",
    "epoch = 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_str = \"../cpjump1/jump/logs/train/multiruns/{run}/checkpoints/epoch_{epoch:0>3}.ckpt\"\n",
    "\n",
    "run_dict = {\n",
    "    \"small1\": (run := \"2023-08-16_11-59-26/0\", \"small_jump_cl\", epoch := 43, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"small\": (run := \"2023-08-17_13-32-50/0\", \"small_jump_cl\", epoch := 41, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"med\": (run := \"2023-08-07_11-55-54\", \"med_jump_cl\", epoch := 5, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"big\": (run := \"2023-08-01_11-37-40\", \"big_jump_cl\", epoch := 1, ckpt_str.format(run=run, epoch=epoch)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, experiment, epoch, ckpt = run_dict[\"small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- experiment=small_jump_cl\n",
      "- trainer.devices=[0,2]\n",
      "- data.num_workers=16\n",
      "- data.prefetch_factor=2\n",
      "- model/criterion=frozen_contrastive.yaml\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"cat ../cpjump1/jump/logs/train/multiruns/{run}/.hydra/overrides.yaml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last.ckpt', 'epoch_041.ckpt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f\"../cpjump1/jump/logs/train/multiruns/{run}/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=\"../configs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, experiment, epoch, ckpt = run_dict[\"small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- small_jump_cl\n",
      "- fingerprints\n",
      "- clip_like\n",
      "- ${model.image_encoder.instance_model_name}\n",
      "train: true\n",
      "test: true\n",
      "evaluate: true\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "data:\n",
      "  compound_transform:\n",
      "    _target_: src.modules.compound_transforms.fp_transform.FPTransform\n",
      "    fps:\n",
      "    - maccs\n",
      "    - ecfp\n",
      "    compound_str_type: inchi\n",
      "    params:\n",
      "      ecfp:\n",
      "        radius: 2\n",
      "  _target_: src.models.jump_cl.datamodule.BasicJUMPDataModule\n",
      "  batch_size: 4\n",
      "  num_workers: 24\n",
      "  pin_memory: null\n",
      "  prefetch_factor: 3\n",
      "  drop_last: true\n",
      "  transform:\n",
      "    _target_: src.modules.transforms.DefaultJUMPTransform\n",
      "    _convert_: object\n",
      "    size: 128\n",
      "    dim:\n",
      "    - -2\n",
      "    - -1\n",
      "  force_split: false\n",
      "  splitter:\n",
      "    _target_: src.splitters.ScaffoldSplitter\n",
      "    train: 800\n",
      "    test: 200\n",
      "    val: 100\n",
      "    retrieval: 0\n",
      "  use_compond_cache: false\n",
      "  data_root_dir: ${paths.projects_dir}/\n",
      "  split_path: ${paths.split_path}/fp_small/\n",
      "  dataloader_config:\n",
      "    train:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: true\n",
      "    val:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "    test:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "  image_metadata_path: ${paths.metadata_path}/images_metadata.parquet\n",
      "  compound_metadata_path: ${paths.metadata_path}/compound_dict.json\n",
      "  compound_col: Metadata_InChI\n",
      "  image_sampler: null\n",
      "  metadata_dir: ${paths.raw_metadata_path}/complete_metadata.csv\n",
      "  local_load_data_dir: ${paths.load_data_path}/final/\n",
      "  index_str: '{Metadata_Source}__{Metadata_Batch}__{Metadata_Plate}__{Metadata_Well}__{Metadata_Site}'\n",
      "  channels:\n",
      "  - DNA\n",
      "  - AGP\n",
      "  - ER\n",
      "  - Mito\n",
      "  - RNA\n",
      "  col_fstring: FileName_Orig{channel}\n",
      "  id_cols:\n",
      "  - Metadata_Source\n",
      "  - Metadata_Batch\n",
      "  - Metadata_Plate\n",
      "  - Metadata_Well\n",
      "  extra_cols:\n",
      "  - Metadata_PlateType\n",
      "  - Metadata_Site\n",
      "model:\n",
      "  image_encoder:\n",
      "    _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "    instance_model_name: resnet18\n",
      "    target_num: ${model.embedding_dim}\n",
      "    n_channels: 5\n",
      "    pretrained: true\n",
      "  molecule_encoder:\n",
      "    _target_: src.modules.molecules.fp_mlp.FingerprintsWithMLP\n",
      "    input_dim: 2167\n",
      "    out_dim: ${model.embedding_dim}\n",
      "    embedding_dim:\n",
      "    - 1024\n",
      "    - 768\n",
      "    - 512\n",
      "    - 512\n",
      "    activation_layer:\n",
      "      _target_: torch.nn.ReLU\n",
      "      _partial_: true\n",
      "    norm_layer:\n",
      "      _target_: torch.nn.BatchNorm1d\n",
      "      _partial_: true\n",
      "    dropout: 0.2\n",
      "  criterion:\n",
      "    _target_: src.modules.losses.contrastive_loss_with_temperature.ContrastiveLossWithTemperature\n",
      "    logit_scale: 2.3\n",
      "    logit_scale_min: 0\n",
      "    logit_scale_max: 4.605170185988092\n",
      "    requires_grad: true\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 0.001\n",
      "    amsgrad: false\n",
      "    lr: ${model.lr}\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "    _partial_: true\n",
      "    T_0: 15\n",
      "    T_mult: 2\n",
      "    eta_min: 0\n",
      "    last_epoch: -1\n",
      "  _target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "  embedding_dim: 256\n",
      "  lr: 0.01\n",
      "  batch_size: ${data.batch_size}\n",
      "  example_input_path: null\n",
      "  monitor: val/loss\n",
      "  interval: epoch\n",
      "  frequency: 1\n",
      "  image_backbone: backbone\n",
      "  image_head: projection_head\n",
      "  molecule_backbone: null\n",
      "  molecule_head: null\n",
      "callbacks:\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 2\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0\n",
      "    patience: 10\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  timer:\n",
      "    _target_: lightning.pytorch.callbacks.Timer\n",
      "    duration: 00:06:00:00\n",
      "    interval: epoch\n",
      "    verbose: true\n",
      "  wandb_watcher:\n",
      "    _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "    watch: true\n",
      "    watch_log: all\n",
      "    log_freq: 100\n",
      "    log_graph: false\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "logger:\n",
      "  csv:\n",
      "    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    name: csv/\n",
      "    prefix: ''\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    log_graph: false\n",
      "    default_hp_metric: true\n",
      "    prefix: ''\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: fp_small\n",
      "    log_model: true\n",
      "    prefix: ''\n",
      "    group: null\n",
      "    tags: ${tags}\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 0\n",
      "  max_epochs: 50\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 2\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 1\n",
      "  num_sanity_val_steps: 2\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  projects_dir: ..\n",
      "  data_root_dir: ${paths.projects_dir}/cpjump1\n",
      "  metadata_path: ${paths.data_root_dir}/jump/models/metadata\n",
      "  raw_metadata_path: ${paths.data_root_dir}/jump/metadata\n",
      "  load_data_path: ${paths.data_root_dir}/jump/load_data\n",
      "  split_path: ${paths.data_root_dir}/jump/models/splits\n",
      "  log_dir: ${paths.data_root_dir}/jump/logs\n",
      "  output_dir: ../cpjump1/jump/logs/train/multiruns/2023-08-17_13-32-50/0\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  style: dim\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "eval:\n",
      "  idr_graph_retrieval:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/retrieval/idr/\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.retrieval.evaluator.IDRRetrievalEvaluator\n",
      "      name: IDRRetrieval\n",
      "      visualize_kwargs: null\n",
      "    callbacks: null\n",
      "    model:\n",
      "      _target_: src.eval.retrieval.module.IDRRetrievalModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    datamodule:\n",
      "      _target_: src.eval.retrieval.datamodule.IDRRetrievalDataModule\n",
      "      selected_compounds_path: ${paths.data_root_dir}/excape-db/selected_compounds.csv\n",
      "      image_metadata_path: ${paths.data_root_dir}/idr0033-rohban-pathways/processed_metadata.csv\n",
      "      data_root_dir: ${paths.data_root_dir}/screen_1751\n",
      "      image_batch_size: 256\n",
      "      compound_batch_size: 16\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 3\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      transform: ${data.transform}\n",
      "      compound_gene_col: Gene_Symbol\n",
      "      image_gene_col: Gene Symbol\n",
      "      col_fstring: FileName_{channel}\n",
      "      channels: null\n",
      "      target_col: Activity_Flag\n",
      "      smiles_col: SMILES\n",
      "      use_cache: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(\n",
    "    config_name=\"train.yaml\",\n",
    "    overrides=[\n",
    "        \"evaluate=true\",\n",
    "        \"eval=retrieval\",\n",
    "        \"paths.projects_dir=..\",\n",
    "        f\"paths.output_dir=../cpjump1/jump/logs/train/multiruns/{run}\",\n",
    "        \"experiment=fp_small\",\n",
    "        \"data.batch_size=4\",\n",
    "        # \"model/molecule_encoder=gin_masking.yaml\",\n",
    "        \"trainer.devices=1\",\n",
    "        # \"eval.moa_image_task.datamodule.data_root_dir=../\",\n",
    "    ],\n",
    ")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "dm = instantiate(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoleculeImageDataset(n_compounds=100, n_images=2860)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "dl = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model[\"_target_\"] += \".load_from_checkpoint\"\n",
    "with open_dict(cfg.model):\n",
    "    cfg.model[\"checkpoint_path\"] = ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'lightning.pytorch.core.module.LightningModule.load_from_checkpoint':\nRuntimeError('Error(s) in loading state_dict for BasicJUMPModule:\\n\\tMissing key(s) in state_dict: \"molecule_encoder.backbone.0.0.weight\", \"molecule_encoder.backbone.0.0.bias\", \"molecule_encoder.backbone.0.1.weight\", \"molecule_encoder.backbone.0.1.bias\", \"molecule_encoder.backbone.0.1.running_mean\", \"molecule_encoder.backbone.0.1.running_var\", \"molecule_encoder.backbone.1.0.weight\", \"molecule_encoder.backbone.1.0.bias\", \"molecule_encoder.backbone.1.1.weight\", \"molecule_encoder.backbone.1.1.bias\", \"molecule_encoder.backbone.1.1.running_mean\", \"molecule_encoder.backbone.1.1.running_var\", \"molecule_encoder.backbone.2.0.weight\", \"molecule_encoder.backbone.2.0.bias\", \"molecule_encoder.backbone.2.1.weight\", \"molecule_encoder.backbone.2.1.bias\", \"molecule_encoder.backbone.2.1.running_mean\", \"molecule_encoder.backbone.2.1.running_var\", \"molecule_encoder.backbone.3.0.weight\", \"molecule_encoder.backbone.3.0.bias\", \"molecule_encoder.backbone.3.1.weight\", \"molecule_encoder.backbone.3.1.bias\", \"molecule_encoder.backbone.3.1.running_mean\", \"molecule_encoder.backbone.3.1.running_var\", \"molecule_encoder.backbone.4.0.weight\", \"molecule_encoder.backbone.4.0.bias\". \\n\\tUnexpected key(s) in state_dict: \"molecule_backbone.node_embeddings.0.weight\", \"molecule_backbone.node_embeddings.1.weight\", \"molecule_backbone.gnn_layers.0.mlp.0.weight\", \"molecule_backbone.gnn_layers.0.mlp.0.bias\", \"molecule_backbone.gnn_layers.0.mlp.2.weight\", \"molecule_backbone.gnn_layers.0.mlp.2.bias\", \"molecule_backbone.gnn_layers.0.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.0.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.0.bn.weight\", \"molecule_backbone.gnn_layers.0.bn.bias\", \"molecule_backbone.gnn_layers.0.bn.running_mean\", \"molecule_backbone.gnn_layers.0.bn.running_var\", \"molecule_backbone.gnn_layers.0.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.1.mlp.0.weight\", \"molecule_backbone.gnn_layers.1.mlp.0.bias\", \"molecule_backbone.gnn_layers.1.mlp.2.weight\", \"molecule_backbone.gnn_layers.1.mlp.2.bias\", \"molecule_backbone.gnn_layers.1.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.1.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.1.bn.weight\", \"molecule_backbone.gnn_layers.1.bn.bias\", \"molecule_backbone.gnn_layers.1.bn.running_mean\", \"molecule_backbone.gnn_layers.1.bn.running_var\", \"molecule_backbone.gnn_layers.1.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.2.mlp.0.weight\", \"molecule_backbone.gnn_layers.2.mlp.0.bias\", \"molecule_backbone.gnn_layers.2.mlp.2.weight\", \"molecule_backbone.gnn_layers.2.mlp.2.bias\", \"molecule_backbone.gnn_layers.2.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.2.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.2.bn.weight\", \"molecule_backbone.gnn_layers.2.bn.bias\", \"molecule_backbone.gnn_layers.2.bn.running_mean\", \"molecule_backbone.gnn_layers.2.bn.running_var\", \"molecule_backbone.gnn_layers.2.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.3.mlp.0.weight\", \"molecule_backbone.gnn_layers.3.mlp.0.bias\", \"molecule_backbone.gnn_layers.3.mlp.2.weight\", \"molecule_backbone.gnn_layers.3.mlp.2.bias\", \"molecule_backbone.gnn_layers.3.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.3.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.3.bn.weight\", \"molecule_backbone.gnn_layers.3.bn.bias\", \"molecule_backbone.gnn_layers.3.bn.running_mean\", \"molecule_backbone.gnn_layers.3.bn.running_var\", \"molecule_backbone.gnn_layers.3.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.4.mlp.0.weight\", \"molecule_backbone.gnn_layers.4.mlp.0.bias\", \"molecule_backbone.gnn_layers.4.mlp.2.weight\", \"molecule_backbone.gnn_layers.4.mlp.2.bias\", \"molecule_backbone.gnn_layers.4.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.4.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.4.bn.weight\", \"molecule_backbone.gnn_layers.4.bn.bias\", \"molecule_backbone.gnn_layers.4.bn.running_mean\", \"molecule_backbone.gnn_layers.4.bn.running_var\", \"molecule_backbone.gnn_layers.4.bn.num_batches_tracked\", \"molecule_head.weight\", \"molecule_head.bias\", \"molecule_encoder.projection_head.weight\", \"molecule_encoder.projection_head.bias\", \"molecule_encoder.backbone.node_embeddings.0.weight\", \"molecule_encoder.backbone.node_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.0.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.0.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.0.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.0.bn.weight\", \"molecule_encoder.backbone.gnn_layers.0.bn.bias\", \"molecule_encoder.backbone.gnn_layers.0.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.0.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.0.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.1.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.1.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.1.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.1.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.1.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.1.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.1.bn.weight\", \"molecule_encoder.backbone.gnn_layers.1.bn.bias\", \"molecule_encoder.backbone.gnn_layers.1.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.1.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.1.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.2.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.2.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.2.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.2.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.2.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.2.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.2.bn.weight\", \"molecule_encoder.backbone.gnn_layers.2.bn.bias\", \"molecule_encoder.backbone.gnn_layers.2.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.2.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.2.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.3.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.3.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.3.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.3.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.3.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.3.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.3.bn.weight\", \"molecule_encoder.backbone.gnn_layers.3.bn.bias\", \"molecule_encoder.backbone.gnn_layers.3.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.3.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.3.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.4.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.4.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.4.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.4.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.4.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.4.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.4.bn.weight\", \"molecule_encoder.backbone.gnn_layers.4.bn.bias\", \"molecule_encoder.backbone.gnn_layers.4.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.4.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.4.bn.num_batches_tracked\". \\n\\tsize mismatch for image_encoder.projection_head.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\\n\\tsize mismatch for image_encoder.projection_head.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for image_head.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\\n\\tsize mismatch for image_head.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).')\nfull_key: model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m _target_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/core/module.py:1537\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m \u001b[39mPrimary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m \u001b[39mit stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1535\u001b[0m \u001b[39m    y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1537\u001b[0m loaded \u001b[39m=\u001b[39m _load_from_checkpoint(\n\u001b[1;32m   1538\u001b[0m     \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m   1539\u001b[0m     checkpoint_path,\n\u001b[1;32m   1540\u001b[0m     map_location,\n\u001b[1;32m   1541\u001b[0m     hparams_file,\n\u001b[1;32m   1542\u001b[0m     strict,\n\u001b[1;32m   1543\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1544\u001b[0m )\n\u001b[1;32m   1545\u001b[0m \u001b[39mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, pl\u001b[39m.\u001b[39mLightningModule):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[39m=\u001b[39m _load_state(\u001b[39mcls\u001b[39;49m, checkpoint, strict\u001b[39m=\u001b[39;49mstrict, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     92\u001b[0m     state_dict \u001b[39m=\u001b[39m checkpoint[\u001b[39m\"\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/core/saving.py:157\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39massert\u001b[39;00m strict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m keys \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49mload_state_dict(checkpoint[\u001b[39m\"\u001b[39;49m\u001b[39mstate_dict\u001b[39;49m\u001b[39m\"\u001b[39;49m], strict\u001b[39m=\u001b[39;49mstrict)\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m strict:\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for BasicJUMPModule:\n\tMissing key(s) in state_dict: \"molecule_encoder.backbone.0.0.weight\", \"molecule_encoder.backbone.0.0.bias\", \"molecule_encoder.backbone.0.1.weight\", \"molecule_encoder.backbone.0.1.bias\", \"molecule_encoder.backbone.0.1.running_mean\", \"molecule_encoder.backbone.0.1.running_var\", \"molecule_encoder.backbone.1.0.weight\", \"molecule_encoder.backbone.1.0.bias\", \"molecule_encoder.backbone.1.1.weight\", \"molecule_encoder.backbone.1.1.bias\", \"molecule_encoder.backbone.1.1.running_mean\", \"molecule_encoder.backbone.1.1.running_var\", \"molecule_encoder.backbone.2.0.weight\", \"molecule_encoder.backbone.2.0.bias\", \"molecule_encoder.backbone.2.1.weight\", \"molecule_encoder.backbone.2.1.bias\", \"molecule_encoder.backbone.2.1.running_mean\", \"molecule_encoder.backbone.2.1.running_var\", \"molecule_encoder.backbone.3.0.weight\", \"molecule_encoder.backbone.3.0.bias\", \"molecule_encoder.backbone.3.1.weight\", \"molecule_encoder.backbone.3.1.bias\", \"molecule_encoder.backbone.3.1.running_mean\", \"molecule_encoder.backbone.3.1.running_var\", \"molecule_encoder.backbone.4.0.weight\", \"molecule_encoder.backbone.4.0.bias\". \n\tUnexpected key(s) in state_dict: \"molecule_backbone.node_embeddings.0.weight\", \"molecule_backbone.node_embeddings.1.weight\", \"molecule_backbone.gnn_layers.0.mlp.0.weight\", \"molecule_backbone.gnn_layers.0.mlp.0.bias\", \"molecule_backbone.gnn_layers.0.mlp.2.weight\", \"molecule_backbone.gnn_layers.0.mlp.2.bias\", \"molecule_backbone.gnn_layers.0.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.0.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.0.bn.weight\", \"molecule_backbone.gnn_layers.0.bn.bias\", \"molecule_backbone.gnn_layers.0.bn.running_mean\", \"molecule_backbone.gnn_layers.0.bn.running_var\", \"molecule_backbone.gnn_layers.0.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.1.mlp.0.weight\", \"molecule_backbone.gnn_layers.1.mlp.0.bias\", \"molecule_backbone.gnn_layers.1.mlp.2.weight\", \"molecule_backbone.gnn_layers.1.mlp.2.bias\", \"molecule_backbone.gnn_layers.1.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.1.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.1.bn.weight\", \"molecule_backbone.gnn_layers.1.bn.bias\", \"molecule_backbone.gnn_layers.1.bn.running_mean\", \"molecule_backbone.gnn_layers.1.bn.running_var\", \"molecule_backbone.gnn_layers.1.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.2.mlp.0.weight\", \"molecule_backbone.gnn_layers.2.mlp.0.bias\", \"molecule_backbone.gnn_layers.2.mlp.2.weight\", \"molecule_backbone.gnn_layers.2.mlp.2.bias\", \"molecule_backbone.gnn_layers.2.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.2.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.2.bn.weight\", \"molecule_backbone.gnn_layers.2.bn.bias\", \"molecule_backbone.gnn_layers.2.bn.running_mean\", \"molecule_backbone.gnn_layers.2.bn.running_var\", \"molecule_backbone.gnn_layers.2.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.3.mlp.0.weight\", \"molecule_backbone.gnn_layers.3.mlp.0.bias\", \"molecule_backbone.gnn_layers.3.mlp.2.weight\", \"molecule_backbone.gnn_layers.3.mlp.2.bias\", \"molecule_backbone.gnn_layers.3.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.3.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.3.bn.weight\", \"molecule_backbone.gnn_layers.3.bn.bias\", \"molecule_backbone.gnn_layers.3.bn.running_mean\", \"molecule_backbone.gnn_layers.3.bn.running_var\", \"molecule_backbone.gnn_layers.3.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.4.mlp.0.weight\", \"molecule_backbone.gnn_layers.4.mlp.0.bias\", \"molecule_backbone.gnn_layers.4.mlp.2.weight\", \"molecule_backbone.gnn_layers.4.mlp.2.bias\", \"molecule_backbone.gnn_layers.4.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.4.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.4.bn.weight\", \"molecule_backbone.gnn_layers.4.bn.bias\", \"molecule_backbone.gnn_layers.4.bn.running_mean\", \"molecule_backbone.gnn_layers.4.bn.running_var\", \"molecule_backbone.gnn_layers.4.bn.num_batches_tracked\", \"molecule_head.weight\", \"molecule_head.bias\", \"molecule_encoder.projection_head.weight\", \"molecule_encoder.projection_head.bias\", \"molecule_encoder.backbone.node_embeddings.0.weight\", \"molecule_encoder.backbone.node_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.0.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.0.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.0.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.0.bn.weight\", \"molecule_encoder.backbone.gnn_layers.0.bn.bias\", \"molecule_encoder.backbone.gnn_layers.0.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.0.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.0.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.1.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.1.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.1.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.1.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.1.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.1.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.1.bn.weight\", \"molecule_encoder.backbone.gnn_layers.1.bn.bias\", \"molecule_encoder.backbone.gnn_layers.1.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.1.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.1.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.2.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.2.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.2.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.2.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.2.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.2.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.2.bn.weight\", \"molecule_encoder.backbone.gnn_layers.2.bn.bias\", \"molecule_encoder.backbone.gnn_layers.2.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.2.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.2.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.3.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.3.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.3.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.3.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.3.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.3.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.3.bn.weight\", \"molecule_encoder.backbone.gnn_layers.3.bn.bias\", \"molecule_encoder.backbone.gnn_layers.3.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.3.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.3.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.4.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.4.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.4.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.4.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.4.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.4.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.4.bn.weight\", \"molecule_encoder.backbone.gnn_layers.4.bn.bias\", \"molecule_encoder.backbone.gnn_layers.4.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.4.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.4.bn.num_batches_tracked\". \n\tsize mismatch for image_encoder.projection_head.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for image_encoder.projection_head.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\n\tsize mismatch for image_head.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\n\tsize mismatch for image_head.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m instantiate(cfg\u001b[39m.\u001b[39;49mmodel)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mCONVERT, ConvertMode\u001b[39m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mPARTIAL, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m instantiate_node(\n\u001b[1;32m    227\u001b[0m         config, \u001b[39m*\u001b[39;49margs, recursive\u001b[39m=\u001b[39;49m_recursive_, convert\u001b[39m=\u001b[39;49m_convert_, partial\u001b[39m=\u001b[39;49m_partial_\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m \u001b[39melif\u001b[39;00m OmegaConf\u001b[39m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[39m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[39m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[39m=\u001b[39mconvert, recursive\u001b[39m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[39m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mreturn\u001b[39;00m _call_target(_target_, partial, args, kwargs, full_key)\n\u001b[1;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[39m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m convert \u001b[39m==\u001b[39m ConvertMode\u001b[39m.\u001b[39mALL \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[39min\u001b[39;00m (ConvertMode\u001b[39m.\u001b[39mPARTIAL, ConvertMode\u001b[39m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[39mand\u001b[39;00m node\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mobject_type \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mfull_key: \u001b[39m\u001b[39m{\u001b[39;00mfull_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[39mraise\u001b[39;00m InstantiationException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'lightning.pytorch.core.module.LightningModule.load_from_checkpoint':\nRuntimeError('Error(s) in loading state_dict for BasicJUMPModule:\\n\\tMissing key(s) in state_dict: \"molecule_encoder.backbone.0.0.weight\", \"molecule_encoder.backbone.0.0.bias\", \"molecule_encoder.backbone.0.1.weight\", \"molecule_encoder.backbone.0.1.bias\", \"molecule_encoder.backbone.0.1.running_mean\", \"molecule_encoder.backbone.0.1.running_var\", \"molecule_encoder.backbone.1.0.weight\", \"molecule_encoder.backbone.1.0.bias\", \"molecule_encoder.backbone.1.1.weight\", \"molecule_encoder.backbone.1.1.bias\", \"molecule_encoder.backbone.1.1.running_mean\", \"molecule_encoder.backbone.1.1.running_var\", \"molecule_encoder.backbone.2.0.weight\", \"molecule_encoder.backbone.2.0.bias\", \"molecule_encoder.backbone.2.1.weight\", \"molecule_encoder.backbone.2.1.bias\", \"molecule_encoder.backbone.2.1.running_mean\", \"molecule_encoder.backbone.2.1.running_var\", \"molecule_encoder.backbone.3.0.weight\", \"molecule_encoder.backbone.3.0.bias\", \"molecule_encoder.backbone.3.1.weight\", \"molecule_encoder.backbone.3.1.bias\", \"molecule_encoder.backbone.3.1.running_mean\", \"molecule_encoder.backbone.3.1.running_var\", \"molecule_encoder.backbone.4.0.weight\", \"molecule_encoder.backbone.4.0.bias\". \\n\\tUnexpected key(s) in state_dict: \"molecule_backbone.node_embeddings.0.weight\", \"molecule_backbone.node_embeddings.1.weight\", \"molecule_backbone.gnn_layers.0.mlp.0.weight\", \"molecule_backbone.gnn_layers.0.mlp.0.bias\", \"molecule_backbone.gnn_layers.0.mlp.2.weight\", \"molecule_backbone.gnn_layers.0.mlp.2.bias\", \"molecule_backbone.gnn_layers.0.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.0.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.0.bn.weight\", \"molecule_backbone.gnn_layers.0.bn.bias\", \"molecule_backbone.gnn_layers.0.bn.running_mean\", \"molecule_backbone.gnn_layers.0.bn.running_var\", \"molecule_backbone.gnn_layers.0.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.1.mlp.0.weight\", \"molecule_backbone.gnn_layers.1.mlp.0.bias\", \"molecule_backbone.gnn_layers.1.mlp.2.weight\", \"molecule_backbone.gnn_layers.1.mlp.2.bias\", \"molecule_backbone.gnn_layers.1.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.1.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.1.bn.weight\", \"molecule_backbone.gnn_layers.1.bn.bias\", \"molecule_backbone.gnn_layers.1.bn.running_mean\", \"molecule_backbone.gnn_layers.1.bn.running_var\", \"molecule_backbone.gnn_layers.1.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.2.mlp.0.weight\", \"molecule_backbone.gnn_layers.2.mlp.0.bias\", \"molecule_backbone.gnn_layers.2.mlp.2.weight\", \"molecule_backbone.gnn_layers.2.mlp.2.bias\", \"molecule_backbone.gnn_layers.2.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.2.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.2.bn.weight\", \"molecule_backbone.gnn_layers.2.bn.bias\", \"molecule_backbone.gnn_layers.2.bn.running_mean\", \"molecule_backbone.gnn_layers.2.bn.running_var\", \"molecule_backbone.gnn_layers.2.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.3.mlp.0.weight\", \"molecule_backbone.gnn_layers.3.mlp.0.bias\", \"molecule_backbone.gnn_layers.3.mlp.2.weight\", \"molecule_backbone.gnn_layers.3.mlp.2.bias\", \"molecule_backbone.gnn_layers.3.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.3.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.3.bn.weight\", \"molecule_backbone.gnn_layers.3.bn.bias\", \"molecule_backbone.gnn_layers.3.bn.running_mean\", \"molecule_backbone.gnn_layers.3.bn.running_var\", \"molecule_backbone.gnn_layers.3.bn.num_batches_tracked\", \"molecule_backbone.gnn_layers.4.mlp.0.weight\", \"molecule_backbone.gnn_layers.4.mlp.0.bias\", \"molecule_backbone.gnn_layers.4.mlp.2.weight\", \"molecule_backbone.gnn_layers.4.mlp.2.bias\", \"molecule_backbone.gnn_layers.4.edge_embeddings.0.weight\", \"molecule_backbone.gnn_layers.4.edge_embeddings.1.weight\", \"molecule_backbone.gnn_layers.4.bn.weight\", \"molecule_backbone.gnn_layers.4.bn.bias\", \"molecule_backbone.gnn_layers.4.bn.running_mean\", \"molecule_backbone.gnn_layers.4.bn.running_var\", \"molecule_backbone.gnn_layers.4.bn.num_batches_tracked\", \"molecule_head.weight\", \"molecule_head.bias\", \"molecule_encoder.projection_head.weight\", \"molecule_encoder.projection_head.bias\", \"molecule_encoder.backbone.node_embeddings.0.weight\", \"molecule_encoder.backbone.node_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.0.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.0.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.0.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.0.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.0.bn.weight\", \"molecule_encoder.backbone.gnn_layers.0.bn.bias\", \"molecule_encoder.backbone.gnn_layers.0.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.0.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.0.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.1.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.1.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.1.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.1.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.1.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.1.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.1.bn.weight\", \"molecule_encoder.backbone.gnn_layers.1.bn.bias\", \"molecule_encoder.backbone.gnn_layers.1.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.1.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.1.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.2.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.2.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.2.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.2.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.2.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.2.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.2.bn.weight\", \"molecule_encoder.backbone.gnn_layers.2.bn.bias\", \"molecule_encoder.backbone.gnn_layers.2.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.2.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.2.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.3.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.3.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.3.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.3.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.3.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.3.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.3.bn.weight\", \"molecule_encoder.backbone.gnn_layers.3.bn.bias\", \"molecule_encoder.backbone.gnn_layers.3.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.3.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.3.bn.num_batches_tracked\", \"molecule_encoder.backbone.gnn_layers.4.mlp.0.weight\", \"molecule_encoder.backbone.gnn_layers.4.mlp.0.bias\", \"molecule_encoder.backbone.gnn_layers.4.mlp.2.weight\", \"molecule_encoder.backbone.gnn_layers.4.mlp.2.bias\", \"molecule_encoder.backbone.gnn_layers.4.edge_embeddings.0.weight\", \"molecule_encoder.backbone.gnn_layers.4.edge_embeddings.1.weight\", \"molecule_encoder.backbone.gnn_layers.4.bn.weight\", \"molecule_encoder.backbone.gnn_layers.4.bn.bias\", \"molecule_encoder.backbone.gnn_layers.4.bn.running_mean\", \"molecule_encoder.backbone.gnn_layers.4.bn.running_var\", \"molecule_encoder.backbone.gnn_layers.4.bn.num_batches_tracked\". \\n\\tsize mismatch for image_encoder.projection_head.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\\n\\tsize mismatch for image_encoder.projection_head.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).\\n\\tsize mismatch for image_head.weight: copying a param with shape torch.Size([128, 512]) from checkpoint, the shape in current model is torch.Size([256, 512]).\\n\\tsize mismatch for image_head.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([256]).')\nfull_key: model"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluators = instantiate_evaluator_list(cfg.eval, cross_modal_module=None, logger=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0minstantiate_evaluator_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mevaluator_list_cfg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0momegaconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcross_modal_module\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlogger\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mckpt_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Instantiates evaluator list from config.\n",
      "\u001b[0;31mFile:\u001b[0m      /mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/utils/instantiators.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "instantiate_evaluator_list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriel-watkinson-work\u001b[0m (\u001b[33mjump_models\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../cpjump1/jump/logs/train/multiruns/2023-08-17_13-32-50/0/wandb/run-20230822_144235-9af36zug</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jump_models/fp_small/runs/9af36zug' target=\"_blank\">leafy-snowflake-1</a></strong> to <a href='https://wandb.ai/jump_models/fp_small' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jump_models/fp_small' target=\"_blank\">https://wandb.ai/jump_models/fp_small</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jump_models/fp_small/runs/9af36zug' target=\"_blank\">https://wandb.ai/jump_models/fp_small/runs/9af36zug</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger = utils.instantiate_loggers(cfg.get(\"logger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maccelerator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccelerator\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstrategy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_nodes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprecision\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'16-mixed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bf16-mixed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'32-true'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'64-true'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'32'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bf16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'32-true'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlogger\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfast_dev_run\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_time\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_train_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_val_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_test_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlimit_predict_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moverfit_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mval_check_interval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcheck_val_every_n_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlog_every_n_steps\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0menable_checkpointing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0menable_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0menable_model_summary\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maccumulate_grad_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgradient_clip_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mgradient_clip_algorithm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdeterministic\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbenchmark\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minference_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0muse_distributed_sampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprofiler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofilers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfiler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdetect_anomaly\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbarebones\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mplugins\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrecisionPlugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_sync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerSync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrecisionPlugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_environment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClusterEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointIO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplugins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_sync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerSync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msync_batchnorm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreload_dataloaders_every_n_epochs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdefault_root_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Customize every aspect of training via flags.\n",
      "\n",
      "Args:\n",
      "    accelerator: Supports passing different accelerator types (\"cpu\", \"gpu\", \"tpu\", \"ipu\", \"hpu\", \"mps\", \"auto\")\n",
      "        as well as custom accelerator instances.\n",
      "\n",
      "    strategy: Supports different training strategies with aliases as well custom strategies.\n",
      "        Default: ``\"auto\"``.\n",
      "\n",
      "    devices: The devices to use. Can be set to a positive number (int or str), a sequence of device indices\n",
      "        (list or str), the value ``-1`` to indicate all available devices should be used, or ``\"auto\"`` for\n",
      "        automatic selection based on the chosen accelerator. Default: ``\"auto\"``.\n",
      "\n",
      "    num_nodes: Number of GPU nodes for distributed training.\n",
      "        Default: ``1``.\n",
      "\n",
      "    precision: Double precision (64, '64' or '64-true'), full precision (32, '32' or '32-true'),\n",
      "        16bit mixed precision (16, '16', '16-mixed') or bfloat16 mixed precision ('bf16', 'bf16-mixed').\n",
      "        Can be used on CPU, GPU, TPUs, HPUs or IPUs.\n",
      "        Default: ``'32-true'``.\n",
      "\n",
      "    logger: Logger (or iterable collection of loggers) for experiment tracking. A ``True`` value uses\n",
      "        the default ``TensorBoardLogger`` if it is installed, otherwise ``CSVLogger``.\n",
      "        ``False`` will disable logging. If multiple loggers are provided, local files\n",
      "        (checkpoints, profiler traces, etc.) are saved in the ``log_dir`` of he first logger.\n",
      "        Default: ``True``.\n",
      "\n",
      "    callbacks: Add a callback or list of callbacks.\n",
      "        Default: ``None``.\n",
      "\n",
      "    fast_dev_run: Runs n if set to ``n`` (int) else 1 if set to ``True`` batch(es)\n",
      "        of train, val and test to find any bugs (ie: a sort of unit test).\n",
      "        Default: ``False``.\n",
      "\n",
      "    max_epochs: Stop training once this number of epochs is reached. Disabled by default (None).\n",
      "        If both max_epochs and max_steps are not specified, defaults to ``max_epochs = 1000``.\n",
      "        To enable infinite training, set ``max_epochs = -1``.\n",
      "\n",
      "    min_epochs: Force training for at least these many epochs. Disabled by default (None).\n",
      "\n",
      "    max_steps: Stop training after this number of steps. Disabled by default (-1). If ``max_steps = -1``\n",
      "        and ``max_epochs = None``, will default to ``max_epochs = 1000``. To enable infinite training, set\n",
      "        ``max_epochs`` to ``-1``.\n",
      "\n",
      "    min_steps: Force training for at least these number of steps. Disabled by default (``None``).\n",
      "\n",
      "    max_time: Stop training after this amount of time has passed. Disabled by default (``None``).\n",
      "        The time duration can be specified in the format DD:HH:MM:SS (days, hours, minutes seconds), as a\n",
      "        :class:`datetime.timedelta`, or a dictionary with keys that will be passed to\n",
      "        :class:`datetime.timedelta`.\n",
      "\n",
      "    limit_train_batches: How much of training dataset to check (float = fraction, int = num_batches).\n",
      "        Default: ``1.0``.\n",
      "\n",
      "    limit_val_batches: How much of validation dataset to check (float = fraction, int = num_batches).\n",
      "        Default: ``1.0``.\n",
      "\n",
      "    limit_test_batches: How much of test dataset to check (float = fraction, int = num_batches).\n",
      "        Default: ``1.0``.\n",
      "\n",
      "    limit_predict_batches: How much of prediction dataset to check (float = fraction, int = num_batches).\n",
      "        Default: ``1.0``.\n",
      "\n",
      "    overfit_batches: Overfit a fraction of training/validation data (float) or a set number of batches (int).\n",
      "        Default: ``0.0``.\n",
      "\n",
      "    val_check_interval: How often to check the validation set. Pass a ``float`` in the range [0.0, 1.0] to check\n",
      "        after a fraction of the training epoch. Pass an ``int`` to check after a fixed number of training\n",
      "        batches. An ``int`` value can only be higher than the number of training batches when\n",
      "        ``check_val_every_n_epoch=None``, which validates after every ``N`` training batches\n",
      "        across epochs or during iteration-based training.\n",
      "        Default: ``1.0``.\n",
      "\n",
      "    check_val_every_n_epoch: Perform a validation loop every after every `N` training epochs. If ``None``,\n",
      "        validation will be done solely based on the number of training batches, requiring ``val_check_interval``\n",
      "        to be an integer value.\n",
      "        Default: ``1``.\n",
      "\n",
      "    num_sanity_val_steps: Sanity check runs n validation batches before starting the training routine.\n",
      "        Set it to `-1` to run all batches in all validation dataloaders.\n",
      "        Default: ``2``.\n",
      "\n",
      "    log_every_n_steps: How often to log within steps.\n",
      "        Default: ``50``.\n",
      "\n",
      "    enable_checkpointing: If ``True``, enable checkpointing.\n",
      "        It will configure a default ModelCheckpoint callback if there is no user-defined ModelCheckpoint in\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.callbacks`.\n",
      "        Default: ``True``.\n",
      "\n",
      "    enable_progress_bar: Whether to enable to progress bar by default.\n",
      "        Default: ``True``.\n",
      "\n",
      "    enable_model_summary: Whether to enable model summarization by default.\n",
      "        Default: ``True``.\n",
      "\n",
      "    accumulate_grad_batches: Accumulates gradients over k batches before stepping the optimizer.\n",
      "        Default: 1.\n",
      "\n",
      "    gradient_clip_val: The value at which to clip gradients. Passing ``gradient_clip_val=None`` disables\n",
      "        gradient clipping. If using Automatic Mixed Precision (AMP), the gradients will be unscaled before.\n",
      "        Default: ``None``.\n",
      "\n",
      "    gradient_clip_algorithm: The gradient clipping algorithm to use. Pass ``gradient_clip_algorithm=\"value\"``\n",
      "        to clip by value, and ``gradient_clip_algorithm=\"norm\"`` to clip by norm. By default it will\n",
      "        be set to ``\"norm\"``.\n",
      "\n",
      "    deterministic: If ``True``, sets whether PyTorch operations must use deterministic algorithms.\n",
      "        Set to ``\"warn\"`` to use deterministic algorithms whenever possible, throwing warnings on operations\n",
      "        that don't support deterministic mode (requires PyTorch 1.11+). If not set, defaults to ``False``.\n",
      "        Default: ``None``.\n",
      "\n",
      "    benchmark: The value (``True`` or ``False``) to set ``torch.backends.cudnn.benchmark`` to.\n",
      "        The value for ``torch.backends.cudnn.benchmark`` set in the current session will be used\n",
      "        (``False`` if not manually set). If :paramref:`~lightning.pytorch.trainer.trainer.Trainer.deterministic`\n",
      "        is set to ``True``, this will default to ``False``. Override to manually set a different value.\n",
      "        Default: ``None``.\n",
      "\n",
      "    inference_mode: Whether to use :func:`torch.inference_mode` or :func:`torch.no_grad` during\n",
      "        evaluation (``validate``/``test``/``predict``).\n",
      "\n",
      "    use_distributed_sampler: Whether to wrap the DataLoader's sampler with\n",
      "        :class:`torch.utils.data.DistributedSampler`. If not specified this is toggled automatically for\n",
      "        strategies that require it. By default, it will add ``shuffle=True`` for the train sampler and\n",
      "        ``shuffle=False`` for validation/test/predict samplers. If you want to disable this logic, you can pass\n",
      "        ``False`` and add your own distributed sampler in the dataloader hooks. If ``True`` and a distributed\n",
      "        sampler was already added, Lightning will not replace the existing one. For iterable-style datasets,\n",
      "        we don't do this automatically.\n",
      "\n",
      "    profiler: To profile individual steps during training and assist in identifying bottlenecks.\n",
      "        Default: ``None``.\n",
      "\n",
      "    detect_anomaly: Enable anomaly detection for the autograd engine.\n",
      "        Default: ``False``.\n",
      "\n",
      "    barebones: Whether to run in \"barebones mode\", where all features that may impact raw speed are\n",
      "        disabled. This is meant for analyzing the Trainer overhead and is discouraged during regular training\n",
      "        runs. The following features are deactivated:\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_checkpointing`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.logger`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_progress_bar`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.log_every_n_steps`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.enable_model_summary`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.num_sanity_val_steps`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.fast_dev_run`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.detect_anomaly`,\n",
      "        :paramref:`~lightning.pytorch.trainer.trainer.Trainer.profiler`,\n",
      "        :meth:`~lightning.pytorch.core.module.LightningModule.log`,\n",
      "        :meth:`~lightning.pytorch.core.module.LightningModule.log_dict`.\n",
      "    plugins: Plugins allow modification of core behavior like ddp and amp, and enable custom lightning plugins.\n",
      "        Default: ``None``.\n",
      "\n",
      "    sync_batchnorm: Synchronize batch norm layers between process groups/whole world.\n",
      "        Default: ``False``.\n",
      "\n",
      "    reload_dataloaders_every_n_epochs: Set to a non-negative integer to reload dataloaders every n epochs.\n",
      "        Default: ``0``.\n",
      "\n",
      "    default_root_dir: Default path for logs and weights when no logger/ckpt_callback passed.\n",
      "        Default: ``os.getcwd()``.\n",
      "        Can be remote file paths such as `s3://mybucket/path` or 'hdfs://path/'\n",
      "\n",
      "Raises:\n",
      "    TypeError:\n",
      "        If ``gradient_clip_val`` is not an int or float.\n",
      "\n",
      "    MisconfigurationException:\n",
      "        If ``gradient_clip_algorithm`` is invalid.\n",
      "        If ``track_grad_norm`` is not a positive number or inf.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "Trainer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Logs the metric dict passed in. If `step` parameter is None and `step` key is presented is metrics, uses\n",
      "metrics[\"step\"] as a step.\n",
      "\n",
      "Args:\n",
      "    metrics: Metric values\n",
      "    step: Step for which metrics should be logged. Default value is `self.global_step` during training or\n",
      "        the total validation / test log step count during validation and testing.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "trainer._logger_connector.log_metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fe0feeed120>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':\nTypeError(\"Trainer.__init__() got an unexpected keyword argument 'name'\")\nfull_key: trainer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m _target_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m instantiate(cfg\u001b[39m.\u001b[39;49mtrainer, logger\u001b[39m=\u001b[39;49mlogger, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mCONVERT, ConvertMode\u001b[39m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mPARTIAL, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m instantiate_node(\n\u001b[1;32m    227\u001b[0m         config, \u001b[39m*\u001b[39;49margs, recursive\u001b[39m=\u001b[39;49m_recursive_, convert\u001b[39m=\u001b[39;49m_convert_, partial\u001b[39m=\u001b[39;49m_partial_\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m \u001b[39melif\u001b[39;00m OmegaConf\u001b[39m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[39m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[39m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[39m=\u001b[39mconvert, recursive\u001b[39m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[39m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mreturn\u001b[39;00m _call_target(_target_, partial, args, kwargs, full_key)\n\u001b[1;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[39m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m convert \u001b[39m==\u001b[39m ConvertMode\u001b[39m.\u001b[39mALL \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[39min\u001b[39;00m (ConvertMode\u001b[39m.\u001b[39mPARTIAL, ConvertMode\u001b[39m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[39mand\u001b[39;00m node\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mobject_type \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mfull_key: \u001b[39m\u001b[39m{\u001b[39;00mfull_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[39mraise\u001b[39;00m InstantiationException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'lightning.pytorch.trainer.trainer.Trainer':\nTypeError(\"Trainer.__init__() got an unexpected keyword argument 'name'\")\nfull_key: trainer"
     ]
    }
   ],
   "source": [
    "trainer = instantiate(cfg.trainer, logger=logger, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_log_model',\n",
       " '_logged_model_time',\n",
       " 'log_hyperparams',\n",
       " 'log_metrics',\n",
       " 'log_table',\n",
       " 'log_text',\n",
       " 'log_image',\n",
       " '_scan_and_log_checkpoints',\n",
       " 'log_dir',\n",
       " 'log_graph']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in trainer.loggers[2].__dir__() if \"log\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Log images (tensors, numpy arrays, PIL Images or file paths).\n",
      "\n",
      "Optional kwargs are lists passed to each image (ex: caption, masks, boxes).\n",
      "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "trainer.loggers[2].log_image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mif\u001b[39;00m run\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfinished\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m    \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m run\u001b[39m.\u001b[39mhistory()\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/3.1-gw-wandb-plots.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m       \u001b[39mprint\u001b[39m(row[\u001b[39m\"\u001b[39m\u001b[39m_timestamp\u001b[39m\u001b[39m\"\u001b[39m], row[\u001b[39m\"\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "run = api.run(\"gabriel-watkinson-work/fp_small/pgwoh2f5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run.state == \"finished\":\n",
    "    for i, row in run.history().iterrows():\n",
    "        print(row[\"_timestamp\"], row[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gradients/image_encoder.backbone.layer1.0.conv1.weight',\n",
       " 'gradients/image_encoder.backbone.layer2.1.conv2.weight',\n",
       " 'gradients/molecule_encoder.backbone.2.1.weight',\n",
       " '_wandb',\n",
       " 'gradients/image_encoder.backbone.layer1.1.bn2.bias',\n",
       " 'gradients/image_encoder.backbone.layer2.0.downsample.1.weight',\n",
       " 'jump_moa/image/val/Accuracy_top_3',\n",
       " 'gradients/image_encoder.backbone.layer2.1.bn1.weight',\n",
       " 'jump_moa/image/val/F1Score_top_5',\n",
       " 'gradients/image_encoder.backbone.layer1.0.bn2.weight',\n",
       " 'gradients/image_encoder.backbone.layer2.1.bn2.bias',\n",
       " 'gradients/image_encoder.backbone.layer2.1.conv1.weight',\n",
       " 'gradients/molecule_encoder.backbone.4.0.weight',\n",
       " 'gradients/image_encoder.backbone.layer1.1.bn1.bias',\n",
       " 'gradients/image_encoder.backbone.layer2.1.bn2.weight',\n",
       " 'gradients/image_encoder.backbone.layer2.1.bn1.bias',\n",
       " 'gradients/image_encoder.backbone.layer3.0.downsample.1.bias',\n",
       " 'gradients/image_encoder.backbone.bn1.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.1.conv2.weight',\n",
       " 'lr-Adam/moa_image_encoder',\n",
       " 'gradients/image_encoder.backbone.layer3.0.conv2.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.1.bn2.bias',\n",
       " 'gradients/image_encoder.backbone.layer2.0.bn2.weight',\n",
       " 'jump_moa/image/test/Accuracy_top_5',\n",
       " 'gradients/image_encoder.backbone.conv1.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.0.downsample.0.weight',\n",
       " 'gradients/image_encoder.backbone.layer3.0.downsample.1.weight',\n",
       " 'gradients/image_encoder.backbone.layer2.0.conv2.weight',\n",
       " 'model/temperature',\n",
       " 'gradients/molecule_encoder.backbone.1.1.bias',\n",
       " 'gradients/image_encoder.backbone.layer3.1.conv1.weight',\n",
       " 'gradients/image_encoder.backbone.layer3.0.conv1.weight',\n",
       " 'trainer/global_step',\n",
       " 'gradients/molecule_encoder.backbone.0.0.bias',\n",
       " '_step',\n",
       " 'gradients/image_encoder.backbone.layer4.0.bn2.weight',\n",
       " '_timestamp',\n",
       " 'gradients/image_encoder.backbone.layer3.1.conv2.weight',\n",
       " 'gradients/molecule_encoder.backbone.3.1.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.1.conv1.weight',\n",
       " 'gradients/image_encoder.backbone.layer2.0.conv1.weight',\n",
       " 'gradients/molecule_encoder.backbone.1.0.weight',\n",
       " 'gradients/image_encoder.backbone.layer1.0.bn2.bias',\n",
       " 'jump_moa/image/plots/train_plots',\n",
       " 'gradients/image_encoder.backbone.layer4.1.bn1.bias',\n",
       " 'jump_moa/image/train/F1Score_top_5',\n",
       " '_runtime',\n",
       " 'gradients/image_encoder.backbone.layer1.0.conv2.weight',\n",
       " 'train/loss_step',\n",
       " 'gradients/image_encoder.backbone.layer1.1.conv2.weight',\n",
       " 'gradients/molecule_encoder.backbone.0.0.weight',\n",
       " 'gradients/image_encoder.backbone.layer3.1.bn2.weight',\n",
       " 'gradients/image_encoder.backbone.layer3.1.bn2.bias',\n",
       " 'gradients/image_encoder.backbone.layer3.1.bn1.weight',\n",
       " 'gradients/molecule_encoder.backbone.2.0.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.0.bn1.weight',\n",
       " 'test/loss',\n",
       " 'gradients/image_encoder.projection_head.bias',\n",
       " 'gradients/molecule_encoder.backbone.0.1.weight',\n",
       " 'lr-Adam/image_projection_head',\n",
       " 'jump_moa/image/test/loss',\n",
       " 'gradients/image_encoder.backbone.layer3.0.bn2.weight',\n",
       " 'jump_moa/image/train/loss_epoch',\n",
       " 'gradients/image_encoder.backbone.layer4.0.bn2.bias',\n",
       " 'train/loss_epoch',\n",
       " 'jump_moa/image/train/Accuracy_top_1',\n",
       " 'epoch',\n",
       " 'jump_moa/image/plots/test_plots',\n",
       " 'gradients/image_encoder.backbone.layer2.0.bn1.bias',\n",
       " 'gradients/molecule_encoder.backbone.4.0.bias',\n",
       " 'gradients/image_encoder.backbone.layer2.0.downsample.1.bias',\n",
       " 'gradients/image_encoder.backbone.layer3.0.downsample.0.weight',\n",
       " 'jump_moa/image/test/AUROC',\n",
       " 'gradients/image_encoder.backbone.layer4.0.downsample.1.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.0.conv2.weight',\n",
       " 'gradients/molecule_encoder.backbone.3.1.bias',\n",
       " 'jump_moa/image/val/Accuracy_top_1',\n",
       " 'jump_moa/image/val/Accuracy_top_5',\n",
       " 'gradients/image_encoder.backbone.layer1.0.bn1.bias',\n",
       " 'gradients/image_encoder.backbone.layer1.1.bn2.weight',\n",
       " 'gradients/image_encoder.backbone.layer1.1.bn1.weight',\n",
       " 'gradients/molecule_encoder.backbone.1.1.weight',\n",
       " 'gradients/image_encoder.backbone.layer3.0.bn1.bias',\n",
       " 'lr-Adam/moa_image_head',\n",
       " 'jump_moa/image/test/Accuracy_top_3',\n",
       " 'gradients/molecule_encoder.backbone.0.1.bias',\n",
       " 'jump_moa/image/plots/val_plots',\n",
       " 'jump_moa/image/test/Accuracy_top_1',\n",
       " 'jump_moa/image/val/loss',\n",
       " 'jump_moa/image/train/AUROC',\n",
       " 'jump_moa/image/train/F1Score_top_1',\n",
       " 'jump_moa/image/test/F1Score_top_5',\n",
       " 'gradients/molecule_encoder.backbone.3.0.bias',\n",
       " 'gradients/molecule_encoder.backbone.1.0.bias',\n",
       " 'gradients/image_encoder.backbone.layer3.1.bn1.bias',\n",
       " 'lr-Adam/image_encoder',\n",
       " 'gradients/molecule_encoder.backbone.2.1.bias',\n",
       " 'gradients/image_encoder.backbone.layer4.1.bn2.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.0.bn1.bias',\n",
       " 'gradients/image_encoder.backbone.layer1.0.bn1.weight',\n",
       " 'gradients/image_encoder.backbone.layer3.0.bn2.bias',\n",
       " 'gradients/image_encoder.backbone.layer1.1.conv1.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.0.conv1.weight',\n",
       " 'gradients/image_encoder.backbone.layer2.0.downsample.0.weight',\n",
       " 'gradients/image_encoder.backbone.bn1.bias',\n",
       " 'jump_moa/image/test/F1Score_top_1',\n",
       " 'jump_moa/image/train/Accuracy_top_5',\n",
       " 'lr-Adam/criterion',\n",
       " 'gradients/image_encoder.backbone.layer2.0.bn2.bias',\n",
       " 'gradients/image_encoder.backbone.layer3.0.bn1.weight',\n",
       " 'gradients/image_encoder.projection_head.weight',\n",
       " 'gradients/criterion.logit_scale',\n",
       " 'jump_moa/image/train/Accuracy_top_3',\n",
       " 'lr-Adam/molecule_encoder',\n",
       " 'jump_moa/image/val/AUROC',\n",
       " 'gradients/molecule_encoder.backbone.3.0.weight',\n",
       " 'jump_moa/image/val/F1Score_top_1',\n",
       " 'gradients/image_encoder.backbone.layer2.0.bn1.weight',\n",
       " 'gradients/image_encoder.backbone.layer4.0.downsample.1.bias',\n",
       " 'gradients/image_encoder.backbone.layer4.1.bn1.weight',\n",
       " 'gradients/molecule_encoder.backbone.2.0.bias']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(run.summary.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
