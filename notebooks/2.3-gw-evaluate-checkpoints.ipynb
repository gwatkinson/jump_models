{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models from checkpoints and evaluate them on the evaluation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from src.models.jump_cl import BasicJUMPModule\n",
    "from src.utils import instantiate_evaluator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounting cpjump1...\n",
      "Mounting cpjump2...\n",
      "Mounting cpjump3...\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    if not Path(f\"../cpjump{i}/jump/\").exists():\n",
    "        print(f\"Mounting cpjump{i}...\")\n",
    "        os.system(f\"sshfs bioclust:/projects/cpjump{i}/ ../cpjump{i}\")\n",
    "    else:\n",
    "        print(f\"cpjump{i} already mounted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_str = \"../cpjump1/jump/logs/train/runs/{run}/checkpoints/epoch_{epoch:0>3}.ckpt\"\n",
    "\n",
    "run_dict = {\n",
    "    \"small\": (run := \"2023-08-03_14-37-42\", \"small_jump_cl\", epoch := 19, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"med\": (run := \"2023-08-07_11-55-54\", \"med_jump_cl\", epoch := 5, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"big\": (run := \"2023-08-01_11-37-40\", \"big_jump_cl\", epoch := 1, ckpt_str.format(run=run, epoch=epoch)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, experiment, epoch, ckpt = run_dict[\"small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- experiment=big_jump_cl\n",
      "- trainer.devices=[0,1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f\"cat ../cpjump1/jump/logs/train/runs/{run}/.hydra/overrides.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epoch_001.ckpt', 'last.ckpt']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f\"../cpjump1/jump/logs/train/runs/{run}/checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the config and instantiate the model, loggers and evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=\"../configs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, experiment, epoch, ckpt = run_dict[\"small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- med_jump_cl\n",
      "- simple_contrastive_training\n",
      "- ${model.molecule_encoder.pretrained_name}\n",
      "- ${model.image_encoder.instance_model_name}\n",
      "train: true\n",
      "test: true\n",
      "evaluate: true\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "data:\n",
      "  compound_transform:\n",
      "    _target_: src.modules.compound_transforms.dgllife_transform.DGLPretrainedFromInchi\n",
      "    add_self_loop: true\n",
      "    canonical_atom_order: true\n",
      "    num_virtual_nodes: 0\n",
      "    explicit_hydrogens: false\n",
      "  _target_: src.models.jump_cl.datamodule.BasicJUMPDataModule\n",
      "  batch_size: 32\n",
      "  num_workers: 24\n",
      "  pin_memory: null\n",
      "  prefetch_factor: 3\n",
      "  collate_fn:\n",
      "    _target_: src.modules.collate_fn.dgl_image.image_graph_collate_function\n",
      "    _partial_: true\n",
      "  transform:\n",
      "    _target_: src.modules.transforms.DefaultJUMPTransform\n",
      "    _convert_: object\n",
      "    size: 128\n",
      "    dim:\n",
      "    - -2\n",
      "    - -1\n",
      "  force_split: false\n",
      "  splitter:\n",
      "    _target_: src.splitters.ScaffoldSplitter\n",
      "    train: 800\n",
      "    test: 200\n",
      "    val: 100\n",
      "    retrieval: 0\n",
      "  split_path: ${paths.split_path}/small_jump_cl/\n",
      "  dataloader_config:\n",
      "    train:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      shuffle: true\n",
      "    val:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      shuffle: false\n",
      "    test:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      shuffle: false\n",
      "  image_metadata_path: ${paths.metadata_path}/images_metadata.parquet\n",
      "  compound_metadata_path: ${paths.metadata_path}/compound_dict.json\n",
      "  compound_col: Metadata_InChI\n",
      "  image_sampler: null\n",
      "  metadata_dir: ${paths.raw_metadata_path}/complete_metadata.csv\n",
      "  local_load_data_dir: ${paths.load_data_path}/final/\n",
      "  index_str: '{Metadata_Source}__{Metadata_Batch}__{Metadata_Plate}__{Metadata_Well}__{Metadata_Site}'\n",
      "  channels:\n",
      "  - DNA\n",
      "  - AGP\n",
      "  - ER\n",
      "  - Mito\n",
      "  - RNA\n",
      "  col_fstring: FileName_Orig{channel}\n",
      "  id_cols:\n",
      "  - Metadata_Source\n",
      "  - Metadata_Batch\n",
      "  - Metadata_Plate\n",
      "  - Metadata_Well\n",
      "  extra_cols:\n",
      "  - Metadata_PlateType\n",
      "  - Metadata_Site\n",
      "model:\n",
      "  image_encoder:\n",
      "    _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "    instance_model_name: resnet18\n",
      "    target_num: ${model.embedding_dim}\n",
      "    n_channels: 5\n",
      "    pretrained: true\n",
      "  molecule_encoder:\n",
      "    _target_: src.modules.molecules.dgllife_gin.GINPretrainedWithLinearHead\n",
      "    pretrained_name: gin_supervised_infomax\n",
      "    out_dim: ${model.embedding_dim}\n",
      "    pooling: mean\n",
      "    preload: true\n",
      "  criterion:\n",
      "    _target_: src.modules.losses.contrastive_loss_with_temperature.ContrastiveLossWithTemperature\n",
      "    logit_scale: 0\n",
      "    logit_scale_min: -1\n",
      "    logit_scale_max: 4.605170185988092\n",
      "    requires_grad: true\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 0.01\n",
      "    amsgrad: false\n",
      "    lr: ${model.lr}\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "    _partial_: true\n",
      "    T_0: 15\n",
      "    T_mult: 2\n",
      "    eta_min: 0\n",
      "    last_epoch: -1\n",
      "  _target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "  embedding_dim: 128\n",
      "  lr: 0.04\n",
      "  batch_size: ${data.batch_size}\n",
      "  example_input_path: ${paths.data_root_dir}/jump/models/example_batch/simple_jump_cl/batch.pth\n",
      "  monitor: val/loss\n",
      "  interval: epoch\n",
      "  frequency: 1\n",
      "  params_group_to_ignore: []\n",
      "  image_backbone: backbone\n",
      "  image_head: projection_head\n",
      "  molecule_backbone: backbone\n",
      "  molecule_head: projection_head\n",
      "callbacks:\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 2\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0\n",
      "    patience: 10\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "  wandb_watcher:\n",
      "    _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "    watch: true\n",
      "    watch_log: all\n",
      "    log_freq: 100\n",
      "    log_graph: false\n",
      "logger:\n",
      "  csv:\n",
      "    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    name: csv/\n",
      "    prefix: ''\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    log_graph: false\n",
      "    default_hp_metric: true\n",
      "    prefix: ''\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: jump_models\n",
      "    log_model: true\n",
      "    prefix: ''\n",
      "    group: small_jump_cl\n",
      "    tags: ${tags}\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 0\n",
      "  max_epochs: 50\n",
      "  accelerator: gpu\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 2\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 1\n",
      "  num_sanity_val_steps: 2\n",
      "  reload_dataloaders_every_n_epochs: 1\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  data_root_dir: ../cpjump1/\n",
      "  metadata_path: ${paths.data_root_dir}/jump/models/metadata\n",
      "  raw_metadata_path: ${paths.data_root_dir}/jump/metadata\n",
      "  load_data_path: ${paths.data_root_dir}/jump/load_data\n",
      "  split_path: ${paths.data_root_dir}/jump/models/splits\n",
      "  log_dir: ${paths.data_root_dir}/jump/logs\n",
      "  output_dir: ../cpjump1/jump/logs/train/runs/2023-08-03_14-37-42\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  style: dim\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "eval:\n",
      "  moa_image_task:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "        lr: 0.01\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.moa.module.JumpMOAImageModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/moa\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.moa_image_task.trainer.default_root_dir}/checkpoints\n",
      "        filename: moa_epoch_{epoch:03d}\n",
      "        monitor: jump_moa/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: true\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: false\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: jump_moa/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 10\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: true\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        log_graph: false\n",
      "        plot_every_n_epoch: 5\n",
      "        prefix: jump_moa/image/plots\n",
      "      image_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: image_encoder\n",
      "        group_name: image_encoder\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: JumpMOAImageModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.moa.datamodule.JumpMOADataModule\n",
      "      moa_load_df_path: ${paths.data_root_dir}/jump/models/eval/moa/image_task/moa_1024.csv\n",
      "      split_path: ${paths.data_root_dir}/jump/models/eval/moa/image_task/splits/moa_1024/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      transform: ${data.transform}\n",
      "      metadata_dir: ${paths.raw_metadata_path}\n",
      "      load_data_dir: ${paths.load_data_path}\n",
      "      splitter:\n",
      "        _target_: src.splitters.StratifiedSplitter\n",
      "        train: 0.75\n",
      "        val: 0.15\n",
      "        test: 0.1\n",
      "      max_obs_per_class: 1024\n",
      "      target_col: moa\n",
      "      return_image: true\n",
      "      smiles_col: smiles\n",
      "      return_compound: false\n",
      "      compound_transform: null\n",
      "      collate_fn: null\n",
      "      use_cache: true\n",
      "      force_split: false\n",
      "  tox21:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "        lr: 0.01\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.Tox21Module\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/tox21/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.tox21.trainer.default_root_dir}/checkpoints\n",
      "        filename: moa_epoch_{epoch:03d}\n",
      "        monitor: ogb/tox21/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: true\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: false\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/tox21/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 10\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_watcher:\n",
      "        _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "        watch: true\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        log_graph: false\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: molecule_encoder\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: Tox21Module\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.Tox21DataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      collate_fn: null\n",
      "      use_cache: true\n",
      "  lipo:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "        lr: 0.01\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.LipoModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/lipo/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.lipo.trainer.default_root_dir}/checkpoints\n",
      "        filename: moa_epoch_{epoch:03d}\n",
      "        monitor: ogb/lipo/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: true\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: false\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/lipo/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 10\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_watcher:\n",
      "        _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "        watch: true\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        log_graph: false\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: molecule_encoder\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: LipoModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.LipoDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      collate_fn: null\n",
      "      use_cache: true\n",
      "  esol:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "        lr: 0.01\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.EsolModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/esol/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.esol.trainer.default_root_dir}/checkpoints\n",
      "        filename: moa_epoch_{epoch:03d}\n",
      "        monitor: ogb/esol/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: true\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: false\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/esol/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 10\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_watcher:\n",
      "        _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "        watch: true\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        log_graph: false\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: molecule_encoder\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: EsolModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.EsolDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      collate_fn: null\n",
      "      use_cache: true\n",
      "  bbbp:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "        lr: 0.01\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.BBBPModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/bbbp/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.bbbp.trainer.default_root_dir}/checkpoints\n",
      "        filename: moa_epoch_{epoch:03d}\n",
      "        monitor: ogb/bbbp/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: true\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: false\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/bbbp/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 10\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_watcher:\n",
      "        _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "        watch: true\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        log_graph: false\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: molecule_encoder\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: BBBPModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.BBBPDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      collate_fn: null\n",
      "      use_cache: true\n",
      "  hiv:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "        lr: 0.01\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.HIVModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/hiv/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.hiv.trainer.default_root_dir}/checkpoints\n",
      "        filename: moa_epoch_{epoch:03d}\n",
      "        monitor: ogb/hiv/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: true\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: false\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/hiv/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 10\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_watcher:\n",
      "        _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "        watch: true\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        log_graph: false\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: molecule_encoder\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: HIVModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.HIVDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      collate_fn: null\n",
      "      use_cache: true\n",
      "  idr_graph_retrieval:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/retrieval/idr/\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.retrieval.evaluator.IDRRetrievalEvaluator\n",
      "      name: IDRRetrieval\n",
      "      visualize_kwargs: null\n",
      "    callbacks: null\n",
      "    model:\n",
      "      _target_: src.eval.retrieval.module.IDRRetrievalModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    datamodule:\n",
      "      _target_: src.eval.retrieval.datamodule.IDRRetrievalDataModule\n",
      "      selected_compounds_path: ${paths.data_root_dir}/excape-db/selected_compounds.csv\n",
      "      image_metadata_path: ${paths.data_root_dir}/idr0033-rohban-pathways/processed_metadata.csv\n",
      "      data_root_dir: ${paths.data_root_dir}/screen_1751\n",
      "      image_batch_size: 256\n",
      "      compound_batch_size: 16\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 3\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      transform: ${data.transform}\n",
      "      compound_gene_col: Gene_Symbol\n",
      "      image_gene_col: Gene Symbol\n",
      "      col_fstring: FileName_{channel}\n",
      "      channels: null\n",
      "      target_col: Activity_Flag\n",
      "      smiles_col: SMILES\n",
      "      use_cache: false\n",
      "      mol_collate_fn: null\n",
      "      img_collate_fn: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(\n",
    "    config_name=\"train.yaml\",\n",
    "    overrides=[\n",
    "        \"evaluate=true\",\n",
    "        \"eval=evaluators\",\n",
    "        \"paths.data_root_dir=../cpjump1/\",\n",
    "        f\"paths.output_dir=../cpjump1/jump/logs/train/runs/{run}\",\n",
    "        f\"experiment={experiment}\",\n",
    "        \"trainer.devices=1\",\n",
    "    ],\n",
    ")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../cpjump1/jump/logs/train/runs/2023-08-03_14-37-42/checkpoints/epoch_005.ckpt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(ckpt).exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encoder = instantiate(cfg.model.image_encoder)\n",
    "molecule_encoder = instantiate(cfg.model.molecule_encoder)\n",
    "criterion = instantiate(cfg.model.criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: d268fcb1-e9a5-4a33-8be2-c4196760ec65)')' thrown while requesting HEAD https://huggingface.co/timm/resnet18.a1_in1k/resolve/main/model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gin_supervised_infomax_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_infomax.pth...\n",
      "Pretrained model loaded\n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicJUMPModule(\n",
       "  (image_encoder): CNNEncoder(\n",
       "    (backbone): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (drop_block): Identity()\n",
       "          (act1): ReLU(inplace=True)\n",
       "          (aa): Identity()\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "      (fc): Identity()\n",
       "    )\n",
       "    (entry): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (projection_head): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (dropouts): ModuleList(\n",
       "      (0-4): 5 x Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (molecule_encoder): GINPretrainedWithLinearHead(\n",
       "    (backbone): GIN(\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "      (node_embeddings): ModuleList(\n",
       "        (0): Embedding(120, 300)\n",
       "        (1): Embedding(3, 300)\n",
       "      )\n",
       "      (gnn_layers): ModuleList(\n",
       "        (0-4): 5 x GINLayer(\n",
       "          (mlp): Sequential(\n",
       "            (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (edge_embeddings): ModuleList(\n",
       "            (0): Embedding(6, 300)\n",
       "            (1): Embedding(3, 300)\n",
       "          )\n",
       "          (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): AvgPooling()\n",
       "    (projection_head): Linear(in_features=300, out_features=128, bias=True)\n",
       "  )\n",
       "  (criterion): ContrastiveLossWithTemperature()\n",
       "  (image_backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (image_head): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (molecule_backbone): GIN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (node_embeddings): ModuleList(\n",
       "      (0): Embedding(120, 300)\n",
       "      (1): Embedding(3, 300)\n",
       "    )\n",
       "    (gnn_layers): ModuleList(\n",
       "      (0-4): 5 x GINLayer(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=300, out_features=600, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=600, out_features=300, bias=True)\n",
       "        )\n",
       "        (edge_embeddings): ModuleList(\n",
       "          (0): Embedding(6, 300)\n",
       "          (1): Embedding(3, 300)\n",
       "        )\n",
       "        (bn): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (molecule_head): Linear(in_features=300, out_features=128, bias=True)\n",
       "  (train_loss): MeanMetric()\n",
       "  (val_loss): MeanMetric()\n",
       "  (test_loss): MeanMetric()\n",
       "  (val_loss_min): MinMetric()\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "No callback configs found! Skipping..\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "evaluator_list = instantiate_evaluator_list(cfg.eval, cross_modal_module=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_list.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
