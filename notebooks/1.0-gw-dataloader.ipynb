{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from src.models.jump_cl.datamodule import BasicJUMPDataModule\n",
    "from src.modules.images.timm_pretrained import CNNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=\"../configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(\n",
    "    config_name=\"train.yaml\",\n",
    "    overrides=[\n",
    "        \"experiment=frozen_med\",\n",
    "        \"paths.data_root_dir=../cpjump1/\",\n",
    "        \"model/image_encoder=vit_base\",\n",
    "        \"model/molecule_encoder=attentive_fp\",\n",
    "        \"data/compound_transform=attentive_fp\",\n",
    "        \"data.transform.size=384\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_encoder:\n",
      "  _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "  instance_model_name: vit_base_r50_s16_384.orig_in21k_ft_in1k\n",
      "  target_num: ${model.embedding_dim}\n",
      "  n_channels: 5\n",
      "  pretrained: true\n",
      "molecule_encoder:\n",
      "  _target_: src.modules.molecules.attentive_fp.AttentiveFPWithLinearHead\n",
      "  node_feat_size: 256\n",
      "  edge_feat_size: 128\n",
      "  num_layers: 4\n",
      "  num_timesteps: 2\n",
      "  graph_feat_size: 256\n",
      "  n_tasks: 256\n",
      "  dropout: 0.2\n",
      "  out_dim: 512\n",
      "criterion:\n",
      "  _target_: src.modules.losses.contrastive_loss_with_temperature.ContrastiveLossWithTemperature\n",
      "  logit_scale: 0\n",
      "  logit_scale_min: -1\n",
      "  logit_scale_max: 4.605170185988092\n",
      "  requires_grad: false\n",
      "optimizer:\n",
      "  _target_: torch.optim.Adam\n",
      "  _partial_: true\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "  eps: 1.0e-08\n",
      "  weight_decay: 0.01\n",
      "  amsgrad: false\n",
      "  lr: ${model.lr}\n",
      "scheduler:\n",
      "  _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "  _partial_: true\n",
      "  T_0: 7\n",
      "  T_mult: 2\n",
      "  eta_min: 0\n",
      "  last_epoch: -1\n",
      "_target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "embedding_dim: 512\n",
      "lr: 0.01\n",
      "batch_size: ${data.batch_size}\n",
      "example_input_path: ${paths.data_root_dir}/jump/models/example_batch/simple_jump_cl/batch.pth\n",
      "monitor: val/loss\n",
      "interval: epoch\n",
      "frequency: 1\n",
      "params_group_to_ignore: []\n",
      "image_backbone: backbone\n",
      "image_head: projection_head\n",
      "molecule_backbone: backbone\n",
      "molecule_head: projection_head\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = instantiate(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.jump_cl.datamodule:Loading image metadata df from ../cpjump1//jump/models/metadata/images_metadata.parquet\n",
      "INFO:src.models.jump_cl.datamodule:Loading compound dictionary from ../cpjump1//jump/models/metadata/compound_dict.json\n",
      "INFO:src.models.jump_cl.datamodule:Loading train ids from ../cpjump1//jump/models/splits/med_jump_cl/train_ids.csv\n",
      "INFO:src.models.jump_cl.datamodule:Train, test, val lengths: 25000, 2000, 3000\n",
      "INFO:src.models.jump_cl.datamodule:Preparing train dataset\n",
      "INFO:src.models.jump_cl.datamodule:Preparing validation dataset\n"
     ]
    }
   ],
   "source": [
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_712353/3787650211.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.train_dataset.load_df[f\"FileName_Orig{chan}\"] = dm.train_dataset.load_df[f\"FileName_Orig{chan}\"].str.replace(\"/projects/\", \"../\")\n"
     ]
    }
   ],
   "source": [
    "for chan in [\"DNA\", \"AGP\", \"ER\", \"Mito\", \"RNA\"]:\n",
    "    dm.train_dataset.load_df[f\"FileName_Orig{chan}\"] = dm.train_dataset.load_df[f\"FileName_Orig{chan}\"].str.replace(\n",
    "        \"/projects/\", \"../\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[ 1.6790,  1.6244,  1.5152,  ..., -0.7096, -0.6959, -0.7096],\n",
       "          [ 1.7472,  1.7336,  1.6244,  ..., -0.6959, -0.6959, -0.6959],\n",
       "          [ 1.7472,  1.7199,  1.6517,  ..., -0.7096, -0.6823, -0.6686],\n",
       "          ...,\n",
       "          [ 0.5052,  1.0375,  1.3378,  ..., -0.7232, -0.7232, -0.7369],\n",
       "          [ 0.3687,  0.9010,  1.3241,  ..., -0.7232, -0.7369, -0.7369],\n",
       "          [ 0.1230,  0.6826,  1.1876,  ..., -0.7232, -0.7232, -0.7232]],\n",
       " \n",
       "         [[-1.2070, -1.1039, -0.7433,  ...,  0.3128,  0.6992,  0.7249],\n",
       "          [-1.0782, -1.0524, -0.8206,  ...,  0.3128,  0.4416,  0.4158],\n",
       "          [-0.8979, -1.0524, -1.0009,  ...,  0.3643,  0.3643,  0.2098],\n",
       "          ...,\n",
       "          [ 0.4158,  0.1325, -0.0221,  ..., -0.7691, -0.8721, -0.8206],\n",
       "          [ 0.5704,  0.2355, -0.0221,  ..., -0.7691, -0.9494, -0.8721],\n",
       "          [ 0.3643,  0.2870,  0.0552,  ..., -0.7176, -0.8979, -0.8463]],\n",
       " \n",
       "         [[-0.5458, -0.7003, -0.8548,  ..., -0.3913,  0.0465, -0.0823],\n",
       "          [-0.5973, -0.7003, -0.8548,  ..., -0.6746, -0.2625, -0.3398],\n",
       "          [-0.7261, -0.7518, -0.8033,  ..., -0.8806, -0.6746, -0.7003],\n",
       "          ...,\n",
       "          [ 1.7718,  1.1281,  0.7675,  ..., -1.0351, -1.0866, -0.9836],\n",
       "          [ 1.7461,  1.2311,  0.8190,  ..., -0.9063, -0.9578, -0.9063],\n",
       "          [ 1.8491,  1.4371,  0.9478,  ..., -0.8806, -0.9321, -0.9321]],\n",
       " \n",
       "         [[-0.5592, -0.6067, -0.6542,  ..., -0.6305, -0.3693, -0.2031],\n",
       "          [-0.5355, -0.5830, -0.6067,  ..., -0.8204, -0.6305, -0.4405],\n",
       "          [-0.5355, -0.5355, -0.5355,  ..., -0.8679, -0.7254, -0.5592],\n",
       "          ...,\n",
       "          [ 1.5299,  0.9839,  0.7227,  ..., -0.7017, -0.6542, -0.6305],\n",
       "          [ 1.6011,  1.0788,  0.7227,  ..., -0.6779, -0.6067, -0.5830],\n",
       "          [ 1.6723,  1.1975,  0.7702,  ..., -0.6542, -0.6067, -0.5830]],\n",
       " \n",
       "         [[-0.1982, -0.4886, -0.7263,  ..., -0.7791, -0.2774, -0.1718],\n",
       "          [-0.2774, -0.5150, -0.6999,  ..., -0.9639, -0.5678, -0.4358],\n",
       "          [-0.3830, -0.4886, -0.6206,  ..., -0.9639, -0.7263, -0.6206],\n",
       "          ...,\n",
       "          [ 1.0956,  0.6467,  0.4619,  ..., -0.7527, -0.6999, -0.6471],\n",
       "          [ 1.1748,  0.7259,  0.4355,  ..., -0.7263, -0.6999, -0.6206],\n",
       "          [ 1.2276,  0.8844,  0.5939,  ..., -0.6735, -0.6471, -0.5678]]]),\n",
       " 'compound': Graph(num_nodes=14, num_edges=44,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)})}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = instantiate(cfg.callbacks.jump_cl_freezer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HybridEmbed(\n",
       "  (backbone): ResNetV2(\n",
       "    (stem): Sequential(\n",
       "      (conv): StdConv2dSame(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
       "      (norm): GroupNormAct(\n",
       "        32, 64, eps=1e-05, affine=True\n",
       "        (drop): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (pool): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "    )\n",
       "    (stages): Sequential(\n",
       "      (0): ResNetStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (downsample): DownsampleConv(\n",
       "              (conv): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (conv1): StdConv2dSame(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResNetStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (downsample): DownsampleConv(\n",
       "              (conv): StdConv2dSame(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (norm): GroupNormAct(\n",
       "                32, 512, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (conv1): StdConv2dSame(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 128, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 512, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResNetStage(\n",
       "        (blocks): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (downsample): DownsampleConv(\n",
       "              (conv): StdConv2dSame(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (norm): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (conv1): StdConv2dSame(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (6): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (7): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "          (8): Bottleneck(\n",
       "            (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm1): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (norm2): GroupNormAct(\n",
       "              32, 256, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm3): GroupNormAct(\n",
       "              32, 1024, eps=1e-05, affine=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (act3): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Identity()\n",
       "    (head): ClassifierHead(\n",
       "      (global_pool): SelectAdaptivePool2d (pool_type=, flatten=Identity())\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (fc): Identity()\n",
       "      (flatten): Identity()\n",
       "    )\n",
       "  )\n",
       "  (proj): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.image_encoder.backbone.patch_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dm.train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([14, 74]), torch.Size([44, 13]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndata[\"h\"].shape, x.edata[\"e\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 384, 384])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"image\"].unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.image_encoder.backbone.patch_embed.proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/vit_base_r50_s16_384.orig_in21k_ft_in1k)\n",
      "INFO:timm.models._hub:[timm/vit_base_r50_s16_384.orig_in21k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "INFO:src.modules.images.timm_pretrained:Using model vit_base_resnet50 with projection head\n"
     ]
    }
   ],
   "source": [
    "im = CNNEncoder(\n",
    "    instance_model_name=\"vit_base_r50_s16_384.orig_in21k_ft_in1k\",\n",
    "    target_num=512,\n",
    "    n_channels=5,\n",
    "    pretrained=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256, 256])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.forward(x[\"image\"].unsqueeze(0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "dl = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[-0.3262, -0.3435, -0.3262,  ..., -0.3435, -0.3262, -0.3089],\n",
       "          [-0.3262, -0.3435, -0.3089,  ..., -0.2915, -0.3262, -0.3089],\n",
       "          [-0.3089, -0.3262, -0.3262,  ..., -0.3435, -0.3262, -0.3262],\n",
       "          ...,\n",
       "          [-0.3089, -0.3262, -0.3262,  ..., -0.3262, -0.3262, -0.3262],\n",
       "          [-0.3435, -0.3435, -0.3089,  ..., -0.3262, -0.3262, -0.3262],\n",
       "          [-0.3262, -0.2915, -0.2915,  ..., -0.3089, -0.3435, -0.3262]],\n",
       " \n",
       "         [[-0.7364, -0.7008, -0.7008,  ..., -0.7008, -0.7008, -0.7008],\n",
       "          [-0.7364, -0.7364, -0.7364,  ..., -0.6830, -0.6830, -0.7008],\n",
       "          [-0.7186, -0.7364, -0.7364,  ..., -0.7008, -0.6652, -0.6830],\n",
       "          ...,\n",
       "          [-0.6830, -0.6652, -0.7008,  ..., -0.3446, -0.4337, -0.5405],\n",
       "          [-0.6652, -0.7008, -0.6652,  ..., -0.3090, -0.2734, -0.3624],\n",
       "          [-0.7186, -0.6830, -0.7008,  ..., -0.3090, -0.2378, -0.2912]],\n",
       " \n",
       "         [[-0.7122, -0.6796, -0.6959,  ..., -0.6633, -0.6308, -0.6796],\n",
       "          [-0.6796, -0.7122, -0.6633,  ..., -0.6796, -0.6633, -0.6633],\n",
       "          [-0.6796, -0.6796, -0.6796,  ..., -0.6959, -0.6959, -0.6796],\n",
       "          ...,\n",
       "          [-0.6796, -0.6959, -0.6633,  ..., -0.5657, -0.6308, -0.6308],\n",
       "          [-0.6796, -0.6796, -0.7122,  ..., -0.6145, -0.5820, -0.5657],\n",
       "          [-0.6796, -0.6633, -0.6796,  ..., -0.5820, -0.6145, -0.5657]],\n",
       " \n",
       "         [[-1.2971, -0.9988, -0.8248,  ..., -0.7502, -0.8000, -0.9243],\n",
       "          [-1.1977, -1.1480, -1.3468,  ..., -1.2971, -0.9988, -0.7005],\n",
       "          [-1.5208, -0.5017, -1.1977,  ..., -0.7005, -1.1480, -0.3774],\n",
       "          ...,\n",
       "          [-0.2531, -0.6508, -0.3525,  ..., -0.5762, -0.3277, -0.1039],\n",
       "          [-0.1288, -0.0294,  0.5175,  ..., -0.6011, -0.5762, -0.2282],\n",
       "          [-0.3277,  0.0203,  0.2938,  ..., -0.6757, -0.5514, -0.5762]],\n",
       " \n",
       "         [[-0.7315, -0.7141, -0.6794,  ..., -0.6794, -0.6968, -0.6621],\n",
       "          [-0.7141, -0.6968, -0.7141,  ..., -0.6794, -0.6968, -0.6968],\n",
       "          [-0.7141, -0.7141, -0.7141,  ..., -0.6968, -0.6968, -0.6794],\n",
       "          ...,\n",
       "          [-0.6794, -0.6968, -0.6794,  ..., -0.5580, -0.6274, -0.5927],\n",
       "          [-0.6794, -0.6621, -0.6794,  ..., -0.5927, -0.6100, -0.5753],\n",
       "          [-0.6621, -0.6794, -0.6794,  ..., -0.5580, -0.6100, -0.5927]]]),\n",
       " 'compound': Graph(num_nodes=14, num_edges=44,\n",
       "       ndata_schemes={'h': Scheme(shape=(74,), dtype=torch.float32)}\n",
       "       edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)})}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "b = {\n",
    "    \"image\": x[\"image\"].unsqueeze(0),\n",
    "    \"compound\": x[\"compound\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects / cpjump1 / jump / models / example_batch / simple_jump_cl / batch.pth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0429, -0.0390,  0.0602,  0.0495, -0.0300,  0.0639, -0.0669,  0.0061,\n",
       "         -0.0332, -0.0858,  0.0504,  0.0589, -0.0047,  0.0326, -0.0458, -0.0006,\n",
       "         -0.1529, -0.0057, -0.0414, -0.0168, -0.0141, -0.0045,  0.0413, -0.0539,\n",
       "         -0.0514, -0.0826,  0.0031,  0.0320,  0.0294,  0.0219, -0.0783,  0.0549,\n",
       "          0.0621,  0.0181,  0.0320, -0.0391,  0.0571, -0.0513, -0.0249,  0.0668,\n",
       "         -0.0379, -0.0061,  0.0385, -0.0471,  0.0023,  0.0157,  0.0326,  0.0374,\n",
       "         -0.0731, -0.0163, -0.0617,  0.0898, -0.1262,  0.0227,  0.0920,  0.0767,\n",
       "          0.0809, -0.0212,  0.0421,  0.0346,  0.0787, -0.0290,  0.1543,  0.0636,\n",
       "         -0.0374,  0.0189,  0.0615,  0.0857, -0.0751, -0.0087, -0.0537, -0.0732,\n",
       "          0.1246, -0.1340,  0.0598,  0.0149,  0.0045,  0.0066, -0.0073, -0.0267,\n",
       "          0.0229, -0.1014, -0.0145,  0.0433,  0.0187,  0.0412,  0.0437, -0.0696,\n",
       "          0.0050,  0.0152,  0.0164,  0.0696, -0.0305, -0.0265, -0.0670,  0.0506,\n",
       "         -0.0842,  0.0778, -0.0897, -0.0196, -0.0455, -0.0695,  0.0415,  0.0640,\n",
       "         -0.0327,  0.0761, -0.0234, -0.0328, -0.0735,  0.0205, -0.0116,  0.1143,\n",
       "          0.0642,  0.0700,  0.0460, -0.0250, -0.0505, -0.0193, -0.0047,  0.0283,\n",
       "          0.0559,  0.0266,  0.0061, -0.0238,  0.0868, -0.0236, -0.0490,  0.0934,\n",
       "          0.0482,  0.0253,  0.0461,  0.0288, -0.0167, -0.0572,  0.0034,  0.0509,\n",
       "          0.0052,  0.1149, -0.0039, -0.0189, -0.0602,  0.0191,  0.1246,  0.0195,\n",
       "          0.0430,  0.0198, -0.0542,  0.0158, -0.0544,  0.0283,  0.0646,  0.1049,\n",
       "          0.0064, -0.0157, -0.0624,  0.0862,  0.0971, -0.0160,  0.0927, -0.0115,\n",
       "          0.0341, -0.0110, -0.0561,  0.0395, -0.0240,  0.0332, -0.0330, -0.0547,\n",
       "         -0.0137,  0.0076, -0.0468, -0.0552,  0.0832,  0.0613,  0.0344, -0.0093,\n",
       "         -0.1067, -0.0427, -0.0335, -0.0822, -0.0774, -0.0517, -0.0047, -0.0373,\n",
       "          0.0256, -0.0464, -0.0621,  0.0641,  0.0315, -0.0257, -0.0327, -0.0082,\n",
       "          0.0537,  0.0670,  0.0723, -0.0241,  0.0303,  0.0449,  0.0318, -0.0690,\n",
       "         -0.0103,  0.0750,  0.0361, -0.0291,  0.0829, -0.0216, -0.0845,  0.0397,\n",
       "         -0.0084,  0.0324, -0.0980,  0.0810, -0.0196, -0.0853,  0.0197, -0.0373,\n",
       "         -0.0219, -0.1174, -0.0341, -0.0042, -0.0071,  0.0393, -0.0400, -0.0289,\n",
       "         -0.0480,  0.0824,  0.0400,  0.0366,  0.1017,  0.0849, -0.0404,  0.0166,\n",
       "         -0.0159,  0.0127, -0.0489, -0.1265,  0.0278,  0.1015, -0.0086,  0.0622,\n",
       "         -0.0077, -0.0459, -0.1070, -0.0558, -0.0390, -0.0425, -0.1049,  0.0221,\n",
       "          0.0286, -0.0698, -0.0837,  0.0436,  0.0064, -0.0682,  0.0651,  0.0465,\n",
       "          0.0953, -0.0671,  0.0114, -0.0621,  0.0520, -0.0293, -0.0051,  0.0492,\n",
       "         -0.0061, -0.0838, -0.0414, -0.0545,  0.0178,  0.0737, -0.0031, -0.0893,\n",
       "         -0.0175,  0.0291,  0.0270,  0.0120,  0.0356,  0.0102,  0.0234, -0.0682,\n",
       "         -0.0415, -0.0350, -0.0681,  0.0783, -0.0493,  0.0377,  0.0152,  0.0272,\n",
       "         -0.1141, -0.0711, -0.0711,  0.0007,  0.0902, -0.0057,  0.0326,  0.0848,\n",
       "          0.0836,  0.0265, -0.0296,  0.0754,  0.0438, -0.0695, -0.0054, -0.0596,\n",
       "          0.0496, -0.0849,  0.0687, -0.0074,  0.1582,  0.0345, -0.0489,  0.0740,\n",
       "         -0.0890, -0.0177,  0.1142,  0.0819, -0.1014, -0.0085,  0.0714,  0.1040,\n",
       "          0.0494, -0.0062,  0.0190,  0.0135, -0.0913, -0.0581,  0.0233,  0.1565,\n",
       "         -0.0628, -0.0120, -0.0270,  0.0049, -0.0916,  0.0500,  0.0591,  0.0068,\n",
       "         -0.0260,  0.0271, -0.0631, -0.0439,  0.0042, -0.0178, -0.0856, -0.0128,\n",
       "          0.0025, -0.0419, -0.0496,  0.0983, -0.0524,  0.0960,  0.0886, -0.0851,\n",
       "         -0.0277,  0.0359,  0.0571,  0.0635,  0.0626,  0.0248, -0.0246,  0.0304,\n",
       "          0.1043, -0.0738, -0.0461, -0.0365,  0.0324, -0.0241, -0.0420, -0.0172,\n",
       "         -0.0193,  0.0274, -0.0780, -0.0367, -0.0353,  0.0442,  0.0063, -0.0490,\n",
       "          0.0926, -0.0710,  0.0097, -0.0189, -0.1127, -0.0183,  0.0966, -0.0399,\n",
       "          0.0225, -0.0841,  0.0040,  0.0317,  0.0847, -0.0054,  0.0885,  0.0435,\n",
       "         -0.0665,  0.0422,  0.0050,  0.0044, -0.0184, -0.0762, -0.0630,  0.1678,\n",
       "          0.1341, -0.0096,  0.0114,  0.1410,  0.0483, -0.0094, -0.0016, -0.0675,\n",
       "          0.0597, -0.0123,  0.0960,  0.0293,  0.0201, -0.0618, -0.0236,  0.0290,\n",
       "         -0.0959,  0.0307, -0.0593, -0.1257,  0.0105, -0.0745,  0.0131, -0.0031,\n",
       "         -0.0074,  0.0933, -0.0365, -0.1126,  0.0470, -0.0044, -0.0124,  0.0245,\n",
       "         -0.0613,  0.0079, -0.0185, -0.0227, -0.0128,  0.0051, -0.1335,  0.0448,\n",
       "         -0.0099,  0.0276,  0.0966, -0.0239,  0.0159,  0.0916, -0.0692,  0.0795,\n",
       "          0.0072, -0.0251, -0.0377,  0.0184, -0.0803,  0.0727,  0.0155,  0.0158,\n",
       "         -0.0310,  0.0847, -0.0174, -0.0036, -0.0157,  0.0411,  0.0484,  0.0718,\n",
       "          0.0680,  0.0094, -0.0571,  0.0609,  0.0568,  0.0557, -0.0678, -0.0248,\n",
       "         -0.0937,  0.0510,  0.0670, -0.0474, -0.0540, -0.0492, -0.0712, -0.0120,\n",
       "          0.0435,  0.0090,  0.0173,  0.0402,  0.0159, -0.0729, -0.0696,  0.0606,\n",
       "         -0.0291, -0.0147,  0.0397,  0.0590, -0.0903,  0.0834,  0.1469,  0.0511,\n",
       "          0.0470,  0.0641, -0.0270,  0.0317, -0.0390,  0.0435,  0.0977,  0.0426,\n",
       "         -0.0192,  0.0105,  0.0549,  0.0663,  0.0453, -0.0794,  0.0462,  0.0987]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.molecule_encoder.forward(x[\"compound\"], get_node_weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks.train_bn = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks.freeze_before_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params in each groups:\n",
      "{'image_projection_head': 2, 'molecule_projection_head': 2, 'criterion': 1, 'image_encoder': 60, 'molecule_encoder': 42}\n",
      "Number of require grad params in each groups:\n",
      "{'image_projection_head': 2, 'molecule_projection_head': 2, 'criterion': 0, 'image_encoder': 0, 'molecule_encoder': 0}\n",
      "Params groups to keep:\n",
      "['image_projection_head', 'molecule_projection_head']\n"
     ]
    }
   ],
   "source": [
    "params_groups = [\n",
    "    {\n",
    "        \"params\": list(model.image_head.parameters()),\n",
    "        \"name\": \"image_projection_head\",\n",
    "    },\n",
    "    {\n",
    "        \"params\": list(model.molecule_head.parameters()),\n",
    "        \"name\": \"molecule_projection_head\",\n",
    "    },\n",
    "    {\n",
    "        \"params\": list(model.criterion.parameters()),\n",
    "        \"name\": \"criterion\",\n",
    "    },\n",
    "    {\n",
    "        \"params\": list(model.image_backbone.parameters()),\n",
    "        \"name\": \"image_encoder\",\n",
    "    },\n",
    "    {\n",
    "        \"params\": list(model.molecule_backbone.parameters()),\n",
    "        \"name\": \"molecule_encoder\",\n",
    "    },\n",
    "]\n",
    "filtered_params_groups = [\n",
    "    {\n",
    "        \"params\": list(filter(lambda p: p.requires_grad, group[\"params\"])),\n",
    "        \"name\": group[\"name\"],\n",
    "    }\n",
    "    for group in params_groups\n",
    "]\n",
    "\n",
    "params_len = {group[\"name\"]: len(group[\"params\"]) for group in params_groups}\n",
    "group_lens = {group[\"name\"]: len(group[\"params\"]) for group in filtered_params_groups}\n",
    "\n",
    "group_to_keep = [\n",
    "    group[\"name\"]\n",
    "    for group in filtered_params_groups\n",
    "    if group_lens[group[\"name\"]] > 0 and group[\"name\"] not in model.params_group_to_ignore\n",
    "]\n",
    "\n",
    "print(f\"Number of params in each groups:\\n{params_len}\")\n",
    "print(f\"Number of require grad params in each groups:\\n{group_lens}\")\n",
    "print(f\"Params groups to keep:\\n{group_to_keep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNEncoder(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (act1): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (drop_block): Identity()\n",
       "        (act1): ReLU(inplace=True)\n",
       "        (aa): Identity()\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        (act2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (projection_head): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (dropouts): ModuleList(\n",
       "    (0-4): 5 x Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.image_encoder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
