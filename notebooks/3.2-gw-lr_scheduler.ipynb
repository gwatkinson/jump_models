{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models from checkpoints and evaluate them on the evaluation tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import molfeat\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.utils import instantiate\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "\n",
    "from src import utils\n",
    "from src.models.jump_cl import BasicJUMPModule\n",
    "from src.modules.collate_fn import default_collate\n",
    "from src.modules.collate_fn.default_collate import _default_collate_fn_map\n",
    "from src.modules.losses.contrastive_losses import InfoNCE, NTXent, RegInfoNCE, RegNTXent\n",
    "from src.utils import instantiate_evaluator_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpjump1 already mounted.\n",
      "cpjump2 already mounted.\n",
      "cpjump3 already mounted.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    if not Path(f\"../cpjump{i}/jump/\").exists():\n",
    "        print(f\"Mounting cpjump{i}...\")\n",
    "        os.system(f\"sshfs bioclust:/projects/cpjump{i}/ ../cpjump{i}\")\n",
    "    else:\n",
    "        print(f\"cpjump{i} already mounted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_str = \"../cpjump1/jump/logs/train/multiruns/{run}/checkpoints/epoch_{epoch:0>3}.ckpt\"\n",
    "single_run_ckpt_str = \"../cpjump1/jump/logs/train/runs/{run}/checkpoints/epoch_{epoch:0>3}.ckpt\"\n",
    "\n",
    "run_dict = {\n",
    "    \"small1\": (run := \"2023-08-16_11-59-26/0\", \"small_jump_cl\", epoch := 43, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"small\": (run := \"2023-08-17_13-32-50/0\", \"small_jump_cl\", epoch := 41, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"med\": (run := \"2023-08-07_11-55-54\", \"med_jump_cl\", epoch := 5, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"big\": (run := \"2023-08-01_11-37-40\", \"big_jump_cl\", epoch := 1, ckpt_str.format(run=run, epoch=epoch)),\n",
    "    \"new_small\": (\n",
    "        run := \"2023-08-22_17-15-50\",\n",
    "        \"fp_small\",\n",
    "        epoch := 43,\n",
    "        single_run_ckpt_str.format(run=run, epoch=epoch),\n",
    "    ),\n",
    "    \"new_big\": (run := \"2023-08-23_20-49-23\", \"fp_big\", epoch := 1, single_run_ckpt_str.format(run=run, epoch=epoch)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, experiment, epoch, ckpt = run_dict[\"new_big\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- big_jump_cl\n",
      "- fingerprints\n",
      "- clip_like\n",
      "- ${model.image_encoder.instance_model_name}\n",
      "train: true\n",
      "test: true\n",
      "evaluate: true\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 2354\n",
      "data:\n",
      "  compound_transform:\n",
      "    _target_: src.modules.compound_transforms.fp_transform.FPTransform\n",
      "    fps:\n",
      "    - maccs\n",
      "    - ecfp\n",
      "    compound_str_type: inchi\n",
      "    params:\n",
      "      ecfp:\n",
      "        radius: 2\n",
      "  _target_: src.models.jump_cl.datamodule.BasicJUMPDataModule\n",
      "  batch_size: 1024\n",
      "  num_workers: 16\n",
      "  pin_memory: null\n",
      "  prefetch_factor: 2\n",
      "  drop_last: true\n",
      "  transform:\n",
      "    _target_: src.modules.transforms.DefaultJUMPTransform\n",
      "    _convert_: object\n",
      "    size: 128\n",
      "    dim:\n",
      "    - -2\n",
      "    - -1\n",
      "  force_split: false\n",
      "  splitter:\n",
      "    _target_: src.splitters.ScaffoldSplitter\n",
      "    train: 90112\n",
      "    test: 10240\n",
      "    val: 5120\n",
      "    retrieval: 3072\n",
      "  use_compond_cache: false\n",
      "  data_root_dir: ${paths.projects_dir}/\n",
      "  split_path: ${paths.split_path}/fp_big4/\n",
      "  dataloader_config:\n",
      "    train:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: true\n",
      "    val:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "    test:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "  image_metadata_path: ${paths.metadata_path}/images_metadata.parquet\n",
      "  compound_metadata_path: ${paths.metadata_path}/compound_dict.json\n",
      "  compound_col: Metadata_InChI\n",
      "  image_sampler: null\n",
      "  metadata_dir: ${paths.raw_metadata_path}/complete_metadata.csv\n",
      "  local_load_data_dir: ${paths.load_data_path}/final/\n",
      "  index_str: '{Metadata_Source}__{Metadata_Batch}__{Metadata_Plate}__{Metadata_Well}__{Metadata_Site}'\n",
      "  channels:\n",
      "  - DNA\n",
      "  - AGP\n",
      "  - ER\n",
      "  - Mito\n",
      "  - RNA\n",
      "  col_fstring: FileName_Orig{channel}\n",
      "  id_cols:\n",
      "  - Metadata_Source\n",
      "  - Metadata_Batch\n",
      "  - Metadata_Plate\n",
      "  - Metadata_Well\n",
      "  extra_cols:\n",
      "  - Metadata_PlateType\n",
      "  - Metadata_Site\n",
      "model:\n",
      "  image_encoder:\n",
      "    _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "    instance_model_name: resnet18\n",
      "    target_num: ${model.embedding_dim}\n",
      "    n_channels: 5\n",
      "    pretrained: true\n",
      "  molecule_encoder:\n",
      "    _target_: src.modules.molecules.fp_mlp.FingerprintsWithMLP\n",
      "    input_dim: 2167\n",
      "    out_dim: ${model.embedding_dim}\n",
      "    embedding_dim:\n",
      "    - 1024\n",
      "    - 768\n",
      "    - 512\n",
      "    - 512\n",
      "    activation_layer:\n",
      "      _target_: torch.nn.ReLU\n",
      "      _partial_: true\n",
      "    norm_layer:\n",
      "      _target_: torch.nn.BatchNorm1d\n",
      "      _partial_: true\n",
      "    dropout: 0.2\n",
      "  criterion:\n",
      "    _target_: src.modules.losses.contrastive_loss_with_temperature.ContrastiveLossWithTemperature\n",
      "    logit_scale: 2.3\n",
      "    logit_scale_min: 0\n",
      "    logit_scale_max: 4.605170185988092\n",
      "    requires_grad: true\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 0.05\n",
      "    amsgrad: false\n",
      "    lr: ${model.lr}\n",
      "  scheduler:\n",
      "    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "    _partial_: true\n",
      "    T_0: 4\n",
      "    T_mult: 2\n",
      "    eta_min: 0\n",
      "    last_epoch: -1\n",
      "  _target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "  embedding_dim: 768\n",
      "  lr: 0.001\n",
      "  batch_size: ${data.batch_size}\n",
      "  example_input_path: null\n",
      "  monitor: val/loss\n",
      "  interval: epoch\n",
      "  frequency: 1\n",
      "  image_backbone: backbone\n",
      "  image_head: projection_head\n",
      "  molecule_backbone: null\n",
      "  molecule_head: null\n",
      "callbacks:\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 2\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0\n",
      "    patience: 10\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  timer:\n",
      "    _target_: lightning.pytorch.callbacks.Timer\n",
      "    duration: 00:06:00:00\n",
      "    interval: epoch\n",
      "    verbose: true\n",
      "  nan_loss:\n",
      "    _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "  wandb_watcher:\n",
      "    _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "    watch: true\n",
      "    watch_log: all\n",
      "    log_freq: 100\n",
      "    log_graph: false\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "logger:\n",
      "  csv:\n",
      "    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    name: csv/\n",
      "    prefix: ''\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    log_graph: false\n",
      "    default_hp_metric: true\n",
      "    prefix: ''\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: fp_big\n",
      "    log_model: true\n",
      "    prefix: ''\n",
      "    group: null\n",
      "    tags: ${tags}\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 0\n",
      "  max_epochs: 50\n",
      "  accelerator: gpu\n",
      "  devices:\n",
      "  - 0\n",
      "  check_val_every_n_epoch: 2\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 1\n",
      "  num_sanity_val_steps: 2\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  projects_dir: /projects\n",
      "  data_root_dir: ${paths.projects_dir}/cpjump1\n",
      "  metadata_path: ${paths.data_root_dir}/jump/models/metadata\n",
      "  raw_metadata_path: ${paths.data_root_dir}/jump/metadata\n",
      "  load_data_path: ${paths.data_root_dir}/jump/load_data\n",
      "  split_path: ${paths.data_root_dir}/jump/models/splits\n",
      "  log_dir: ${paths.data_root_dir}/jump/logs\n",
      "  output_dir: ${hydra:runtime.output_dir}\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: false\n",
      "  style: dim\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "eval:\n",
      "  moa_image_task:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.ExponentialLR\n",
      "        _partial_: true\n",
      "        gamma: 0.92\n",
      "      _target_: src.eval.moa.module.JumpMOAImageModule\n",
      "      lr: 0.01\n",
      "      num_classes: 9\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/moa\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.moa_image_task.trainer.default_root_dir}/checkpoints\n",
      "        filename: moa_epoch_{epoch:03d}\n",
      "        monitor: jump_moa/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: true\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: false\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: jump_moa/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 5\n",
      "        log_graph: false\n",
      "        prefix: jump_moa/image/plots\n",
      "        cmap: Oranges_r\n",
      "        fmt: .2f\n",
      "        per_fmt: .1%\n",
      "        fz: 10\n",
      "        lw: 0.5\n",
      "        cbar: false\n",
      "        figsize:\n",
      "        - 16\n",
      "        - 16\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "      image_freezer:\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_initial_ratio_lr: 0.05\n",
      "        group_name: moa_image_encoder_unfrozen\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: JumpMOAImageModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.moa.datamodule.JumpMOADataModule\n",
      "      moa_load_df_path: ${paths.data_root_dir}/jump/models/eval/moa/image_task/moa_500_1024.csv\n",
      "      split_path: ${paths.data_root_dir}/jump/models/eval/moa/image_task/splits/moa_500_1024/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      transform: ${data.transform}\n",
      "      metadata_dir: ${paths.raw_metadata_path}\n",
      "      load_data_dir: ${paths.load_data_path}\n",
      "      data_root_dir: null\n",
      "      splitter:\n",
      "        _target_: src.splitters.StratifiedSplitter\n",
      "        train: 0.75\n",
      "        val: 0.15\n",
      "        test: 0.1\n",
      "      max_obs_per_class: 1024\n",
      "      min_obs_per_class: 500\n",
      "      target_col: moa\n",
      "      return_image: true\n",
      "      smiles_col: smiles\n",
      "      return_compound: false\n",
      "      compound_transform: null\n",
      "      use_cache: true\n",
      "      force_split: false\n",
      "  tox21:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.Tox21Module\n",
      "      lr: 0.01\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/tox21/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.tox21.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/tox21/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/tox21/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: tox21_molecule_unfrozen\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: Tox21Module\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.Tox21DataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: true\n",
      "  lipo:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.LipoModule\n",
      "      lr: 0.01\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/lipo/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.lipo.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/lipo/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/lipo/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: lipo_molecule_unfrozen\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: LipoModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.LipoDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: true\n",
      "  esol:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.EsolModule\n",
      "      lr: 0.01\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/esol/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.esol.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/esol/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/esol/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: esol_molecule_unfrozen\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: EsolModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.EsolDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: true\n",
      "  bbbp:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.BBBPModule\n",
      "      lr: 0.01\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/bbbp/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.bbbp.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/bbbp/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/bbbp/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: bbbp_molecule_unfrozen\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: BBBPModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.BBBPDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: true\n",
      "  hiv:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
      "        _partial_: true\n",
      "        T_0: 10\n",
      "        T_mult: 5\n",
      "        eta_min: 0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.HIVModule\n",
      "      lr: 0.01\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/hiv/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 100\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      gradient_clip_val: 0.5\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.hiv.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/hiv/image/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/hiv/image/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      molecule_freezer:\n",
      "        _target_: src.callbacks.freeze.BackboneFinetuningFromName\n",
      "        unfreeze_backbone_at_epoch: 11\n",
      "        backbone_name: molecule_encoder\n",
      "        group_name: hiv_molecule_unfrozen\n",
      "        lambda_func:\n",
      "          _target_: src.callbacks.freeze.multiplicative_func\n",
      "          a0: 1.5\n",
      "        backbone_initial_ratio_lr: 0.1\n",
      "        backbone_initial_lr: null\n",
      "        should_align: true\n",
      "        initial_denom_lr: 10.0\n",
      "        train_bn: true\n",
      "        verbose: false\n",
      "        rounding: 12\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: HIVModule\n",
      "      visualize_kwargs: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.HIVDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: true\n",
      "  idr_graph_retrieval:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/retrieval/idr/\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.retrieval.evaluator.IDRRetrievalEvaluator\n",
      "      name: IDRRetrieval\n",
      "      visualize_kwargs: null\n",
      "    callbacks: null\n",
      "    model:\n",
      "      _target_: src.eval.retrieval.module.IDRRetrievalModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    datamodule:\n",
      "      _target_: src.eval.retrieval.datamodule.IDRRetrievalDataModule\n",
      "      selected_compounds_path: ${paths.data_root_dir}/excape-db/selected_compounds.csv\n",
      "      image_metadata_path: ${paths.data_root_dir}/idr0033-rohban-pathways/processed_metadata.csv\n",
      "      data_root_dir: ${paths.data_root_dir}/screen_1751\n",
      "      image_batch_size: 256\n",
      "      compound_batch_size: 16\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 3\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      transform: ${data.transform}\n",
      "      compound_gene_col: Gene_Symbol\n",
      "      image_gene_col: Gene Symbol\n",
      "      col_fstring: FileName_{channel}\n",
      "      channels: null\n",
      "      target_col: Activity_Flag\n",
      "      smiles_col: SMILES\n",
      "      use_cache: false\n"
     ]
    }
   ],
   "source": [
    "os.system(f\"cat ../cpjump1/jump/logs/train/runs/{run}/.hydra/config.yaml\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.yaml', 'hydra.yaml', 'overrides.yaml']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(f\"../cpjump1/jump/logs/train/runs/{run}/.hydra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the config and instantiate the model, loggers and evaluators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalHydra.instance().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=f\"../configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- small_jump_cl\n",
      "- pretrained_gin\n",
      "- clip_like\n",
      "- ${model.molecule_encoder.pretrained_name}\n",
      "- ${model.image_encoder.instance_model_name}\n",
      "train: true\n",
      "test: true\n",
      "evaluate: true\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "data:\n",
      "  compound_transform:\n",
      "    _target_: src.modules.compound_transforms.dgllife_transform.DGLPretrainedFromInchi\n",
      "    add_self_loop: true\n",
      "    canonical_atom_order: true\n",
      "    num_virtual_nodes: 0\n",
      "    explicit_hydrogens: false\n",
      "  _target_: src.models.jump_cl.datamodule.BasicJUMPDataModule\n",
      "  batch_size: 4\n",
      "  num_workers: 24\n",
      "  pin_memory: null\n",
      "  prefetch_factor: 3\n",
      "  drop_last: true\n",
      "  transform:\n",
      "    _target_: src.modules.transforms.DefaultJUMPTransform\n",
      "    _convert_: object\n",
      "    size: 128\n",
      "    dim:\n",
      "    - -2\n",
      "    - -1\n",
      "  force_split: false\n",
      "  splitter:\n",
      "    _target_: src.splitters.ScaffoldSplitter\n",
      "    train: 1024\n",
      "    test: 256\n",
      "    val: 128\n",
      "    retrieval: 0\n",
      "  use_compond_cache: false\n",
      "  data_root_dir: ${paths.projects_dir}/\n",
      "  split_path: ${paths.split_path}/fp_small3/\n",
      "  dataloader_config:\n",
      "    train:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: true\n",
      "    val:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "    test:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "  image_metadata_path: ${paths.metadata_path}/images_metadata.parquet\n",
      "  compound_metadata_path: ${paths.metadata_path}/compound_dict.json\n",
      "  compound_col: Metadata_InChI\n",
      "  image_sampler: null\n",
      "  metadata_dir: ${paths.raw_metadata_path}/complete_metadata.csv\n",
      "  local_load_data_dir: ${paths.load_data_path}/final/\n",
      "  index_str: '{Metadata_Source}__{Metadata_Batch}__{Metadata_Plate}__{Metadata_Well}__{Metadata_Site}'\n",
      "  channels:\n",
      "  - DNA\n",
      "  - AGP\n",
      "  - ER\n",
      "  - Mito\n",
      "  - RNA\n",
      "  col_fstring: FileName_Orig{channel}\n",
      "  id_cols:\n",
      "  - Metadata_Source\n",
      "  - Metadata_Batch\n",
      "  - Metadata_Plate\n",
      "  - Metadata_Well\n",
      "  extra_cols:\n",
      "  - Metadata_PlateType\n",
      "  - Metadata_Site\n",
      "model:\n",
      "  image_encoder:\n",
      "    _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "    instance_model_name: resnet18\n",
      "    target_num: ${model.embedding_dim}\n",
      "    n_channels: 5\n",
      "    pretrained: true\n",
      "  molecule_encoder:\n",
      "    _target_: src.modules.molecules.dgllife_gin.GINPretrainedWithLinearHead\n",
      "    pretrained_name: gin_supervised_contextpred\n",
      "    out_dim: ${model.embedding_dim}\n",
      "    pooling: mean\n",
      "    preload: true\n",
      "  criterion:\n",
      "    _target_: src.modules.losses.contrastive_losses.InfoNCE\n",
      "    norm: true\n",
      "    temperature: 1\n",
      "    temperature_requires_grad: false\n",
      "    temperature_min: 0\n",
      "    temperature_max: 100\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 0.001\n",
      "    amsgrad: false\n",
      "    lr: ${model.lr}\n",
      "  scheduler:\n",
      "    _target_: src.modules.lr_schedulers.warmup_wrapper.WarmUpWrapper\n",
      "    _partial_: true\n",
      "    warmup_steps:\n",
      "    - 5\n",
      "    interpolation: linear\n",
      "    wrapped_scheduler: ReduceLROnPlateau\n",
      "    cooldown: 5\n",
      "    factor: 0.6\n",
      "    patience: 10\n",
      "    min_lr: 1.0e-06\n",
      "    threshold: 0.0001\n",
      "    mode: min\n",
      "    verbose: true\n",
      "  _target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "  embedding_dim: 256\n",
      "  lr: 0.0003\n",
      "  batch_size: ${data.batch_size}\n",
      "  example_input_path: ${paths.data_root_dir}/jump/models/example_batch/simple_jump_cl/batch.pth\n",
      "  monitor: val/loss\n",
      "  interval: epoch\n",
      "  frequency: 1\n",
      "  image_backbone: backbone\n",
      "  image_head: projection_head\n",
      "  molecule_backbone: backbone\n",
      "  molecule_head: projection_head\n",
      "callbacks:\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 2\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0\n",
      "    patience: 10\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  timer:\n",
      "    _target_: lightning.pytorch.callbacks.Timer\n",
      "    duration: 00:06:00:00\n",
      "    interval: epoch\n",
      "    verbose: true\n",
      "  nan_loss:\n",
      "    _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "  wandb_watcher:\n",
      "    _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "    watch: true\n",
      "    watch_log: all\n",
      "    log_freq: 100\n",
      "    log_graph: false\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "logger:\n",
      "  csv:\n",
      "    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    name: csv/\n",
      "    prefix: ''\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    log_graph: false\n",
      "    default_hp_metric: true\n",
      "    prefix: ''\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: gin_small\n",
      "    log_model: true\n",
      "    prefix: ''\n",
      "    group: null\n",
      "    tags: ${tags}\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 5\n",
      "  max_epochs: 100\n",
      "  accelerator: gpu\n",
      "  detect_anomaly: true\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 2\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 1\n",
      "  num_sanity_val_steps: 2\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  projects_dir: ..\n",
      "  data_root_dir: ${paths.projects_dir}/cpjump1\n",
      "  metadata_path: ${paths.data_root_dir}/jump/models/metadata\n",
      "  raw_metadata_path: ${paths.data_root_dir}/jump/metadata\n",
      "  load_data_path: ${paths.data_root_dir}/jump/load_data\n",
      "  split_path: ${paths.data_root_dir}/jump/models/splits\n",
      "  log_dir: ${paths.data_root_dir}/jump/logs\n",
      "  output_dir: ../cpjump1/jump/logs/train/multiruns/2023-08-23_20-49-23\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: true\n",
      "  style: dim\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "eval:\n",
      "  idr_graph_retrieval:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/retrieval/idr/\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 2\n",
      "      deterministic: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.retrieval.evaluator.IDRRetrievalEvaluator\n",
      "      name: IDRRetrieval\n",
      "      visualize_kwargs: null\n",
      "    callbacks: null\n",
      "    model:\n",
      "      _target_: src.eval.retrieval.module.IDRRetrievalModule\n",
      "      example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt\n",
      "    datamodule:\n",
      "      _target_: src.eval.retrieval.datamodule.IDRRetrievalDataModule\n",
      "      selected_compounds_path: ${paths.data_root_dir}/excape-db/selected_compounds.csv\n",
      "      image_metadata_path: ${paths.data_root_dir}/idr0033-rohban-pathways/processed_metadata.csv\n",
      "      data_root_dir: ${paths.data_root_dir}/screen_1751\n",
      "      image_batch_size: 256\n",
      "      compound_batch_size: 16\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 3\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      transform: ${data.transform}\n",
      "      compound_gene_col: Gene_Symbol\n",
      "      image_gene_col: Gene Symbol\n",
      "      col_fstring: FileName_{channel}\n",
      "      channels: null\n",
      "      target_col: Activity_Flag\n",
      "      smiles_col: SMILES\n",
      "      use_cache: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(\n",
    "    config_name=\"train.yaml\",\n",
    "    overrides=[\n",
    "        \"evaluate=true\",\n",
    "        \"eval=retrieval\",\n",
    "        \"paths.projects_dir=..\",\n",
    "        f\"paths.output_dir=../cpjump1/jump/logs/train/multiruns/{run}\",\n",
    "        \"experiment=gin_context_pred/small\",\n",
    "        \"data.batch_size=4\",\n",
    "        # \"model/molecule_encoder=gin_masking.yaml\",\n",
    "        \"trainer.devices=1\",\n",
    "        # \"eval.moa_image_task.datamodule.data_root_dir=../\",\n",
    "    ],\n",
    ")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "dm = instantiate(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "dl = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.scheduler.warmup_steps = [3]\n",
    "cfg.model.monitor = \"val/loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gin_supervised_contextpred_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_contextpred.pth...\n",
      "Pretrained model loaded\n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model, map_location=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n"
     ]
    }
   ],
   "source": [
    "trainer = instantiate(\n",
    "    cfg.trainer,\n",
    "    limit_train_batches=1,\n",
    "    limit_val_batches=1,\n",
    "    num_sanity_val_steps=1,\n",
    "    logger=False,\n",
    "    check_val_every_n_epoch=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train/loss': tensor(1.3786),\n",
       " 'train/loss_step': tensor(1.3786),\n",
       " 'train/steps': tensor(3.),\n",
       " 'train/loss_epoch': tensor(1.3786),\n",
       " 'val/loss': tensor(1.3981)}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.callback_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train/loss_step': tensor(1.3786),\n",
       " 'train/steps': tensor(3.),\n",
       " 'train/loss_epoch': tensor(1.3786),\n",
       " 'val/steps': tensor(3.),\n",
       " 'val/loss': tensor(1.3981)}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "batches = []\n",
    "embs = []\n",
    "for i, batch in enumerate(dm.train_dataloader()):\n",
    "    batches.append({k: v.to(device) for k, v in batch.items()})\n",
    "    embs.append(model(**batches[i]))\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_emb': tensor([[ 0.3213, -0.1112, -0.3768,  ...,  0.2018, -0.3701, -0.4943],\n",
       "         [-0.0396, -0.1335,  0.0044,  ...,  0.1353, -0.3113, -0.1665],\n",
       "         [ 0.3029, -0.0417,  0.1074,  ...,  0.4303,  0.0726,  0.1281],\n",
       "         [-0.1516, -0.0128, -0.0193,  ...,  0.1602, -0.1948, -0.0625]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " 'compound_emb': tensor([[ 0.0813,  0.0202, -0.0115,  ...,  0.0848,  0.0620,  0.0570],\n",
       "         [-0.0428, -0.0047,  0.0897,  ...,  0.1063,  0.0917,  0.1529],\n",
       "         [-0.0306,  0.0627, -0.0716,  ...,  0.0193,  0.0201,  0.1033],\n",
       "         [-0.1542,  0.0046, -0.0676,  ...,  0.0799,  0.0721,  0.0802]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "infonce = InfoNCE(temperature=0.5, norm=True, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infonce(embs[0][\"image_emb\"], embs[0][\"image_emb\"]) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = embs[0][\"image_emb\"]\n",
    "z2 = embs[0][\"compound_emb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = torch.einsum(\"ik,jk->ij\", z1, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1_abs = z1.norm(dim=1)\n",
    "z2_abs = z2.norm(dim=1)\n",
    "sim_matrix = sim_matrix / (torch.einsum(\"i,j->ij\", z1_abs, z2_abs) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_matrix = torch.exp(sim_matrix / 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0888, 0.7952, 0.8916, 1.0491],\n",
       "        [0.6790, 0.7940, 0.6577, 1.1722],\n",
       "        [0.8089, 1.0380, 0.7858, 1.1058],\n",
       "        [0.9522, 0.8749, 0.8597, 1.1981]], device='cuda:0',\n",
       "       grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sim = torch.diagonal(sim_matrix)\n",
    "loss = pos_sim / (sim_matrix.sum(dim=1) - pos_sim)  # This is the difference from InfoNCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9214, 1.1506, 1.3238, 0.8076], device='cuda:0',\n",
       "       grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.4275, 4.8740, 4.4021, 4.3147], device='cuda:0',\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sim_matrix.sum(dim=1) - pos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6140, 0.5577, 0.6175, 0.6300], device='cuda:0',\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sim / (sim_matrix.sum(dim=1) - pos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9285, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infonce(model.molecule_encoder(nan_batch[\"compound\"].to(\"cpu\")), im_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "j = 1\n",
    "\n",
    "for criterion in criterions:\n",
    "    for i in range(3):\n",
    "        key = f\"{criterion.__class__.__name__}_{i}\"\n",
    "        if key in res:\n",
    "            key += f\"_{j}\"\n",
    "            j += 1\n",
    "        res[key] = criterion(\n",
    "            embs[i][\"image_emb\"],\n",
    "            embs[i][\"compound_emb\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NtXentLoss_0': tensor(2.4853, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'NtXentLoss_1': tensor(2.4590, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'NtXentLoss_2': tensor(2.4400, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'NTXent_0': tensor(1.1239, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'NTXent_1': tensor(1.0914, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'NTXent_2': tensor(1.0687, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'ContrastiveLossWithTemperature_0': tensor(1.4052, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'ContrastiveLossWithTemperature_1': tensor(1.3802, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'ContrastiveLossWithTemperature_2': tensor(1.3642, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'NTXent_0_1': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'NTXent_1_2': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'NTXent_2_3': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_0': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_1': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_2': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_0_4': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_1_5': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_2_6': tensor(-inf, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_0_7': tensor(15.2721, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_1_8': tensor(48.4157, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_2_9': tensor(6.6935, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_0_10': tensor(15.2721, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_1_11': tensor(48.4157, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_2_12': tensor(6.6935, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_0_13': tensor(1.4072, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'InfoNCE_1_14': tensor(1.3826, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'InfoNCE_2_15': tensor(1.3642, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'InfoNCE_0_16': tensor(16.2995, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_1_17': tensor(49.3947, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_2_18': tensor(7.6799, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_0_19': tensor(15.2721, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_1_20': tensor(48.4157, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'InfoNCE_2_21': tensor(6.6935, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0298, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor(1.0107, device='cuda:0', grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l11 / l12, l21 / l22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_a = embs[0][\"compound_emb\"]\n",
    "embeddings_b = embs[0][\"image_emb\"]\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_a_abs = F.normalize(embeddings_a, dim=1)\n",
    "embeddings_b_abs = F.normalize(embeddings_b, dim=1)\n",
    "\n",
    "out = torch.cat([embeddings_a_abs, embeddings_b_abs], dim=0)\n",
    "n_samples = out.shape[0]\n",
    "\n",
    "# Calculate cosine similarity\n",
    "sim = torch.mm(out, out.t().contiguous())\n",
    "sim = torch.exp(sim / temperature)\n",
    "\n",
    "# Negative similarity\n",
    "mask = ~torch.eye(n_samples, device=sim.device).bool()\n",
    "neg = sim.masked_select(mask).view(n_samples, -1).sum(dim=-1)\n",
    "\n",
    "# Positive similarity\n",
    "pos = torch.exp(torch.sum(embeddings_a * embeddings_b, dim=-1) / temperature)\n",
    "pos = torch.cat([pos, pos], dim=0)\n",
    "\n",
    "loss = -torch.log(pos / neg).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30.5000, device='cuda:0', grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_a_abs = F.normalize(embeddings_a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-18.0215, -34.1079,  -9.9153,  -5.6235],\n",
       "        [ -8.6863, -19.3624,  -5.2746,  -3.0330],\n",
       "        [-19.6764, -35.8913, -10.7404,  -6.0404],\n",
       "        [-21.9357, -40.2616, -12.6212,  -7.4393]], device='cuda:0',\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(embs[0][\"image_emb\"], embs[0][\"compound_emb\"].t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0][\"compound_emb\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[0][\"image_emb\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = instantiate(cfg.trainer, callbacks=utils.instantiate_callbacks(cfg.callbacks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix collate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m      /mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/modules/collate_fn/default_collate.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "default_collate?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
