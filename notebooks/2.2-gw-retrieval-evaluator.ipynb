{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the IDR retrieval evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.utils import instantiate\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.functional import pairwise_cosine_similarity, retrieval_hit_rate\n",
    "from torchmetrics.retrieval import (\n",
    "    RetrievalFallOut,\n",
    "    RetrievalHitRate,\n",
    "    RetrievalMAP,\n",
    "    RetrievalMRR,\n",
    "    RetrievalNormalizedDCG,\n",
    "    RetrievalPrecision,\n",
    "    RetrievalRPrecision,\n",
    ")\n",
    "\n",
    "from src import utils\n",
    "from src.eval.retrieval import IDRRetrievalDataModule, IDRRetrievalEvaluator, IDRRetrievalModule\n",
    "from src.modules.compound_transforms import DGLPretrainedFromSmiles\n",
    "from src.modules.images import CNNEncoder\n",
    "from src.modules.molecules import GINPretrainedWithLinearHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounting cpjump1...\n",
      "Mounting cpjump2...\n",
      "Mounting cpjump3...\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    if not Path(f\"../cpjump{i}/jump/\").exists():\n",
    "        print(f\"Mounting cpjump{i}...\")\n",
    "        os.system(f\"sshfs bioclust:/projects/cpjump{i}/ ../cpjump{i}\")\n",
    "    else:\n",
    "        print(f\"cpjump{i} already mounted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the IDR Evaluator config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalHydra.instance().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=\"../configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- final_experiments\n",
      "- pretrained\n",
      "- loss_experiments\n",
      "- single_view\n",
      "- med_data\n",
      "- resnet34\n",
      "- pna\n",
      "- info_nce\n",
      "train: true\n",
      "load_first_bacth: true\n",
      "test: true\n",
      "evaluate: true\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "data:\n",
      "  compound_transform:\n",
      "    _target_: src.modules.compound_transforms.pna.PNATransform\n",
      "    compound_str_type: inchi\n",
      "  _target_: src.models.jump_cl.datamodule.BasicJUMPDataModule\n",
      "  batch_size: 196\n",
      "  num_workers: 16\n",
      "  pin_memory: null\n",
      "  prefetch_factor: 2\n",
      "  drop_last: true\n",
      "  transform:\n",
      "    _target_: src.modules.transforms.SimpleTransform\n",
      "    _convert_: object\n",
      "    size: 512\n",
      "  force_split: false\n",
      "  splitter:\n",
      "    _target_: src.splitters.ScaffoldSplitter\n",
      "    train: 32768\n",
      "    test: 8192\n",
      "    val: 4096\n",
      "    retrieval: 4096\n",
      "  use_compond_cache: false\n",
      "  data_root_dir: ${paths.projects_dir}/\n",
      "  split_path: ${paths.split_path}/scaffold_split/\n",
      "  dataloader_config:\n",
      "    train:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: true\n",
      "    val:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "    test:\n",
      "      batch_size: 100\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "  image_metadata_path: ${paths.metadata_path}/images_metadata.parquet\n",
      "  compound_metadata_path: ${paths.metadata_path}/compound_dict.json\n",
      "  compound_col: Metadata_InChI\n",
      "  image_sampler: null\n",
      "  metadata_dir: ${paths.raw_metadata_path}/complete_metadata.csv\n",
      "  local_load_data_dir: ${paths.load_data_path}/final/\n",
      "  index_str: '{Metadata_Source}__{Metadata_Batch}__{Metadata_Plate}__{Metadata_Well}__{Metadata_Site}'\n",
      "  channels:\n",
      "  - DNA\n",
      "  - AGP\n",
      "  - ER\n",
      "  - Mito\n",
      "  - RNA\n",
      "  col_fstring: FileName_Orig{channel}\n",
      "  id_cols:\n",
      "  - Metadata_Source\n",
      "  - Metadata_Batch\n",
      "  - Metadata_Plate\n",
      "  - Metadata_Well\n",
      "  extra_cols:\n",
      "  - Metadata_PlateType\n",
      "  - Metadata_Site\n",
      "  train_ids_name: train_med\n",
      "model:\n",
      "  image_encoder:\n",
      "    _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "    instance_model_name: resnet34\n",
      "    n_channels: 5\n",
      "    pretrained: true\n",
      "  molecule_encoder:\n",
      "    _target_: src.modules.molecules.pna.PNA\n",
      "    ckpt_path: ${paths.projects_dir}/cpjump1/jump/s3_cache/best_checkpoint_35epochs.pt\n",
      "    target_dim: 256\n",
      "    hidden_dim: 200\n",
      "    mid_batch_norm: true\n",
      "    last_batch_norm: true\n",
      "    readout_batchnorm: true\n",
      "    batch_norm_momentum: 0.93\n",
      "    readout_hidden_dim: 200\n",
      "    readout_layers: 2\n",
      "    dropout: 0.05\n",
      "    propagation_depth: 7\n",
      "    aggregators:\n",
      "    - mean\n",
      "    - max\n",
      "    - min\n",
      "    - std\n",
      "    scalers:\n",
      "    - identity\n",
      "    - amplification\n",
      "    - attenuation\n",
      "    readout_aggregators:\n",
      "    - min\n",
      "    - max\n",
      "    - mean\n",
      "    pretrans_layers: 2\n",
      "    posttrans_layers: 1\n",
      "    residual: true\n",
      "  criterion:\n",
      "    _target_: src.modules.losses.contrastive_losses.InfoNCE\n",
      "    norm: true\n",
      "    temperature: 0.5\n",
      "    return_rank: true\n",
      "    temperature_requires_grad: false\n",
      "    temperature_min: 0\n",
      "    temperature_max: 100\n",
      "  optimizer:\n",
      "    _target_: torch.optim.AdamW\n",
      "    _partial_: true\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 0.01\n",
      "    amsgrad: false\n",
      "    lr: ${model.lr}\n",
      "  scheduler:\n",
      "    _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "    _partial_: true\n",
      "    warmup_epochs: 10\n",
      "    max_epochs: ${trainer.max_epochs}\n",
      "    warmup_start_lr: 1.0e-06\n",
      "    eta_min: 0.0\n",
      "    last_epoch: -1\n",
      "  _target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "  embedding_dim: 128\n",
      "  lr: 0.0003\n",
      "  batch_size: ${data.batch_size}\n",
      "  example_input_path: null\n",
      "  monitor: val/loss\n",
      "  interval: epoch\n",
      "  frequency: 1\n",
      "  split_lr_in_groups: false\n",
      "callbacks:\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 2\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0\n",
      "    patience: 25\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  timer:\n",
      "    _target_: lightning.pytorch.callbacks.Timer\n",
      "    duration: 02:00:00:00\n",
      "    interval: epoch\n",
      "    verbose: true\n",
      "  nan_loss:\n",
      "    _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "  wandb_watcher:\n",
      "    _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "    watch: true\n",
      "    watch_log: all\n",
      "    log_freq: 100\n",
      "    log_graph: false\n",
      "  temperature_logger:\n",
      "    _target_: src.callbacks.temperature_log.TemperatureLoggingCallback\n",
      "    attribute_name:\n",
      "    - criterion\n",
      "    - temperature\n",
      "    key: model/temperature\n",
      "    interval: step\n",
      "    frequency: 1\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "logger:\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: final_experiments\n",
      "    log_model: true\n",
      "    prefix: ''\n",
      "    group: loss_experiment\n",
      "    tags: ${tags}\n",
      "    job_type: pretrain\n",
      "    name: med_info_nce_loss\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 0\n",
      "  max_epochs: 100\n",
      "  accelerator: gpu\n",
      "  detect_anomaly: true\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 1\n",
      "  num_sanity_val_steps: 1\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  projects_dir: ..\n",
      "  data_root_dir: ${paths.projects_dir}/cpjump1\n",
      "  metadata_path: ${paths.data_root_dir}/jump/models/metadata\n",
      "  raw_metadata_path: ${paths.data_root_dir}/jump/metadata\n",
      "  load_data_path: ${paths.data_root_dir}/jump/load_data\n",
      "  model_dir: ${paths.data_root_dir}/jump/s3_cache\n",
      "  split_path: ${paths.data_root_dir}/jump/models/splits\n",
      "  log_dir: ${paths.data_root_dir}/jump/logs\n",
      "  output_dir: ./tmp/21312FS12A\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: true\n",
      "  style: dim\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "eval:\n",
      "  idr_graph_retrieval:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/retrieval/idr/\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "    model:\n",
      "      _target_: src.eval.retrieval.module.IDRRetrievalModule\n",
      "      example_input_path: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.retrieval.datamodule.IDRRetrievalDataModule\n",
      "      image_metadata_path: ${paths.data_root_dir}/idr0033-rohban-pathways/processed_metadata.csv\n",
      "      excape_db_path: ${paths.data_root_dir}/excape-db/excape_db_df.csv\n",
      "      selected_group_path: ${paths.data_root_dir}/excape-db/processed_groups.json\n",
      "      data_root_dir: ${paths.data_root_dir}/screen_1751\n",
      "      image_batch_size: 128\n",
      "      compound_batch_size: 1\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      transform: ${data.transform}\n",
      "      image_gene_col: Gene Symbol\n",
      "      col_fstring: FileName_{channel}\n",
      "      channels: null\n",
      "      target_col: Activity_Flag\n",
      "      smiles_col: SMILES\n",
      "    evaluator:\n",
      "      _target_: src.eval.retrieval.evaluator.IDRRetrievalEvaluator\n",
      "      name: IDRRetrieval\n",
      "      visualize_kwargs: null\n",
      "    callbacks: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(\n",
    "    config_name=\"train.yaml\",\n",
    "    overrides=[\n",
    "        \"evaluate=true\",\n",
    "        \"eval=retrieval\",\n",
    "        \"paths.projects_dir=..\",\n",
    "        \"paths.output_dir=./tmp/21312FS12A\",\n",
    "        \"experiment=final/loss_experiments/info_nce.yaml\",\n",
    "        # \"data.batch_size=32\",\n",
    "        # \"model/molecule_encoder=gin_masking.yaml\",\n",
    "        \"trainer.devices=1\",\n",
    "        # \"eval.moa_image_task.datamodule.data_root_dir=../\",\n",
    "    ],\n",
    ")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_encoder:\n",
      "  _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "  instance_model_name: resnet34\n",
      "  n_channels: 5\n",
      "  pretrained: true\n",
      "molecule_encoder:\n",
      "  _target_: src.modules.molecules.pna.PNA\n",
      "  ckpt_path: ${paths.projects_dir}/cpjump1/jump/s3_cache/best_checkpoint_35epochs.pt\n",
      "  target_dim: 256\n",
      "  hidden_dim: 200\n",
      "  mid_batch_norm: true\n",
      "  last_batch_norm: true\n",
      "  readout_batchnorm: true\n",
      "  batch_norm_momentum: 0.93\n",
      "  readout_hidden_dim: 200\n",
      "  readout_layers: 2\n",
      "  dropout: 0.05\n",
      "  propagation_depth: 7\n",
      "  aggregators:\n",
      "  - mean\n",
      "  - max\n",
      "  - min\n",
      "  - std\n",
      "  scalers:\n",
      "  - identity\n",
      "  - amplification\n",
      "  - attenuation\n",
      "  readout_aggregators:\n",
      "  - min\n",
      "  - max\n",
      "  - mean\n",
      "  pretrans_layers: 2\n",
      "  posttrans_layers: 1\n",
      "  residual: true\n",
      "criterion:\n",
      "  _target_: src.modules.losses.contrastive_losses.InfoNCE\n",
      "  norm: true\n",
      "  temperature: 0.5\n",
      "  return_rank: true\n",
      "  temperature_requires_grad: false\n",
      "  temperature_min: 0\n",
      "  temperature_max: 100\n",
      "optimizer:\n",
      "  _target_: torch.optim.AdamW\n",
      "  _partial_: true\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "  eps: 1.0e-08\n",
      "  weight_decay: 0.01\n",
      "  amsgrad: false\n",
      "  lr: ${model.lr}\n",
      "scheduler:\n",
      "  _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "  _partial_: true\n",
      "  warmup_epochs: 10\n",
      "  max_epochs: ${trainer.max_epochs}\n",
      "  warmup_start_lr: 1.0e-06\n",
      "  eta_min: 0.0\n",
      "  last_epoch: -1\n",
      "_target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "embedding_dim: 128\n",
      "lr: 0.0003\n",
      "batch_size: ${data.batch_size}\n",
      "example_input_path: null\n",
      "monitor: val/loss\n",
      "interval: epoch\n",
      "frequency: 1\n",
      "split_lr_in_groups: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(OmegaConf.to_yaml(cfg.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InstantiationException",
     "evalue": "Error in call to target 'src.eval.retrieval.module.IDRRetrievalModule':\nValueError('Image and molecule encoders must have the same output dimension. Got 512 and 256.')\nfull_key: eval.idr_graph_retrieval.model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m _target_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/eval/retrieval/module.py:82\u001b[0m, in \u001b[0;36mIDRRetrievalModule.__init__\u001b[0;34m(self, cross_modal_module, image_encoder_attribute_name, molecule_encoder_attribute_name, image_encoder, molecule_encoder, distance_metric, example_input, example_input_path)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_encoder\u001b[39m.\u001b[39mout_dim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmolecule_encoder\u001b[39m.\u001b[39mout_dim:\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     83\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImage and molecule encoders must have the same output dimension. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_encoder\u001b[39m.\u001b[39mout_dim\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmolecule_encoder\u001b[39m.\u001b[39mout_dim\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m     )\n\u001b[1;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_dim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_encoder\u001b[39m.\u001b[39mout_dim\n",
      "\u001b[0;31mValueError\u001b[0m: Image and molecule encoders must have the same output dimension. Got 512 and 256.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m cfg\u001b[39m.\u001b[39meval:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     evaluator \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49minstantiate_evaluator(\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         cfg\u001b[39m.\u001b[39;49meval[key],\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         model_cfg\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         logger\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         ckpt_path\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mckpt_path,\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     )\n\u001b[1;32m      <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# try:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m#     evaluator.run()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# except Exception as e:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/2.2-gw-retrieval-evaluator.ipynb#X60sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m#     log.error(f\"Error while running {evaluator}: {e}\")\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/utils/instantiators.py:76\u001b[0m, in \u001b[0;36minstantiate_evaluator\u001b[0;34m(evaluator_cfg, model_cfg, logger, ckpt_path, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m evaluator_cfg:\n\u001b[1;32m     75\u001b[0m     model \u001b[39m=\u001b[39m hydra\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39minstantiate(model_cfg)\n\u001b[0;32m---> 76\u001b[0m     module \u001b[39m=\u001b[39m hydra\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49minstantiate(evaluator_cfg\u001b[39m.\u001b[39;49mmodel, cross_modal_module\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mEvaluator config must contain a model!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     _convert_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mCONVERT, ConvertMode\u001b[39m.\u001b[39mNONE)\n\u001b[1;32m    224\u001b[0m     _partial_ \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mpop(_Keys\u001b[39m.\u001b[39mPARTIAL, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m instantiate_node(\n\u001b[1;32m    227\u001b[0m         config, \u001b[39m*\u001b[39;49margs, recursive\u001b[39m=\u001b[39;49m_recursive_, convert\u001b[39m=\u001b[39;49m_convert_, partial\u001b[39m=\u001b[39;49m_partial_\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    229\u001b[0m \u001b[39melif\u001b[39;00m OmegaConf\u001b[39m.\u001b[39mis_list(config):\n\u001b[1;32m    230\u001b[0m     \u001b[39m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[1;32m    231\u001b[0m     config_copy \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(config)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[0m, in \u001b[0;36minstantiate_node\u001b[0;34m(node, convert, recursive, partial, *args)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 value \u001b[39m=\u001b[39m instantiate_node(\n\u001b[1;32m    343\u001b[0m                     value, convert\u001b[39m=\u001b[39mconvert, recursive\u001b[39m=\u001b[39mrecursive\n\u001b[1;32m    344\u001b[0m                 )\n\u001b[1;32m    345\u001b[0m             kwargs[key] \u001b[39m=\u001b[39m _convert_node(value, convert)\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mreturn\u001b[39;00m _call_target(_target_, partial, args, kwargs, full_key)\n\u001b[1;32m    348\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     \u001b[39m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[39m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m convert \u001b[39m==\u001b[39m ConvertMode\u001b[39m.\u001b[39mALL \u001b[39mor\u001b[39;00m (\n\u001b[1;32m    352\u001b[0m         convert \u001b[39min\u001b[39;00m (ConvertMode\u001b[39m.\u001b[39mPARTIAL, ConvertMode\u001b[39m.\u001b[39mOBJECT)\n\u001b[1;32m    353\u001b[0m         \u001b[39mand\u001b[39;00m node\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mobject_type \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    354\u001b[0m     ):\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[0m, in \u001b[0;36m_call_target\u001b[0;34m(_target_, _partial_, args, kwargs, full_key)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m full_key:\n\u001b[1;32m     96\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mfull_key: \u001b[39m\u001b[39m{\u001b[39;00mfull_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 97\u001b[0m \u001b[39mraise\u001b[39;00m InstantiationException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Error in call to target 'src.eval.retrieval.module.IDRRetrievalModule':\nValueError('Image and molecule encoders must have the same output dimension. Got 512 and 256.')\nfull_key: eval.idr_graph_retrieval.model"
     ]
    }
   ],
   "source": [
    "for key in cfg.eval:\n",
    "    evaluator = utils.instantiate_evaluator(\n",
    "        cfg.eval[key],\n",
    "        model_cfg=cfg.model,\n",
    "        logger=None,\n",
    "        ckpt_path=cfg.ckpt_path,\n",
    "    )\n",
    "\n",
    "    # try:\n",
    "    #     evaluator.run()\n",
    "    # except Exception as e:\n",
    "    #     log.error(f\"Error while running {evaluator}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gin_supervised_infomax_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_infomax.pth...\n",
      "Pretrained model loaded\n"
     ]
    }
   ],
   "source": [
    "datamodule = IDRRetrievalDataModule(\n",
    "    selected_compounds_path=\"../cpjump1/excape-db/selected_compounds.csv\",\n",
    "    image_metadata_path=\"../cpjump1/idr0033-rohban-pathways/processed_metadata.csv\",\n",
    "    data_root_dir=\"../cpjump1/screen_1751\",\n",
    "    image_batch_size=8,\n",
    "    compound_batch_size=8,\n",
    "    num_workers=8,\n",
    "    pin_memory=False,\n",
    "    prefetch_factor=3,\n",
    "    compound_transform=DGLPretrainedFromSmiles(),\n",
    "    transform=DefaultJUMPTransform(size=256),\n",
    "    compound_gene_col=\"Gene_Symbol\",\n",
    "    image_gene_col=\"Gene Symbol\",\n",
    "    col_fstring=\"FileName_{channel}\",\n",
    "    channels=None,\n",
    "    target_col=\"Activity_Flag\",\n",
    "    smiles_col=\"SMILES\",\n",
    "    use_cache=False,\n",
    "    mol_collate_fn=None,\n",
    "    img_collate_fn=None,\n",
    ")\n",
    "\n",
    "image_encoder = CNNEncoder(\"resnet18\", target_num=128)\n",
    "molecule_encoder = GINPretrainedWithLinearHead(\"gin_supervised_infomax\", out_dim=128)\n",
    "\n",
    "idr_model = IDRRetrievalModule(\n",
    "    image_encoder=image_encoder,\n",
    "    molecule_encoder=molecule_encoder,\n",
    "    example_input_path=\"../cpjump1/jump/models/eval/test/example.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idr_model = IDRRetrievalModule(\n",
    "    image_encoder=image_encoder,\n",
    "    molecule_encoder=molecule_encoder,\n",
    "    example_input_path=\"../cpjump1/jump/models/eval/test/example.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator=\"gpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06db0f8688d4b92853ad42d6a26f506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = trainer.predict(idr_model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = datamodule.predict_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_from_list_of_dict(res, key):\n",
    "    return torch.cat([r[key] for r in res], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174d27d925d0421f974ecc20c4db2439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde7a6c16d5f44ca8006416b20144625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5426723d0ba34098a749588d14ebb9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed29d2356824dfc901939991368300a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d624e5e28d36419a9bf9eecc0df9f9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730a256b17024bfabc92d3a197c9f8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbaf76f4810422e92a3cbd9275adc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738f7ab33cd74364989b3a69bc342127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c07b041b81d414a86b67ea5395d5289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4f44b134314f0d8fef941dae9d85b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e9d4e53fd49b885c058db6e0f811a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118634dbb41a4f47a595f5f78e2605dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_metrics = {}\n",
    "for gene in dl:\n",
    "    compound_emb = trainer.predict(idr_model, dl[gene][\"molecule\"])\n",
    "    activities = concat_from_list_of_dict(compound_emb, \"activity_flag\")\n",
    "    compound_emb = concat_from_list_of_dict(compound_emb, \"compound\")\n",
    "\n",
    "    image_emb = trainer.predict(idr_model, dl[gene][\"image\"])\n",
    "    image_emb = concat_from_list_of_dict(image_emb, \"image\")\n",
    "\n",
    "    gene_metrics = idr_model.retrieval(\n",
    "        image_embeddings=image_emb, compound_embeddings=compound_emb, activities=activities\n",
    "    )\n",
    "\n",
    "    out_metrics[gene] = gene_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.loggers[0].log_metrics(out_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.loggers.wandb.WandbLogger at 0x7f39eb9bf010>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_logger.log_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = defaultdict(lambda: 0)\n",
    "for gene in out_metrics:\n",
    "    for metric in out_metrics[gene]:\n",
    "        mean_metrics[metric] += out_metrics[gene][metric] / len(out_metrics)\n",
    "\n",
    "mean_metrics = dict(mean_metrics)\n",
    "for metric in mean_metrics:\n",
    "    mean_metrics[metric] = float(mean_metrics[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "idr_model.to(device)\n",
    "idr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, molecule_activities = idr_model.get_distance_matrix(\n",
    "    image_dataloader=img_dataloader, molecule_dataloader=mol_dataloader, max_num_batches=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_metrics = MetricCollection(\n",
    "    {\n",
    "        \"RetrievalMRR\": RetrievalMRR(),\n",
    "        \"RetrievalHitRate_top_1\": RetrievalHitRate(top_k=1),\n",
    "        \"RetrievalHitRate_top_3\": RetrievalHitRate(top_k=3),\n",
    "        \"RetrievalHitRate_top_5\": RetrievalHitRate(top_k=5),\n",
    "        \"RetrievalHitRate_top_10\": RetrievalHitRate(top_k=10),\n",
    "        \"RetrievalFallOut_top_5\": RetrievalFallOut(top_k=5),\n",
    "        \"RetrievalMAP_top_5\": RetrievalMAP(top_k=5),\n",
    "        \"RetrievalPrecision_top_5\": RetrievalPrecision(top_k=5),\n",
    "        \"RetrievalNormalizedDCG\": RetrievalNormalizedDCG(),\n",
    "        # \"RetrievalRPrecision\": RetrievalRPrecision()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0018,  0.0432,  0.0789,  ...,  0.0255,  0.0430,  0.0028],\n",
       "        [-0.0261, -0.0429, -0.0069,  ..., -0.0523, -0.0571, -0.0432],\n",
       "        [ 0.0019,  0.0239,  0.0101,  ...,  0.0945,  0.0225,  0.0465],\n",
       "        ...,\n",
       "        [ 0.1606,  0.0905,  0.1849,  ...,  0.1315,  0.1821,  0.1393],\n",
       "        [ 0.1091,  0.0410,  0.0730,  ...,  0.1198,  0.1352,  0.0692],\n",
       "        [ 0.1708,  0.1863,  0.2509,  ...,  0.1794,  0.2304,  0.2223]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh3 = RetrievalHitRate(top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = torch.arange(dist.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RetrievalFallOut_top_5': tensor(0.0495),\n",
       " 'RetrievalHitRate_top_1': tensor(0.0270),\n",
       " 'RetrievalHitRate_top_10': tensor(0.7838),\n",
       " 'RetrievalHitRate_top_5': tensor(0.2703),\n",
       " 'RetrievalMAP_top_5': tensor(0.1083),\n",
       " 'RetrievalMRR': tensor(0.1887),\n",
       " 'RetrievalNormalizedDCG': tensor(0.5436),\n",
       " 'RetrievalPrecision_top_5': tensor(0.0595)}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_metrics(preds=dist, target=molecule_activities.expand(dist.T.shape).T, indexes=indexes.expand(dist.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:69: FutureWarning: Importing `retrieval_hit_rate` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `retrieval_hit_rate` from `torchmetrics.retrieval` instead.\n",
      "  _future_warning(\n"
     ]
    }
   ],
   "source": [
    "rhs = []\n",
    "for i in range(37):\n",
    "    rhs.append(retrieval_hit_rate(preds=dist[:, i], target=molecule_activities, top_k=4).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_id = sorted(range(dist.shape[0]), key=lambda x: dist[x, i], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2223,  0.2065,  0.1724,  0.1472,  0.1469,  0.1406,  0.1393,  0.1358,\n",
       "         0.1271,  0.1198,  0.1185,  0.1169,  0.1123,  0.1114,  0.1094,  0.1046,\n",
       "         0.1027,  0.0972,  0.0968,  0.0966,  0.0917,  0.0916,  0.0883,  0.0880,\n",
       "         0.0878,  0.0871,  0.0792,  0.0785,  0.0779,  0.0757,  0.0723,  0.0703,\n",
       "         0.0699,  0.0697,  0.0692,  0.0641,  0.0639,  0.0597,  0.0589,  0.0586,\n",
       "         0.0567,  0.0559,  0.0546,  0.0520,  0.0486,  0.0480,  0.0476,  0.0468,\n",
       "         0.0465,  0.0451,  0.0436,  0.0433,  0.0413,  0.0387,  0.0380,  0.0367,\n",
       "         0.0353,  0.0352,  0.0343,  0.0328,  0.0326,  0.0323,  0.0263,  0.0253,\n",
       "         0.0239,  0.0195,  0.0178,  0.0152,  0.0147,  0.0133,  0.0124,  0.0120,\n",
       "         0.0082,  0.0028,  0.0026, -0.0012, -0.0025, -0.0037, -0.0069, -0.0101,\n",
       "        -0.0131, -0.0139, -0.0144, -0.0178, -0.0211, -0.0214, -0.0223, -0.0233,\n",
       "        -0.0235, -0.0309, -0.0333, -0.0344, -0.0385, -0.0393, -0.0414, -0.0432,\n",
       "        -0.0481, -0.0482, -0.0544, -0.0569, -0.0576, -0.0639, -0.0657, -0.0676,\n",
       "        -0.0701, -0.0720, -0.0726, -0.0785, -0.0788, -0.0820, -0.0931, -0.0936,\n",
       "        -0.1075, -0.1090, -0.1143, -0.1147, -0.1241, -0.1350, -0.1463, -0.1763])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[sorted_id, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecule_activities[sorted_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2702702702702703"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (dict, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m idr_model\u001b[39m.\u001b[39;49mget_distance_matrix(image_dataloader\u001b[39m=\u001b[39;49mimg_dataloader, molecule_dataloader\u001b[39m=\u001b[39;49mmol_dataloader, max_num_batches\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/eval/retrieval/module.py:65\u001b[0m, in \u001b[0;36mIDRRetrievalModule.get_distance_matrix\u001b[0;34m(self, image_dataloader, molecule_dataloader, max_num_batches)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m max_num_batches \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_num_batches:\n\u001b[1;32m     64\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     image_embeddings\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_encoder(image_batch)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m i, molecule_batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(molecule_dataloader):\n\u001b[1;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m max_num_batches \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_num_batches:\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/modules/images/timm_pretrained.py:132\u001b[0m, in \u001b[0;36mCNNEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 132\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(x)\n\u001b[1;32m    133\u001b[0m     re \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection_head(x)\n\u001b[1;32m    134\u001b[0m     \u001b[39mreturn\u001b[39;00m re\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/timm/models/resnet.py:541\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 541\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_features(x)\n\u001b[1;32m    542\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_head(x)\n\u001b[1;32m    543\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/timm/models/resnet.py:520\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_features\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 520\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    521\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    522\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact1(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (dict, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n"
     ]
    }
   ],
   "source": [
    "idr_model.get_distance_matrix(image_dataloader=img_dataloader, molecule_dataloader=mol_dataloader, max_num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRCA1': IDRRetrievalImageDataset(n_images=37),\n",
       " 'HIF1A': IDRRetrievalImageDataset(n_images=83),\n",
       " 'HSPA5': IDRRetrievalImageDataset(n_images=45),\n",
       " 'JUN': IDRRetrievalImageDataset(n_images=87),\n",
       " 'STAT3': IDRRetrievalImageDataset(n_images=123),\n",
       " 'TP53': IDRRetrievalImageDataset(n_images=88)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.test_image_datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
