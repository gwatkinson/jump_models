{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop the IDR retrieval evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.functional import pairwise_cosine_similarity, retrieval_hit_rate\n",
    "from torchmetrics.retrieval import (\n",
    "    RetrievalFallOut,\n",
    "    RetrievalHitRate,\n",
    "    RetrievalMAP,\n",
    "    RetrievalMRR,\n",
    "    RetrievalNormalizedDCG,\n",
    "    RetrievalPrecision,\n",
    "    RetrievalRPrecision,\n",
    ")\n",
    "\n",
    "from src.eval.retrieval import IDRRetrievalDataModule, IDRRetrievalEvaluator, IDRRetrievalModule\n",
    "from src.modules.compound_transforms import DGLPretrainedFromSmiles\n",
    "from src.modules.images import CNNEncoder\n",
    "from src.modules.molecules import GINPretrainedWithLinearHead\n",
    "from src.modules.transforms import DefaultJUMPTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpjump1 already mounted.\n",
      "cpjump2 already mounted.\n",
      "cpjump3 already mounted.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    if not Path(f\"../cpjump{i}/jump/\").exists():\n",
    "        print(f\"Mounting cpjump{i}...\")\n",
    "        os.system(f\"sshfs bioclust:/projects/cpjump{i}/ ../cpjump{i}\")\n",
    "    else:\n",
    "        print(f\"cpjump{i} already mounted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading gin_supervised_infomax_pre_trained.pth from https://data.dgl.ai/dgllife/pre_trained/gin_supervised_infomax.pth...\n",
      "Pretrained model loaded\n"
     ]
    }
   ],
   "source": [
    "datamodule = IDRRetrievalDataModule(\n",
    "    selected_compounds_path=\"../cpjump1/excape-db/selected_compounds.csv\",\n",
    "    image_metadata_path=\"../cpjump1/idr0033-rohban-pathways/processed_metadata.csv\",\n",
    "    data_root_dir=\"../cpjump1/screen_1751\",\n",
    "    image_batch_size=8,\n",
    "    compound_batch_size=8,\n",
    "    num_workers=8,\n",
    "    pin_memory=False,\n",
    "    prefetch_factor=3,\n",
    "    compound_transform=DGLPretrainedFromSmiles(),\n",
    "    transform=DefaultJUMPTransform(size=256),\n",
    "    compound_gene_col=\"Gene_Symbol\",\n",
    "    image_gene_col=\"Gene Symbol\",\n",
    "    col_fstring=\"FileName_{channel}\",\n",
    "    channels=None,\n",
    "    target_col=\"Activity_Flag\",\n",
    "    smiles_col=\"SMILES\",\n",
    "    use_cache=False,\n",
    "    mol_collate_fn=None,\n",
    "    img_collate_fn=None,\n",
    ")\n",
    "\n",
    "image_encoder = CNNEncoder(\"resnet18\", target_num=128)\n",
    "molecule_encoder = GINPretrainedWithLinearHead(\"gin_supervised_infomax\", out_dim=128)\n",
    "\n",
    "idr_model = IDRRetrievalModule(\n",
    "    image_encoder=image_encoder,\n",
    "    molecule_encoder=molecule_encoder,\n",
    "    example_input_path=\"../cpjump1/jump/models/eval/test/example.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idr_model = IDRRetrievalModule(\n",
    "    image_encoder=image_encoder,\n",
    "    molecule_encoder=molecule_encoder,\n",
    "    example_input_path=\"../cpjump1/jump/models/eval/test/example.pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(accelerator=\"gpu\", devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06db0f8688d4b92853ad42d6a26f506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = trainer.predict(idr_model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.prepare_data()\n",
    "datamodule.setup(\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = datamodule.predict_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_from_list_of_dict(res, key):\n",
    "    return torch.cat([r[key] for r in res], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174d27d925d0421f974ecc20c4db2439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde7a6c16d5f44ca8006416b20144625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5426723d0ba34098a749588d14ebb9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed29d2356824dfc901939991368300a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d624e5e28d36419a9bf9eecc0df9f9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730a256b17024bfabc92d3a197c9f8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbaf76f4810422e92a3cbd9275adc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738f7ab33cd74364989b3a69bc342127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c07b041b81d414a86b67ea5395d5289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4f44b134314f0d8fef941dae9d85b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e9d4e53fd49b885c058db6e0f811a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118634dbb41a4f47a595f5f78e2605dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out_metrics = {}\n",
    "for gene in dl:\n",
    "    compound_emb = trainer.predict(idr_model, dl[gene][\"molecule\"])\n",
    "    activities = concat_from_list_of_dict(compound_emb, \"activity_flag\")\n",
    "    compound_emb = concat_from_list_of_dict(compound_emb, \"compound\")\n",
    "\n",
    "    image_emb = trainer.predict(idr_model, dl[gene][\"image\"])\n",
    "    image_emb = concat_from_list_of_dict(image_emb, \"image\")\n",
    "\n",
    "    gene_metrics = idr_model.retrieval(\n",
    "        image_embeddings=image_emb, compound_embeddings=compound_emb, activities=activities\n",
    "    )\n",
    "\n",
    "    out_metrics[gene] = gene_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.loggers[0].log_metrics(out_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/lightning/pytorch/loggers/wandb.py:396: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightning.pytorch.loggers.wandb.WandbLogger at 0x7f39eb9bf010>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb_logger.log_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = defaultdict(lambda: 0)\n",
    "for gene in out_metrics:\n",
    "    for metric in out_metrics[gene]:\n",
    "        mean_metrics[metric] += out_metrics[gene][metric] / len(out_metrics)\n",
    "\n",
    "mean_metrics = dict(mean_metrics)\n",
    "for metric in mean_metrics:\n",
    "    mean_metrics[metric] = float(mean_metrics[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "idr_model.to(device)\n",
    "idr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, molecule_activities = idr_model.get_distance_matrix(\n",
    "    image_dataloader=img_dataloader, molecule_dataloader=mol_dataloader, max_num_batches=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_metrics = MetricCollection(\n",
    "    {\n",
    "        \"RetrievalMRR\": RetrievalMRR(),\n",
    "        \"RetrievalHitRate_top_1\": RetrievalHitRate(top_k=1),\n",
    "        \"RetrievalHitRate_top_3\": RetrievalHitRate(top_k=3),\n",
    "        \"RetrievalHitRate_top_5\": RetrievalHitRate(top_k=5),\n",
    "        \"RetrievalHitRate_top_10\": RetrievalHitRate(top_k=10),\n",
    "        \"RetrievalFallOut_top_5\": RetrievalFallOut(top_k=5),\n",
    "        \"RetrievalMAP_top_5\": RetrievalMAP(top_k=5),\n",
    "        \"RetrievalPrecision_top_5\": RetrievalPrecision(top_k=5),\n",
    "        \"RetrievalNormalizedDCG\": RetrievalNormalizedDCG(),\n",
    "        # \"RetrievalRPrecision\": RetrievalRPrecision()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0018,  0.0432,  0.0789,  ...,  0.0255,  0.0430,  0.0028],\n",
       "        [-0.0261, -0.0429, -0.0069,  ..., -0.0523, -0.0571, -0.0432],\n",
       "        [ 0.0019,  0.0239,  0.0101,  ...,  0.0945,  0.0225,  0.0465],\n",
       "        ...,\n",
       "        [ 0.1606,  0.0905,  0.1849,  ...,  0.1315,  0.1821,  0.1393],\n",
       "        [ 0.1091,  0.0410,  0.0730,  ...,  0.1198,  0.1352,  0.0692],\n",
       "        [ 0.1708,  0.1863,  0.2509,  ...,  0.1794,  0.2304,  0.2223]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh3 = RetrievalHitRate(top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = torch.arange(dist.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RetrievalFallOut_top_5': tensor(0.0495),\n",
       " 'RetrievalHitRate_top_1': tensor(0.0270),\n",
       " 'RetrievalHitRate_top_10': tensor(0.7838),\n",
       " 'RetrievalHitRate_top_5': tensor(0.2703),\n",
       " 'RetrievalMAP_top_5': tensor(0.1083),\n",
       " 'RetrievalMRR': tensor(0.1887),\n",
       " 'RetrievalNormalizedDCG': tensor(0.5436),\n",
       " 'RetrievalPrecision_top_5': tensor(0.0595)}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_metrics(preds=dist, target=molecule_activities.expand(dist.T.shape).T, indexes=indexes.expand(dist.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:69: FutureWarning: Importing `retrieval_hit_rate` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `retrieval_hit_rate` from `torchmetrics.retrieval` instead.\n",
      "  _future_warning(\n"
     ]
    }
   ],
   "source": [
    "rhs = []\n",
    "for i in range(37):\n",
    "    rhs.append(retrieval_hit_rate(preds=dist[:, i], target=molecule_activities, top_k=4).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_id = sorted(range(dist.shape[0]), key=lambda x: dist[x, i], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2223,  0.2065,  0.1724,  0.1472,  0.1469,  0.1406,  0.1393,  0.1358,\n",
       "         0.1271,  0.1198,  0.1185,  0.1169,  0.1123,  0.1114,  0.1094,  0.1046,\n",
       "         0.1027,  0.0972,  0.0968,  0.0966,  0.0917,  0.0916,  0.0883,  0.0880,\n",
       "         0.0878,  0.0871,  0.0792,  0.0785,  0.0779,  0.0757,  0.0723,  0.0703,\n",
       "         0.0699,  0.0697,  0.0692,  0.0641,  0.0639,  0.0597,  0.0589,  0.0586,\n",
       "         0.0567,  0.0559,  0.0546,  0.0520,  0.0486,  0.0480,  0.0476,  0.0468,\n",
       "         0.0465,  0.0451,  0.0436,  0.0433,  0.0413,  0.0387,  0.0380,  0.0367,\n",
       "         0.0353,  0.0352,  0.0343,  0.0328,  0.0326,  0.0323,  0.0263,  0.0253,\n",
       "         0.0239,  0.0195,  0.0178,  0.0152,  0.0147,  0.0133,  0.0124,  0.0120,\n",
       "         0.0082,  0.0028,  0.0026, -0.0012, -0.0025, -0.0037, -0.0069, -0.0101,\n",
       "        -0.0131, -0.0139, -0.0144, -0.0178, -0.0211, -0.0214, -0.0223, -0.0233,\n",
       "        -0.0235, -0.0309, -0.0333, -0.0344, -0.0385, -0.0393, -0.0414, -0.0432,\n",
       "        -0.0481, -0.0482, -0.0544, -0.0569, -0.0576, -0.0639, -0.0657, -0.0676,\n",
       "        -0.0701, -0.0720, -0.0726, -0.0785, -0.0788, -0.0820, -0.0931, -0.0936,\n",
       "        -0.1075, -0.1090, -0.1143, -0.1147, -0.1241, -0.1350, -0.1463, -0.1763])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist[sorted_id, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "molecule_activities[sorted_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2702702702702703"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (dict, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m idr_model\u001b[39m.\u001b[39;49mget_distance_matrix(image_dataloader\u001b[39m=\u001b[39;49mimg_dataloader, molecule_dataloader\u001b[39m=\u001b[39;49mmol_dataloader, max_num_batches\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/eval/retrieval/module.py:65\u001b[0m, in \u001b[0;36mIDRRetrievalModule.get_distance_matrix\u001b[0;34m(self, image_dataloader, molecule_dataloader, max_num_batches)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m max_num_batches \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_num_batches:\n\u001b[1;32m     64\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     image_embeddings\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_encoder(image_batch)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m i, molecule_batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(molecule_dataloader):\n\u001b[1;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m max_num_batches \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m max_num_batches:\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/modules/images/timm_pretrained.py:132\u001b[0m, in \u001b[0;36mCNNEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 132\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone(x)\n\u001b[1;32m    133\u001b[0m     re \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection_head(x)\n\u001b[1;32m    134\u001b[0m     \u001b[39mreturn\u001b[39;00m re\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/timm/models/resnet.py:541\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 541\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_features(x)\n\u001b[1;32m    542\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_head(x)\n\u001b[1;32m    543\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/timm/models/resnet.py:520\u001b[0m, in \u001b[0;36mResNet.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_features\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 520\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    521\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    522\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mact1(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (dict, Parameter, NoneType, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!dict!, !Parameter!, !NoneType!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, int)\n"
     ]
    }
   ],
   "source": [
    "idr_model.get_distance_matrix(image_dataloader=img_dataloader, molecule_dataloader=mol_dataloader, max_num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRCA1': IDRRetrievalImageDataset(n_images=37),\n",
       " 'HIF1A': IDRRetrievalImageDataset(n_images=83),\n",
       " 'HSPA5': IDRRetrievalImageDataset(n_images=45),\n",
       " 'JUN': IDRRetrievalImageDataset(n_images=87),\n",
       " 'STAT3': IDRRetrievalImageDataset(n_images=123),\n",
       " 'TP53': IDRRetrievalImageDataset(n_images=88)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule.test_image_datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
