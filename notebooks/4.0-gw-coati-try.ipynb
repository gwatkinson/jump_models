{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COATI NLP model for encoding molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "\n",
    "from src.coati.models.io import load_e3gnn_smiles_clip_e2e\n",
    "from src.modules.collate_fn import default_collate\n",
    "from src.modules.losses import InfoNCE\n",
    "from src.modules.molecules.coati import COATI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpjump1 already mounted.\n",
      "cpjump2 already mounted.\n",
      "cpjump3 already mounted.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    if not Path(f\"../cpjump{i}/jump/\").exists():\n",
    "        print(f\"Mounting cpjump{i}...\")\n",
    "        os.system(f\"sshfs bioclust:/projects/cpjump{i}/ ../cpjump{i}\")\n",
    "    else:\n",
    "        print(f\"cpjump{i} already mounted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developping the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = [\n",
    "    \"CC1CC2=CCOC2O1\",\n",
    "    \"OC1CC1(O)CC1CC1\",\n",
    "    \"CC1N2C=NCC12C#C\",\n",
    "    \"CC1COC11C(O)C1O\",\n",
    "    \"CC12OCC(CO1)C2=O\",\n",
    "    \"CC12CC(CO1)CC2=O\",\n",
    "    \"CCN=COC\",\n",
    "    \"CC1(CO)CO1\",\n",
    "    \"C(C#N)C(=O)N\",\n",
    "    \"CC(=O)OC=N\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from s3://terray-public/models/grande_closed.pkl\n",
      "Loading tokenizer may_closedparen from s3://terray-public/models/grande_closed.pkl\n",
      "number of parameters: 12.64M\n",
      "number of parameters Total: 2.44M xformer: 17.92M Total: 20.36M \n",
      "vocab_name not found in tokenizer_vocabs, trying to load from file\n"
     ]
    }
   ],
   "source": [
    "model = COATI(\n",
    "    pretrained_name=\"grande_closed\",\n",
    "    out_dim=128,\n",
    "    padding_length=250,\n",
    "    freeze=False,\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/4.0-gw-coati-try.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/notebooks/4.0-gw-coati-try.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model(smiles)\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/modules/molecules/coati.py:102\u001b[0m, in \u001b[0;36mCOATI.forward\u001b[0;34m(self, smiles, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice:\n\u001b[1;32m    100\u001b[0m     tokens \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 102\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract(tokens)\n\u001b[1;32m    103\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprojection_head(z)\n\u001b[1;32m    104\u001b[0m \u001b[39mreturn\u001b[39;00m z\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/modules/molecules/coati.py:94\u001b[0m, in \u001b[0;36mCOATI.extract\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackbone\u001b[39m.\u001b[39;49mencode(idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenizer)\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/coati/models/encoding/smiles_xformer.py:102\u001b[0m, in \u001b[0;36mRotarySmilesTransformer.encode\u001b[0;34m(self, idx, tokenizer)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, idx, tokenizer):\n\u001b[1;32m    100\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only returns the vector of the [STOP] token which MUST be the last\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[39m    token before [PAD]\"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxformer(idx)\n\u001b[1;32m    103\u001b[0m     \u001b[39mreturn\u001b[39;00m get_stop_token_embs(x, idx, tokenizer)\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/coati/models/encoding/smiles_xformer.py:319\u001b[0m, in \u001b[0;36mRotarySmilesTransformer.xformer\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    317\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39memb(idx)\n\u001b[1;32m    318\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mh:\n\u001b[0;32m--> 319\u001b[0m     x \u001b[39m=\u001b[39m block(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memb)\n\u001b[1;32m    320\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer\u001b[39m.\u001b[39mln_f(x)\n\u001b[1;32m    321\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/coati/models/encoding/basic_transformer.py:143\u001b[0m, in \u001b[0;36mRotaryBlock.forward\u001b[0;34m(self, x, rotary_embedding)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, rotary_embedding: RotaryEmbedding):\n\u001b[0;32m--> 143\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln_1(x), rotary_embedding)\n\u001b[1;32m    144\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlpf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_2(x))\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/jump_models/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/coati/models/encoding/basic_transformer.py:118\u001b[0m, in \u001b[0;36mRotarySelfAttention.forward\u001b[0;34m(self, x, rotary_embedding)\u001b[0m\n\u001b[1;32m    116\u001b[0m q, k \u001b[39m=\u001b[39m rotary_embedding\u001b[39m.\u001b[39mrotary_embed(q, k)\n\u001b[1;32m    117\u001b[0m \u001b[39m# causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m att \u001b[39m=\u001b[39m (q \u001b[39m@\u001b[39m k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m*\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(k\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)))\n\u001b[1;32m    119\u001b[0m att \u001b[39m=\u001b[39m att\u001b[39m.\u001b[39mmasked_fill(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias[:, :, :T, :T] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mfloat\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-inf\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    120\u001b[0m att \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39msoftmax(att, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model(smiles).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from s3://terray-public/models/grande_closed.pkl\n",
      "Loading tokenizer may_closedparen from s3://terray-public/models/grande_closed.pkl\n",
      "number of parameters: 12.64M\n",
      "number of parameters Total: 2.44M xformer: 17.92M Total: 20.36M \n",
      "vocab_name not found in tokenizer_vocabs, trying to load from file\n"
     ]
    }
   ],
   "source": [
    "encoder, tokenizer = load_e3gnn_smiles_clip_e2e(\n",
    "    # model parameters to load.\n",
    "    doc_url=\"s3://terray-public/models/grande_closed.pkl\",\n",
    "    freeze=False,\n",
    "    # device=torch.device(\"cpu\"),\n",
    "    # print_debug=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[PAD]': 0,\n",
       " '[STOP]': 1,\n",
       " '[SMILES]': 2,\n",
       " '[MASK]': 3,\n",
       " '[PREFIX]': 4,\n",
       " '[SUFFIX]': 5,\n",
       " '[MIDDLE]': 6,\n",
       " '[UNK]': 7,\n",
       " '[CLIP]': 8,\n",
       " '[FORMULA]': 9,\n",
       " '[GRAPH]': 10,\n",
       " '[EDGES]': 11,\n",
       " '[EDGE1]': 12,\n",
       " '[EDGEC]': 13,\n",
       " '[EDGE2]': 14,\n",
       " '[EDGE3]': 15,\n",
       " '[SET]': 16,\n",
       " '[ISOMORPHIC]': 17,\n",
       " '[VALID]': 18,\n",
       " '[TRUE]': 19,\n",
       " '[FALSE]': 20,\n",
       " '[geom_drugs]': 21,\n",
       " '[mcule]': 22,\n",
       " '[tspace_real]': 23,\n",
       " '[tensormol]': 24,\n",
       " '[chembl_mols]': 25,\n",
       " '[bbspace]': 26,\n",
       " '[zinc22]': 27,\n",
       " '[tspace_enum]': 28,\n",
       " '[ELM1]': 29,\n",
       " '[ELM2]': 30,\n",
       " '[ELM3]': 31,\n",
       " '[ELM4]': 32,\n",
       " '[ELM5]': 33,\n",
       " '[ELM6]': 34,\n",
       " '[ELM7]': 35,\n",
       " '[ELM8]': 36,\n",
       " '[ELM9]': 37,\n",
       " '[ELM10]': 38,\n",
       " '[ELM11]': 39,\n",
       " '[ELM12]': 40,\n",
       " '[ELM13]': 41,\n",
       " '[ELM14]': 42,\n",
       " '[ELM15]': 43,\n",
       " '[ELM16]': 44,\n",
       " '[ELM17]': 45,\n",
       " '[ELM18]': 46,\n",
       " '[ELM19]': 47,\n",
       " '[ELM20]': 48,\n",
       " '[ELM21]': 49,\n",
       " '[ELM22]': 50,\n",
       " '[ELM23]': 51,\n",
       " '[ELM24]': 52,\n",
       " '[ELM25]': 53,\n",
       " '[ELM26]': 54,\n",
       " '[ELM27]': 55,\n",
       " '[ELM28]': 56,\n",
       " '[ELM29]': 57,\n",
       " '[ELM30]': 58,\n",
       " '[ELM31]': 59,\n",
       " '[ELM32]': 60,\n",
       " '[ELM33]': 61,\n",
       " '[ELM34]': 62,\n",
       " '[ELM35]': 63,\n",
       " '[ELM36]': 64,\n",
       " '[ELM37]': 65,\n",
       " '[ELM38]': 66,\n",
       " '[ELM39]': 67,\n",
       " '[ELM40]': 68,\n",
       " '[ELM41]': 69,\n",
       " '[ELM42]': 70,\n",
       " '[ELM43]': 71,\n",
       " '[ELM44]': 72,\n",
       " '[ELM45]': 73,\n",
       " '[ELM46]': 74,\n",
       " '[ELM47]': 75,\n",
       " '[ELM48]': 76,\n",
       " '[ELM49]': 77,\n",
       " '[ELM50]': 78,\n",
       " '[ELM51]': 79,\n",
       " '[ELM52]': 80,\n",
       " '[ELM53]': 81,\n",
       " '[ELM54]': 82,\n",
       " '[ELM55]': 83,\n",
       " '[ELM56]': 84,\n",
       " '[ELM57]': 85,\n",
       " '[ELM58]': 86,\n",
       " '[ELM59]': 87,\n",
       " '[ELM60]': 88,\n",
       " '[ELM61]': 89,\n",
       " '[ELM62]': 90,\n",
       " '[ELM63]': 91,\n",
       " '[ELM64]': 92,\n",
       " '[ELM65]': 93,\n",
       " '[ELM66]': 94,\n",
       " '[ELM67]': 95,\n",
       " '[ELM68]': 96,\n",
       " '[ELM69]': 97,\n",
       " '[ELM70]': 98,\n",
       " '[ELM71]': 99,\n",
       " '[ELM72]': 100,\n",
       " '[ELM73]': 101,\n",
       " '[ELM74]': 102,\n",
       " '[ELM75]': 103,\n",
       " '[ELM76]': 104,\n",
       " '[ELM77]': 105,\n",
       " '[ELM78]': 106,\n",
       " '[ELM79]': 107,\n",
       " '[ELM80]': 108,\n",
       " '[ELM81]': 109,\n",
       " '[ELM82]': 110,\n",
       " '[ELM83]': 111,\n",
       " '[NUM0]': 112,\n",
       " '[NUM1]': 113,\n",
       " '[NUM2]': 114,\n",
       " '[NUM3]': 115,\n",
       " '[NUM4]': 116,\n",
       " '[NUM5]': 117,\n",
       " '[NUM6]': 118,\n",
       " '[NUM7]': 119,\n",
       " '[NUM8]': 120,\n",
       " '[NUM9]': 121,\n",
       " '[NUM10]': 122,\n",
       " '[NUM11]': 123,\n",
       " '[NUM12]': 124,\n",
       " '[NUM13]': 125,\n",
       " '[NUM14]': 126,\n",
       " '[NUM15]': 127,\n",
       " '[NUM16]': 128,\n",
       " '[NUM17]': 129,\n",
       " '[NUM18]': 130,\n",
       " '[NUM19]': 131,\n",
       " '[NUM20]': 132,\n",
       " '[NUM21]': 133,\n",
       " '[NUM22]': 134,\n",
       " '[NUM23]': 135,\n",
       " '[NUM24]': 136,\n",
       " '[NUM25]': 137,\n",
       " '[NUM26]': 138,\n",
       " '[NUM27]': 139,\n",
       " '[NUM28]': 140,\n",
       " '[NUM29]': 141,\n",
       " '[NUM30]': 142,\n",
       " '[NUM31]': 143,\n",
       " '[NUM32]': 144,\n",
       " '[NUM33]': 145,\n",
       " '[NUM34]': 146,\n",
       " '[NUM35]': 147,\n",
       " '[NUM36]': 148,\n",
       " '[NUM37]': 149,\n",
       " '[NUM38]': 150,\n",
       " '[NUM39]': 151,\n",
       " '[NUM40]': 152,\n",
       " '[NUM41]': 153,\n",
       " '[NUM42]': 154,\n",
       " '[NUM43]': 155,\n",
       " '[NUM44]': 156,\n",
       " '[NUM45]': 157,\n",
       " '[NUM46]': 158,\n",
       " '[NUM47]': 159,\n",
       " '[NUM48]': 160,\n",
       " '[NUM49]': 161,\n",
       " '[NUM50]': 162,\n",
       " '[NUM51]': 163,\n",
       " '[NUM52]': 164,\n",
       " '[NUM53]': 165,\n",
       " '[NUM54]': 166,\n",
       " '[NUM55]': 167,\n",
       " '[NUM56]': 168,\n",
       " '[NUM57]': 169,\n",
       " '[NUM58]': 170,\n",
       " '[NUM59]': 171,\n",
       " '[NUM60]': 172,\n",
       " '[NUM61]': 173,\n",
       " '[NUM62]': 174,\n",
       " '[NUM63]': 175,\n",
       " '[NUM64]': 176,\n",
       " '[NUM65]': 177,\n",
       " '[NUM66]': 178,\n",
       " '[NUM67]': 179,\n",
       " '[NUM68]': 180,\n",
       " '[NUM69]': 181,\n",
       " '[NUM70]': 182,\n",
       " '[NUM71]': 183,\n",
       " '[NUM72]': 184,\n",
       " '[NUM73]': 185,\n",
       " '[NUM74]': 186,\n",
       " '[NUM75]': 187,\n",
       " '[NUM76]': 188,\n",
       " '[NUM77]': 189,\n",
       " '[NUM78]': 190,\n",
       " '[NUM79]': 191,\n",
       " '[NUM80]': 192,\n",
       " '[NUM81]': 193,\n",
       " '[NUM82]': 194,\n",
       " '[NUM83]': 195,\n",
       " '[NUM84]': 196,\n",
       " '[NUM85]': 197,\n",
       " '[NUM86]': 198,\n",
       " '[NUM87]': 199,\n",
       " '[NUM88]': 200,\n",
       " '[NUM89]': 201,\n",
       " '[NUM90]': 202,\n",
       " '[NUM91]': 203,\n",
       " '[NUM92]': 204,\n",
       " '[NUM93]': 205,\n",
       " '[NUM94]': 206,\n",
       " '[NUM95]': 207,\n",
       " '[NUM96]': 208,\n",
       " '[NUM97]': 209,\n",
       " '[NUM98]': 210,\n",
       " '[NUM99]': 211,\n",
       " '[NUM100]': 212,\n",
       " '[NUM101]': 213,\n",
       " '[NUM102]': 214,\n",
       " '[NUM103]': 215,\n",
       " '[NUM104]': 216,\n",
       " '[NUM105]': 217,\n",
       " '[NUM106]': 218,\n",
       " '[NUM107]': 219,\n",
       " '[NUM108]': 220,\n",
       " '[NUM109]': 221,\n",
       " '[NUM110]': 222,\n",
       " '[NUM111]': 223,\n",
       " '[NUM112]': 224,\n",
       " '[NUM113]': 225,\n",
       " '[NUM114]': 226,\n",
       " '[NUM115]': 227,\n",
       " '[NUM116]': 228,\n",
       " '[NUM117]': 229,\n",
       " '[NUM118]': 230,\n",
       " '[NUM119]': 231,\n",
       " '[NUM120]': 232,\n",
       " '[NUM121]': 233,\n",
       " '[NUM122]': 234,\n",
       " '[NUM123]': 235,\n",
       " '[NUM124]': 236,\n",
       " '[NUM125]': 237,\n",
       " '[NUM126]': 238,\n",
       " '[NUM127]': 239,\n",
       " '[NUM128]': 240,\n",
       " '[NUM129]': 241,\n",
       " '[NUM130]': 242,\n",
       " '[NUM131]': 243,\n",
       " '[NUM132]': 244,\n",
       " '[NUM133]': 245,\n",
       " '[NUM134]': 246,\n",
       " '[NUM135]': 247,\n",
       " '[NUM136]': 248,\n",
       " '[NUM137]': 249,\n",
       " '[NUM138]': 250,\n",
       " '[NUM139]': 251,\n",
       " '[NUM140]': 252,\n",
       " '[NUM141]': 253,\n",
       " '[NUM142]': 254,\n",
       " '[NUM143]': 255,\n",
       " '[NUM144]': 256,\n",
       " '[NUM145]': 257,\n",
       " '[NUM146]': 258,\n",
       " '[NUM147]': 259,\n",
       " '[NUM148]': 260,\n",
       " '[NUM149]': 261,\n",
       " '[NUM150]': 262,\n",
       " '[ELM7][NUM5]': 263,\n",
       " '[ELM8][NUM4]': 264,\n",
       " '[ELM9][NUM1]': 265,\n",
       " '[ELM7][NUM3]': 266,\n",
       " '[ELM8][NUM3]': 267,\n",
       " '[ELM8][NUM2]': 268,\n",
       " '[ELM7][NUM6]': 269,\n",
       " '[ELM7][NUM1]': 270,\n",
       " '[SET][mcule]': 271,\n",
       " '[ELM7][NUM7]': 272,\n",
       " '[ELM7][NUM4]': 273,\n",
       " '[ELM9][NUM3]': 274,\n",
       " '[ELM8][NUM6]': 275,\n",
       " '[ELM8][NUM5]': 276,\n",
       " '[ELM8][NUM1]': 277,\n",
       " '[NUM1][ELM9]': 278,\n",
       " '[ELM7][NUM2]': 279,\n",
       " '[NUM0][NUM1]': 280,\n",
       " '[NUM1][NUM2]': 281,\n",
       " '[NUM2][NUM3]': 282,\n",
       " '[NUM3][NUM4]': 283,\n",
       " '[NUM4][NUM5]': 284,\n",
       " '[NUM6][NUM7]': 285,\n",
       " '[NUM7][NUM8]': 286,\n",
       " '[NUM8][NUM9]': 287,\n",
       " '[ELM9][NUM4]': 288,\n",
       " '[ELM9][NUM5]': 289,\n",
       " '[ELM9][NUM2]': 290,\n",
       " '[ELM7][NUM9]': 291,\n",
       " '[NUM5][NUM6]': 292,\n",
       " '[ELM8][NUM7]': 293,\n",
       " '[ELM9][NUM6]': 294,\n",
       " '[ELM7][NUM8]': 295,\n",
       " '[NUM3][NUM5]': 296,\n",
       " '[ELM8][NUM8]': 297,\n",
       " '[NUM6][NUM8]': 298,\n",
       " '[NUM2][NUM4]': 299,\n",
       " '[NUM1][NUM3]': 300,\n",
       " '[NUM7][NUM9]': 301,\n",
       " '[NUM2][NUM7]': 302,\n",
       " '[NUM4][NUM6]': 303,\n",
       " '[NUM5][NUM7]': 304,\n",
       " '[NUM1][NUM4]': 305,\n",
       " '[NUM1][NUM5]': 306,\n",
       " '[NUM3][NUM7]': 307,\n",
       " '[NUM2][NUM5]': 308,\n",
       " '[NUM6][NUM9]': 309,\n",
       " '[NUM1][NUM6]': 310,\n",
       " '[NUM1][NUM7]': 311,\n",
       " '[NUM2][NUM8]': 312,\n",
       " '[NUM1][NUM9]': 313,\n",
       " '[NUM3][NUM8]': 314,\n",
       " '[NUM4][NUM9]': 315,\n",
       " '[NUM5][NUM9]': 316,\n",
       " '[ELM9][NUM7]': 317,\n",
       " '[NUM4][NUM8]': 318,\n",
       " '[NUM3][NUM9]': 319,\n",
       " '[NUM5][NUM8]': 320,\n",
       " '[NUM2][NUM6]': 321,\n",
       " '[NUM4][NUM7]': 322,\n",
       " '[NUM1][NUM8]': 323,\n",
       " '[ELM8][NUM9]': 324,\n",
       " '[ELM9][NUM8]': 325,\n",
       " '[ELM6][NUM4]': 326,\n",
       " '[ELM6][NUM7]': 327,\n",
       " '[ELM6][NUM8]': 328,\n",
       " '[ELM6][NUM6]': 329,\n",
       " '[NUM3][NUM6]': 330,\n",
       " '[ELM9][NUM9]': 331,\n",
       " '[NUM23][ELM6]': 332,\n",
       " '[NUM17][ELM7]': 333,\n",
       " '[ELM16][NUM1]': 334,\n",
       " '[ELM17][NUM1]': 335,\n",
       " '[NUM19][ELM6]': 336,\n",
       " '[NUM21][ELM7]': 337,\n",
       " '[ELM17][NUM2]': 338,\n",
       " '[NUM22][ELM6]': 339,\n",
       " '[NUM20][ELM7]': 340,\n",
       " '[SET][zinc22]': 341,\n",
       " '[NUM19][ELM7]': 342,\n",
       " '[ELM35][NUM1]': 343,\n",
       " '[NUM21][ELM6]': 344,\n",
       " '[NUM18][ELM6]': 345,\n",
       " '[NUM9][NUM10]': 346,\n",
       " '[ELM16][NUM2]': 347,\n",
       " '[NUM18][ELM7]': 348,\n",
       " '[NUM22][ELM7]': 349,\n",
       " '[NUM16][ELM6]': 350,\n",
       " '[NUM17][ELM6]': 351,\n",
       " '[ELM15][NUM1]': 352,\n",
       " '[ELM17][NUM3]': 353,\n",
       " '[NUM20][ELM6]': 354,\n",
       " '[ELM14][NUM1]': 355,\n",
       " '[ELM16][NUM3]': 356,\n",
       " '[NUM8][NUM10]': 357,\n",
       " '[ELM53][NUM1]': 358,\n",
       " '[NUM19][ELM8]': 359,\n",
       " '[NUM22][ELM8]': 360,\n",
       " '[NUM6][NUM10]': 361,\n",
       " '[NUM7][NUM13]': 362,\n",
       " '[NUM5][NUM15]': 363,\n",
       " '[NUM8][NUM12]': 364,\n",
       " '[NUM8][NUM16]': 365,\n",
       " '[NUM8][NUM20]': 366,\n",
       " '[NUM5][NUM21]': 367,\n",
       " '[NUM1][NUM21]': 368,\n",
       " '[NUM9][NUM15]': 369,\n",
       " '[NUM20][ELM8]': 370,\n",
       " '[NUM2][NUM15]': 371,\n",
       " '[NUM9][NUM14]': 372,\n",
       " '[NUM1][NUM12]': 373,\n",
       " '[NUM6][NUM11]': 374,\n",
       " '[NUM4][NUM20]': 375,\n",
       " '[NUM4][NUM18]': 376,\n",
       " '[NUM1][NUM19]': 377,\n",
       " '[NUM6][NUM16]': 378,\n",
       " '[NUM9][NUM11]': 379,\n",
       " '[NUM7][NUM12]': 380,\n",
       " '[NUM18][ELM8]': 381,\n",
       " '[NUM7][NUM22]': 382,\n",
       " '[NUM4][NUM23]': 383,\n",
       " '[NUM6][NUM19]': 384,\n",
       " '[NUM3][NUM19]': 385,\n",
       " '[NUM1][NUM17]': 386,\n",
       " '[NUM2][NUM21]': 387,\n",
       " '[NUM9][NUM16]': 388,\n",
       " '[NUM7][NUM14]': 389,\n",
       " '[NUM7][NUM11]': 390,\n",
       " '[NUM1][NUM15]': 391,\n",
       " '[NUM5][NUM11]': 392,\n",
       " '[NUM6][NUM20]': 393,\n",
       " '[NUM5][NUM17]': 394,\n",
       " '[NUM5][NUM16]': 395,\n",
       " '[NUM7][NUM10]': 396,\n",
       " '[NUM5][NUM19]': 397,\n",
       " '[NUM9][NUM21]': 398,\n",
       " '[NUM6][NUM22]': 399,\n",
       " '[NUM2][NUM19]': 400,\n",
       " '[NUM3][NUM14]': 401,\n",
       " '[NUM2][NUM22]': 402,\n",
       " '[NUM5][NUM14]': 403,\n",
       " '[NUM5][NUM22]': 404,\n",
       " '[NUM8][NUM22]': 405,\n",
       " '[NUM9][NUM12]': 406,\n",
       " '[NUM8][NUM19]': 407,\n",
       " '[NUM4][NUM22]': 408,\n",
       " '[NUM5][NUM20]': 409,\n",
       " '[NUM8][NUM14]': 410,\n",
       " '[NUM1][NUM13]': 411,\n",
       " '[NUM1][NUM14]': 412,\n",
       " '[NUM7][NUM15]': 413,\n",
       " '[NUM8][NUM13]': 414,\n",
       " '[NUM7][NUM18]': 415,\n",
       " '[NUM9][NUM18]': 416,\n",
       " '[NUM6][NUM18]': 417,\n",
       " '[NUM1][NUM11]': 418,\n",
       " '[NUM6][NUM13]': 419,\n",
       " '[NUM9][NUM19]': 420,\n",
       " '[NUM5][NUM13]': 421,\n",
       " '[NUM4][NUM14]': 422,\n",
       " '[NUM4][NUM11]': 423,\n",
       " '[NUM5][NUM10]': 424,\n",
       " '[NUM6][NUM21]': 425,\n",
       " '[NUM1][NUM10]': 426,\n",
       " '[NUM3][NUM15]': 427,\n",
       " '[NUM2][NUM17]': 428,\n",
       " '[NUM5][NUM18]': 429,\n",
       " '[NUM1][NUM16]': 430,\n",
       " '[NUM4][NUM21]': 431,\n",
       " '[NUM1][NUM22]': 432,\n",
       " '[NUM9][NUM13]': 433,\n",
       " '[NUM1][NUM18]': 434,\n",
       " '[NUM7][NUM21]': 435,\n",
       " '[NUM8][NUM15]': 436,\n",
       " '[NUM4][NUM16]': 437,\n",
       " '[NUM7][NUM17]': 438,\n",
       " '[NUM8][NUM17]': 439,\n",
       " '[NUM6][NUM15]': 440,\n",
       " '[NUM4][NUM13]': 441,\n",
       " '[NUM6][NUM12]': 442,\n",
       " '[NUM7][NUM20]': 443,\n",
       " '[NUM9][NUM20]': 444,\n",
       " '[NUM4][NUM19]': 445,\n",
       " '[NUM8][NUM21]': 446,\n",
       " '[NUM8][NUM11]': 447,\n",
       " '[NUM2][NUM20]': 448,\n",
       " '[NUM6][NUM14]': 449,\n",
       " '[NUM1][NUM20]': 450,\n",
       " '[NUM5][NUM12]': 451,\n",
       " '[NUM4][NUM15]': 452,\n",
       " '[NUM8][NUM18]': 453,\n",
       " '[NUM2][NUM18]': 454,\n",
       " '[NUM4][NUM10]': 455,\n",
       " '[NUM3][NUM20]': 456,\n",
       " '[NUM2][NUM14]': 457,\n",
       " '[NUM7][NUM16]': 458,\n",
       " '[NUM7][NUM19]': 459,\n",
       " '[NUM9][NUM17]': 460,\n",
       " '[NUM4][NUM17]': 461,\n",
       " '[NUM3][NUM18]': 462,\n",
       " '[NUM4][NUM12]': 463,\n",
       " '[NUM6][NUM17]': 464,\n",
       " '[ELM35][NUM2]': 465,\n",
       " '[ELM8][NUM13]': 466,\n",
       " '[ELM6][NUM14]': 467,\n",
       " '[NUM15][ELM8]': 468,\n",
       " '[ELM6][NUM11]': 469,\n",
       " '[ELM6][NUM10]': 470,\n",
       " '[ELM6][NUM13]': 471,\n",
       " '[NUM13][ELM8]': 472,\n",
       " '[NUM13][ELM7]': 473,\n",
       " '[ELM16][NUM7]': 474,\n",
       " '[NUM10][ELM8]': 475,\n",
       " '[NUM16][ELM7]': 476,\n",
       " '[ELM8][NUM10]': 477,\n",
       " '[ELM7][NUM14]': 478,\n",
       " '[NUM16][ELM8]': 479,\n",
       " '[NUM14][ELM7]': 480,\n",
       " '[ELM6][NUM12]': 481,\n",
       " '[ELM9][NUM14]': 482,\n",
       " '[NUM18][ELM9]': 483,\n",
       " '[ELM6][NUM16]': 484,\n",
       " '[NUM11][ELM7]': 485,\n",
       " '[NUM11][ELM8]': 486,\n",
       " '[ELM8][NUM14]': 487,\n",
       " '[NUM14][ELM8]': 488,\n",
       " '[NUM10][ELM7]': 489,\n",
       " '[NUM15][ELM7]': 490,\n",
       " '[NUM16][ELM9]': 491,\n",
       " '[NUM20][ELM9]': 492,\n",
       " '[ELM16][NUM8]': 493,\n",
       " '[NUM17][ELM8]': 494,\n",
       " '[NUM17][ELM9]': 495,\n",
       " '[NUM19][ELM9]': 496,\n",
       " '[ELM8][NUM15]': 497,\n",
       " '[NUM21][ELM8]': 498,\n",
       " '[ELM9][NUM12]': 499,\n",
       " '[NUM3][NUM13]': 500,\n",
       " '[NUM3][NUM21]': 501,\n",
       " '[NUM3][NUM17]': 502,\n",
       " '[NUM2][NUM16]': 503,\n",
       " '[ELM1][NUM50]': 504,\n",
       " '[NUM3][NUM11]': 505,\n",
       " '[NUM21][ELM9]': 506,\n",
       " '[NUM15][ELM6]': 507,\n",
       " '[NUM3][NUM12]': 508,\n",
       " '[NUM2][NUM10]': 509,\n",
       " '[NUM3][NUM16]': 510,\n",
       " '[NUM3][NUM10]': 511,\n",
       " '[NUM9][NUM22]': 512,\n",
       " '[NUM2][NUM23]': 513,\n",
       " '[NUM2][NUM12]': 514,\n",
       " '[NUM22][ELM9]': 515,\n",
       " '[NUM2][NUM13]': 516,\n",
       " '[NUM12][NUM13]': 517,\n",
       " '[NUM13][NUM14]': 518,\n",
       " '[NUM10][NUM11]': 519,\n",
       " '[NUM11][NUM12]': 520,\n",
       " '[NUM14][NUM15]': 521,\n",
       " '[NUM15][NUM16]': 522,\n",
       " '[NUM15][NUM17]': 523,\n",
       " '[NUM17][NUM18]': 524,\n",
       " '[NUM18][NUM19]': 525,\n",
       " '[NUM19][NUM20]': 526,\n",
       " '[NUM18][NUM21]': 527,\n",
       " '[NUM21][NUM22]': 528,\n",
       " '[NUM13][NUM21]': 529,\n",
       " '[NUM18][NUM20]': 530,\n",
       " '[NUM22][NUM23]': 531,\n",
       " '[NUM14][NUM20]': 532,\n",
       " '[NUM16][NUM17]': 533,\n",
       " '[NUM14][NUM16]': 534,\n",
       " '[NUM16][NUM18]': 535,\n",
       " '[NUM20][NUM21]': 536,\n",
       " '[NUM18][NUM22]': 537,\n",
       " '[NUM12][NUM14]': 538,\n",
       " '[NUM10][NUM12]': 539,\n",
       " '[NUM13][NUM19]': 540,\n",
       " '[NUM16][NUM20]': 541,\n",
       " '[NUM11][NUM13]': 542,\n",
       " '[NUM21][NUM23]': 543,\n",
       " '[NUM12][NUM20]': 544,\n",
       " '[NUM13][NUM15]': 545,\n",
       " '[NUM12][NUM16]': 546,\n",
       " '[NUM12][NUM17]': 547,\n",
       " '[NUM15][NUM21]': 548,\n",
       " '[NUM19][NUM21]': 549,\n",
       " '[NUM14][NUM21]': 550,\n",
       " '[NUM14][NUM19]': 551,\n",
       " '[NUM13][NUM17]': 552,\n",
       " '[NUM15][NUM19]': 553,\n",
       " '[NUM10][NUM15]': 554,\n",
       " '[NUM10][NUM13]': 555,\n",
       " '[NUM10][NUM17]': 556,\n",
       " '[NUM12][NUM15]': 557,\n",
       " '[NUM16][NUM19]': 558,\n",
       " '[NUM11][NUM17]': 559,\n",
       " '[NUM11][NUM20]': 560,\n",
       " '[NUM11][NUM21]': 561,\n",
       " '[NUM15][NUM20]': 562,\n",
       " '[NUM17][NUM19]': 563,\n",
       " '[NUM12][NUM19]': 564,\n",
       " '[NUM11][NUM14]': 565,\n",
       " '[NUM10][NUM18]': 566,\n",
       " '[NUM17][NUM21]': 567,\n",
       " '[NUM17][NUM22]': 568,\n",
       " '[NUM16][NUM22]': 569,\n",
       " '[NUM15][NUM18]': 570,\n",
       " '[NUM11][NUM18]': 571,\n",
       " '[NUM19][NUM22]': 572,\n",
       " '[NUM11][NUM16]': 573,\n",
       " '[NUM12][NUM18]': 574,\n",
       " '[NUM16][NUM21]': 575,\n",
       " '[NUM13][NUM18]': 576,\n",
       " '[NUM10][NUM21]': 577,\n",
       " '[NUM10][NUM19]': 578,\n",
       " '[NUM13][NUM16]': 579,\n",
       " '[NUM10][NUM16]': 580,\n",
       " '[NUM10][NUM20]': 581,\n",
       " '[NUM14][NUM17]': 582,\n",
       " '[NUM11][NUM19]': 583,\n",
       " '[NUM10][NUM14]': 584,\n",
       " '[NUM14][NUM18]': 585,\n",
       " '[NUM20][NUM22]': 586,\n",
       " '[NUM12][NUM21]': 587,\n",
       " '[NUM17][NUM20]': 588,\n",
       " '[NUM11][NUM15]': 589,\n",
       " '[NUM13][NUM20]': 590,\n",
       " '[NUM17][ELM16]': 591,\n",
       " '[NUM18][ELM16]': 592,\n",
       " '[NUM19][ELM16]': 593,\n",
       " '[NUM17][ELM17]': 594,\n",
       " '[NUM18][NUM23]': 595,\n",
       " '[NUM14][NUM22]': 596,\n",
       " '[NUM10][NUM22]': 597,\n",
       " '[NUM13][NUM22]': 598,\n",
       " '[NUM11][NUM22]': 599,\n",
       " '[NUM15][NUM22]': 600,\n",
       " '[SET][geom_drugs]': 601,\n",
       " '[SET][tspace_enum]': 602,\n",
       " '[ELM1][NUM7][ELM6]': 603,\n",
       " '[ELM1][NUM6][ELM6]': 604,\n",
       " '[SET][tspace_real]': 605,\n",
       " '[ELM6][NUM9][ELM7]': 606,\n",
       " '[ELM7][NUM9][ELM6]': 607,\n",
       " '[NUM3][ELM8][NUM4]': 608,\n",
       " '[NUM4][ELM8][NUM5]': 609,\n",
       " '[NUM2][ELM8][NUM3]': 610,\n",
       " '[NUM1][ELM8][NUM2]': 611,\n",
       " '[NUM5][ELM8][NUM2]': 612,\n",
       " '[NUM4][ELM8][NUM2]': 613,\n",
       " '[ELM1][NUM9][ELM6]': 614,\n",
       " '[NUM3][ELM8][NUM3]': 615,\n",
       " '[NUM4][ELM8][NUM3]': 616,\n",
       " '[NUM3][ELM8][NUM2]': 617,\n",
       " '[ELM1][NUM8][ELM6]': 618,\n",
       " '[NUM2][ELM8][NUM2]': 619,\n",
       " '[NUM3][ELM8][NUM5]': 620,\n",
       " '[NUM1][ELM8][NUM3]': 621,\n",
       " '[NUM1][ELM8][NUM1]': 622,\n",
       " '[NUM5][ELM8][NUM3]': 623,\n",
       " '[NUM2][ELM8][NUM5]': 624,\n",
       " '[NUM4][ELM8][NUM4]': 625,\n",
       " '[NUM2][ELM8][NUM4]': 626,\n",
       " '[NUM6][ELM8][NUM2]': 627,\n",
       " '[NUM5][ELM8][NUM1]': 628,\n",
       " '[NUM2][ELM8][NUM1]': 629,\n",
       " '[NUM4][ELM8][NUM1]': 630,\n",
       " '[NUM3][ELM8][NUM1]': 631,\n",
       " '[NUM0][ELM9][NUM1]': 632,\n",
       " '[ELM6][NUM9][ELM9]': 633,\n",
       " '[ELM7][NUM10][ELM8]': 634,\n",
       " '[ELM1][NUM11][ELM6]': 635,\n",
       " '[ELM1][NUM38][ELM6]': 636,\n",
       " '[ELM1][NUM21][ELM6]': 637,\n",
       " '[ELM1][NUM12][ELM6]': 638,\n",
       " '[ELM1][NUM36][ELM6]': 639,\n",
       " '[ELM1][NUM44][ELM6]': 640,\n",
       " '[ELM1][NUM10][ELM6]': 641,\n",
       " '[ELM1][NUM20][ELM6]': 642,\n",
       " '[ELM1][NUM37][ELM6]': 643,\n",
       " '[ELM1][NUM39][ELM6]': 644,\n",
       " '[ELM1][NUM13][ELM6]': 645,\n",
       " '[ELM1][NUM15][ELM6]': 646,\n",
       " '[ELM7][NUM15][ELM6]': 647,\n",
       " '[ELM1][NUM24][ELM6]': 648,\n",
       " '[ELM8][NUM16][ELM6]': 649,\n",
       " '[ELM1][NUM19][ELM6]': 650,\n",
       " '[ELM1][NUM16][ELM6]': 651,\n",
       " '[ELM1][NUM30][ELM6]': 652,\n",
       " '[ELM1][NUM17][ELM6]': 653,\n",
       " '[ELM1][NUM40][ELM6]': 654,\n",
       " '[ELM1][NUM22][ELM6]': 655,\n",
       " '[ELM1][NUM27][ELM6]': 656,\n",
       " '[ELM1][NUM41][ELM6]': 657,\n",
       " '[ELM1][NUM23][ELM6]': 658,\n",
       " '[ELM1][NUM29][ELM6]': 659,\n",
       " '[ELM7][NUM16][ELM6]': 660,\n",
       " '[ELM8][NUM17][ELM6]': 661,\n",
       " '[ELM1][NUM35][ELM6]': 662,\n",
       " '[ELM1][NUM26][ELM6]': 663,\n",
       " '[ELM1][NUM25][ELM6]': 664,\n",
       " '[ELM1][NUM42][ELM6]': 665,\n",
       " '[ELM7][NUM17][ELM6]': 666,\n",
       " '[ELM1][NUM32][ELM6]': 667,\n",
       " '[NUM3][ELM16][NUM1]': 668,\n",
       " '[ELM1][NUM18][ELM6]': 669,\n",
       " '[ELM1][NUM34][ELM6]': 670,\n",
       " '[ELM1][NUM14][ELM6]': 671,\n",
       " '[ELM1][NUM28][ELM6]': 672,\n",
       " '[ELM1][NUM48][ELM6]': 673,\n",
       " '[ELM6][NUM15][ELM9]': 674,\n",
       " '[ELM1][NUM46][ELM6]': 675,\n",
       " '[ELM1][NUM47][ELM6]': 676,\n",
       " '[NUM1][ELM16][NUM1]': 677,\n",
       " '[ELM1][NUM43][ELM6]': 678,\n",
       " '[ELM1][NUM31][ELM6]': 679,\n",
       " '[NUM2][ELM16][NUM1]': 680,\n",
       " '[ELM1][NUM45][ELM6]': 681,\n",
       " '[NUM4][ELM16][NUM1]': 682,\n",
       " '[NUM10][ELM6][NUM11]': 683,\n",
       " '[NUM11][ELM6][NUM12]': 684,\n",
       " '[NUM13][ELM6][NUM14]': 685,\n",
       " '[ELM7][NUM3][ELM8][NUM2]': 686,\n",
       " '[ELM7][NUM5][ELM8][NUM2]': 687,\n",
       " '[ELM7][NUM1][ELM8][NUM4]': 688,\n",
       " '[ELM7][NUM2][ELM8][NUM2]': 689,\n",
       " '[ELM7][NUM4][ELM8][NUM2]': 690,\n",
       " '[ELM7][NUM1][ELM8][NUM3]': 691,\n",
       " '[ELM7][NUM5][ELM8][NUM3]': 692,\n",
       " '[ELM7][NUM5][ELM8][NUM1]': 693,\n",
       " '[ELM7][NUM3][ELM8][NUM7]': 694,\n",
       " '[ELM7][NUM3][ELM8][NUM1]': 695,\n",
       " '[ELM7][NUM4][ELM8][NUM3]': 696,\n",
       " '[ELM7][NUM4][ELM8][NUM1]': 697,\n",
       " '[ELM7][NUM3][ELM8][NUM3]': 698,\n",
       " '[ELM7][NUM2][ELM8][NUM3]': 699,\n",
       " '[ELM7][NUM2][ELM8][NUM4]': 700,\n",
       " '[ELM7][NUM4][ELM8][NUM5]': 701,\n",
       " '[ELM7][NUM6][ELM8][NUM2]': 702,\n",
       " '[ELM7][NUM4][ELM8][NUM4]': 703,\n",
       " '[ELM7][NUM6][ELM8][NUM4]': 704,\n",
       " '[ELM7][NUM3][ELM8][NUM4]': 705,\n",
       " '[ELM7][NUM2][ELM8][NUM1]': 706,\n",
       " '[ELM7][NUM1][ELM8][NUM2]': 707,\n",
       " '[ELM7][NUM8][ELM8][NUM3]': 708,\n",
       " '[ELM7][NUM1][ELM8][NUM1]': 709,\n",
       " '[ELM7][NUM6][ELM8][NUM3]': 710,\n",
       " '[ELM7][NUM7][ELM8][NUM2]': 711,\n",
       " '[ELM7][NUM6][ELM8][NUM1]': 712,\n",
       " '[ELM7][NUM2][ELM8][NUM6]': 713,\n",
       " '[ELM7][NUM6][ELM8][NUM5]': 714,\n",
       " '[ELM7][NUM3][ELM8][NUM5]': 715,\n",
       " '[ELM7][NUM5][ELM8][NUM5]': 716,\n",
       " '[ELM7][NUM5][ELM8][NUM4]': 717,\n",
       " '[ELM7][NUM7][ELM8][NUM3]': 718,\n",
       " '[ELM7][NUM5][ELM8][NUM6]': 719,\n",
       " '[ELM7][NUM2][ELM8][NUM5]': 720,\n",
       " '[ELM7][NUM7][ELM8][NUM4]': 721,\n",
       " '[ELM7][NUM1][ELM8][NUM6]': 722,\n",
       " '[ELM7][NUM1][ELM8][NUM5]': 723,\n",
       " '[ELM7][NUM3][ELM8][NUM6]': 724,\n",
       " '[ELM7][NUM7][ELM8][NUM5]': 725,\n",
       " '[ELM7][NUM7][ELM8][NUM1]': 726,\n",
       " '[ELM7][NUM8][ELM8][NUM2]': 727,\n",
       " '[ELM7][NUM6][ELM8][NUM6]': 728,\n",
       " '[ELM7][NUM6][ELM8][NUM7]': 729,\n",
       " '[ELM7][NUM2][ELM8][NUM7]': 730,\n",
       " '[ELM7][NUM5][ELM8][NUM7]': 731,\n",
       " '[ELM7][NUM4][ELM8][NUM6]': 732,\n",
       " '[ELM7][NUM4][ELM8][NUM7]': 733,\n",
       " '[ELM7][NUM8][ELM8][NUM1]': 734,\n",
       " '[ELM7][NUM8][ELM8][NUM4]': 735,\n",
       " '[ELM7][NUM7][ELM8][NUM6]': 736,\n",
       " '[ELM7][NUM9][ELM8][NUM3]': 737,\n",
       " '[ELM7][NUM8][ELM8][NUM5]': 738,\n",
       " '[ELM8][NUM8][ELM6][NUM9]': 739,\n",
       " '[ELM7][NUM7][ELM6][NUM8]': 740,\n",
       " '[ELM6][NUM6][ELM6][NUM7]': 741,\n",
       " '[ELM7][NUM8][ELM7][NUM9]': 742,\n",
       " '[ELM7][NUM1][ELM8][NUM7]': 743,\n",
       " '[ELM7][NUM6][ELM7][NUM7]': 744,\n",
       " '[NUM3][ELM8][NUM1][ELM9]': 745,\n",
       " '[ELM8][NUM6][ELM6][NUM7]': 746,\n",
       " '[ELM8][NUM7][ELM6][NUM8]': 747,\n",
       " '[NUM8][ELM8][NUM9][ELM6]': 748,\n",
       " '[NUM2][ELM8][NUM2][ELM9]': 749,\n",
       " '[ELM6][NUM4][ELM6][NUM5]': 750,\n",
       " '[NUM2][ELM8][NUM1][ELM9]': 751,\n",
       " '[ELM7][NUM9][ELM8][NUM4]': 752,\n",
       " '[ELM9][NUM1][ELM16][NUM1]': 753,\n",
       " '[ELM9][NUM3][ELM16][NUM1]': 754,\n",
       " '[ELM9][NUM2][ELM16][NUM1]': 755,\n",
       " '[ELM9][NUM1][ELM17][NUM1]': 756,\n",
       " '[ELM9][NUM4][ELM16][NUM1]': 757,\n",
       " '[ELM9][NUM6][ELM16][NUM1]': 758,\n",
       " '[NUM11][ELM7][NUM2][ELM8]': 759,\n",
       " '[ELM7][NUM3][ELM16][NUM1]': 760,\n",
       " '[ELM9][NUM3][ELM17][NUM1]': 761,\n",
       " '[ELM9][NUM2][ELM17][NUM1]': 762,\n",
       " '[ELM35][NUM1][SET][mcule]': 763,\n",
       " '[ELM1][NUM13][ELM6][NUM14]': 764,\n",
       " '[ELM1][NUM18][ELM6][NUM24]': 765,\n",
       " '[ELM1][NUM28][ELM6][NUM21]': 766,\n",
       " '[ELM1][NUM30][ELM6][NUM28]': 767,\n",
       " '[ELM16][NUM1][ELM17][NUM1]': 768,\n",
       " '[NUM17][ELM6][NUM18][ELM6]': 769,\n",
       " '[NUM20][ELM6][NUM21][ELM6]': 770,\n",
       " '[ELM1][NUM19][ELM6][NUM15]': 771,\n",
       " '[ELM1][NUM35][ELM6][NUM29]': 772,\n",
       " '[ELM1][NUM29][ELM6][NUM25]': 773,\n",
       " '[NUM17][ELM7][NUM18][ELM6]': 774,\n",
       " '[NUM18][ELM6][NUM19][ELM6]': 775,\n",
       " '[NUM19][ELM6][NUM20][ELM6]': 776,\n",
       " '[NUM21][ELM6][NUM22][ELM6]': 777,\n",
       " '[ELM1][NUM12][ELM6][NUM16]': 778,\n",
       " '[ELM1][NUM21][ELM6][NUM20]': 779,\n",
       " '[NUM18][ELM7][NUM19][ELM6]': 780,\n",
       " '[ELM1][NUM14][ELM6][NUM14]': 781,\n",
       " '[ELM1][NUM17][ELM6][NUM19]': 782,\n",
       " '[ELM1][NUM30][ELM6][NUM23]': 783,\n",
       " '[ELM1][NUM18][ELM6][NUM19]': 784,\n",
       " '[ELM1][NUM30][ELM6][NUM22]': 785,\n",
       " '[ELM1][NUM27][ELM6][NUM24]': 786,\n",
       " '[ELM1][NUM26][ELM6][NUM28]': 787,\n",
       " '[ELM1][NUM24][ELM6][NUM26]': 788,\n",
       " '[ELM1][NUM17][ELM6][NUM17]': 789,\n",
       " '[ELM1][NUM22][ELM6][NUM23]': 790,\n",
       " '[ELM1][NUM34][ELM6][NUM22]': 791,\n",
       " '[ELM1][NUM26][ELM6][NUM27]': 792,\n",
       " '[ELM1][NUM16][ELM6][NUM18]': 793,\n",
       " '[ELM1][NUM23][ELM6][NUM19]': 794,\n",
       " '[ELM1][NUM29][ELM6][NUM22]': 795,\n",
       " '[ELM1][NUM35][ELM6][NUM24]': 796,\n",
       " '[ELM1][NUM20][ELM6][NUM19]': 797,\n",
       " '[ELM1][NUM21][ELM6][NUM16]': 798,\n",
       " '[ELM1][NUM24][ELM6][NUM22]': 799,\n",
       " '[ELM16][NUM2][ELM17][NUM1]': 800,\n",
       " '[ELM1][NUM27][ELM6][NUM21]': 801,\n",
       " '[ELM1][NUM24][ELM6][NUM23]': 802,\n",
       " '[ELM1][NUM29][ELM6][NUM26]': 803,\n",
       " '[ELM1][NUM17][ELM6][NUM22]': 804,\n",
       " '[ELM1][NUM21][ELM6][NUM21]': 805,\n",
       " '[ELM1][NUM23][ELM6][NUM20]': 806,\n",
       " '[ELM1][NUM17][ELM6][NUM14]': 807,\n",
       " '[ELM1][NUM13][ELM6][NUM15]': 808,\n",
       " '[ELM1][NUM29][ELM6][NUM29]': 809,\n",
       " '[ELM1][NUM18][ELM6][NUM14]': 810,\n",
       " '[ELM1][NUM30][ELM6][NUM25]': 811,\n",
       " '[ELM1][NUM11][ELM6][NUM15]': 812,\n",
       " '[ELM1][NUM18][ELM6][NUM20]': 813,\n",
       " '[ELM1][NUM23][ELM6][NUM25]': 814,\n",
       " '[ELM1][NUM24][ELM6][NUM19]': 815,\n",
       " '[ELM1][NUM32][ELM6][NUM19]': 816,\n",
       " '[ELM1][NUM21][ELM6][NUM24]': 817,\n",
       " '[ELM1][NUM27][ELM6][NUM29]': 818,\n",
       " '[ELM1][NUM14][ELM6][NUM19]': 819,\n",
       " '[ELM1][NUM19][ELM6][NUM24]': 820,\n",
       " '[ELM1][NUM29][ELM6][NUM23]': 821,\n",
       " '[ELM1][NUM24][ELM6][NUM18]': 822,\n",
       " '[ELM1][NUM33][ELM6][NUM27]': 823,\n",
       " '[ELM1][NUM27][ELM6][NUM22]': 824,\n",
       " '[ELM1][NUM19][ELM6][NUM21]': 825,\n",
       " '[ELM1][NUM23][ELM6][NUM18]': 826,\n",
       " '[ELM1][NUM25][ELM6][NUM22]': 827,\n",
       " '[ELM1][NUM16][ELM6][NUM15]': 828,\n",
       " '[NUM22][ELM6][NUM23][ELM6]': 829,\n",
       " '[ELM1][NUM20][ELM6][NUM21]': 830,\n",
       " '[ELM1][NUM25][ELM6][NUM18]': 831,\n",
       " '[ELM1][NUM29][ELM6][NUM20]': 832,\n",
       " '[ELM1][NUM26][ELM6][NUM20]': 833,\n",
       " '[ELM1][NUM26][ELM6][NUM16]': 834,\n",
       " '[ELM1][NUM28][ELM6][NUM24]': 835,\n",
       " '[ELM1][NUM28][ELM6][NUM19]': 836,\n",
       " '[ELM1][NUM27][ELM6][NUM25]': 837,\n",
       " '[ELM1][NUM22][ELM6][NUM20]': 838,\n",
       " '[ELM1][NUM22][ELM6][NUM22]': 839,\n",
       " '[ELM1][NUM34][ELM6][NUM23]': 840,\n",
       " '[ELM1][NUM33][ELM6][NUM20]': 841,\n",
       " '[ELM1][NUM30][ELM6][NUM26]': 842,\n",
       " '[ELM1][NUM25][ELM6][NUM20]': 843,\n",
       " '[ELM1][NUM15][ELM6][NUM13]': 844,\n",
       " '[ELM1][NUM34][ELM6][NUM28]': 845,\n",
       " '[ELM1][NUM17][ELM6][NUM16]': 846,\n",
       " '[ELM1][NUM20][ELM6][NUM22]': 847,\n",
       " '[ELM1][NUM18][ELM6][NUM22]': 848,\n",
       " '[ELM1][NUM20][ELM6][NUM25]': 849,\n",
       " '[ELM1][NUM28][ELM6][NUM20]': 850,\n",
       " '[ELM1][NUM18][ELM6][NUM17]': 851,\n",
       " '[ELM1][NUM14][ELM6][NUM17]': 852,\n",
       " '[ELM1][NUM14][ELM6][NUM15]': 853,\n",
       " '[ELM1][NUM22][ELM6][NUM19]': 854,\n",
       " '[ELM1][NUM26][ELM6][NUM21]': 855,\n",
       " '[ELM1][NUM21][ELM6][NUM18]': 856,\n",
       " '[ELM1][NUM32][ELM6][NUM23]': 857,\n",
       " '[ELM1][NUM25][ELM6][NUM21]': 858,\n",
       " '[ELM1][NUM32][ELM6][NUM25]': 859,\n",
       " '[ELM1][NUM19][ELM6][NUM20]': 860,\n",
       " '[ELM1][NUM32][ELM6][NUM26]': 861,\n",
       " '[ELM1][NUM25][ELM6][NUM26]': 862,\n",
       " '[ELM1][NUM29][ELM6][NUM19]': 863,\n",
       " '[ELM1][NUM21][ELM6][NUM17]': 864,\n",
       " '[ELM1][NUM21][ELM6][NUM25]': 865,\n",
       " '[ELM1][NUM30][ELM6][NUM20]': 866,\n",
       " '[ELM1][NUM25][ELM6][NUM25]': 867,\n",
       " '[ELM1][NUM15][ELM6][NUM15]': 868,\n",
       " '[ELM1][NUM25][ELM6][NUM17]': 869,\n",
       " '[ELM1][NUM26][ELM6][NUM22]': 870,\n",
       " '[ELM1][NUM26][ELM6][NUM17]': 871,\n",
       " '[ELM1][NUM21][ELM6][NUM23]': 872,\n",
       " '[ELM1][NUM24][ELM6][NUM25]': 873,\n",
       " '[ELM1][NUM14][ELM6][NUM16]': 874,\n",
       " '[ELM1][NUM21][ELM6][NUM19]': 875,\n",
       " '[ELM1][NUM32][ELM6][NUM22]': 876,\n",
       " '[ELM1][NUM31][ELM6][NUM21]': 877,\n",
       " '[ELM1][NUM23][ELM6][NUM21]': 878,\n",
       " '[ELM1][NUM27][ELM6][NUM26]': 879,\n",
       " '[ELM1][NUM25][ELM6][NUM24]': 880,\n",
       " '[ELM1][NUM20][ELM6][NUM20]': 881,\n",
       " '[ELM1][NUM22][ELM6][NUM17]': 882,\n",
       " '[ELM1][NUM13][ELM6][NUM18]': 883,\n",
       " '[ELM1][NUM23][ELM6][NUM17]': 884,\n",
       " '[ELM1][NUM16][ELM6][NUM17]': 885,\n",
       " '[ELM1][NUM25][ELM6][NUM19]': 886,\n",
       " '[ELM1][NUM23][ELM6][NUM23]': 887,\n",
       " '[ELM1][NUM12][ELM6][NUM13]': 888,\n",
       " '[ELM1][NUM20][ELM6][NUM16]': 889,\n",
       " '[ELM1][NUM31][ELM6][NUM23]': 890,\n",
       " '[ELM1][NUM20][ELM6][NUM17]': 891,\n",
       " '[ELM1][NUM22][ELM6][NUM18]': 892,\n",
       " '[ELM1][NUM16][ELM6][NUM19]': 893,\n",
       " '[ELM1][NUM33][ELM6][NUM22]': 894,\n",
       " '[ELM1][NUM37][ELM6][NUM29]': 895,\n",
       " '[ELM1][NUM21][ELM6][NUM22]': 896,\n",
       " '[ELM1][NUM15][ELM6][NUM18]': 897,\n",
       " '[ELM1][NUM22][ELM6][NUM16]': 898,\n",
       " '[ELM1][NUM28][ELM6][NUM25]': 899,\n",
       " '[ELM1][NUM24][ELM6][NUM21]': 900,\n",
       " '[ELM1][NUM22][ELM6][NUM25]': 901,\n",
       " '[ELM1][NUM18][ELM6][NUM15]': 902,\n",
       " '[ELM1][NUM19][ELM6][NUM18]': 903,\n",
       " '[ELM1][NUM29][ELM6][NUM24]': 904,\n",
       " '[ELM1][NUM35][ELM6][NUM27]': 905,\n",
       " '[ELM1][NUM28][ELM6][NUM28]': 906,\n",
       " '[ELM1][NUM19][ELM6][NUM22]': 907,\n",
       " '[ELM1][NUM19][ELM6][NUM16]': 908,\n",
       " '[ELM1][NUM30][ELM6][NUM18]': 909,\n",
       " '[ELM1][NUM26][ELM6][NUM24]': 910,\n",
       " '[ELM1][NUM16][ELM6][NUM13]': 911,\n",
       " '[ELM1][NUM23][ELM6][NUM26]': 912,\n",
       " '[ELM1][NUM26][ELM6][NUM19]': 913,\n",
       " '[ELM1][NUM15][ELM6][NUM16]': 914,\n",
       " '[ELM1][NUM17][ELM6][NUM15]': 915,\n",
       " '[ELM1][NUM28][ELM6][NUM23]': 916,\n",
       " '[ELM1][NUM13][ELM6][NUM13]': 917,\n",
       " '[ELM1][NUM32][ELM6][NUM20]': 918,\n",
       " '[ELM1][NUM25][ELM6][NUM16]': 919,\n",
       " '[ELM1][NUM23][ELM6][NUM22]': 920,\n",
       " '[ELM1][NUM29][ELM6][NUM30]': 921,\n",
       " '[ELM1][NUM27][ELM6][NUM20]': 922,\n",
       " '[ELM1][NUM28][ELM6][NUM26]': 923,\n",
       " '[ELM1][NUM31][ELM6][NUM19]': 924,\n",
       " '[ELM1][NUM29][ELM6][NUM21]': 925,\n",
       " '[ELM1][NUM19][ELM6][NUM17]': 926,\n",
       " '[ELM1][NUM27][ELM6][NUM23]': 927,\n",
       " '[ELM1][NUM18][ELM6][NUM18]': 928,\n",
       " '[ELM1][NUM31][ELM6][NUM20]': 929,\n",
       " '[ELM1][NUM20][ELM6][NUM23]': 930,\n",
       " '[ELM1][NUM31][ELM6][NUM29]': 931,\n",
       " '[ELM1][NUM31][ELM6][NUM22]': 932,\n",
       " '[ELM1][NUM31][ELM6][NUM26]': 933,\n",
       " '[ELM1][NUM17][ELM6][NUM21]': 934,\n",
       " '[ELM1][NUM22][ELM6][NUM26]': 935,\n",
       " '[ELM1][NUM33][ELM6][NUM26]': 936,\n",
       " '[ELM1][NUM32][ELM6][NUM27]': 937,\n",
       " '[ELM1][NUM25][ELM6][NUM28]': 938,\n",
       " '[ELM1][NUM21][ELM6][NUM15]': 939,\n",
       " '[ELM1][NUM16][ELM6][NUM21]': 940,\n",
       " '[ELM1][NUM12][ELM6][NUM15]': 941,\n",
       " '[ELM1][NUM17][ELM6][NUM13]': 942,\n",
       " '[ELM1][NUM15][ELM6][NUM17]': 943,\n",
       " '[ELM1][NUM24][ELM6][NUM16]': 944,\n",
       " '[ELM1][NUM31][ELM6][NUM28]': 945,\n",
       " '[ELM1][NUM30][ELM6][NUM21]': 946,\n",
       " '[ELM1][NUM27][ELM6][NUM28]': 947,\n",
       " '[ELM1][NUM23][ELM6][NUM24]': 948,\n",
       " '[ELM1][NUM35][ELM6][NUM30]': 949,\n",
       " '[ELM1][NUM18][ELM6][NUM23]': 950,\n",
       " '[ELM1][NUM27][ELM6][NUM19]': 951,\n",
       " '[ELM1][NUM11][ELM6][NUM13]': 952,\n",
       " '[ELM1][NUM30][ELM6][NUM30]': 953,\n",
       " '[ELM1][NUM32][ELM6][NUM21]': 954,\n",
       " '[ELM1][NUM24][ELM6][NUM27]': 955,\n",
       " '[ELM1][NUM21][ELM6][NUM26]': 956,\n",
       " '[ELM1][NUM31][ELM6][NUM24]': 957,\n",
       " '[ELM1][NUM20][ELM6][NUM18]': 958,\n",
       " '[ELM1][NUM16][ELM6][NUM16]': 959,\n",
       " '[ELM1][NUM33][ELM6][NUM31]': 960,\n",
       " '[ELM1][NUM10][ELM6][NUM15]': 961,\n",
       " '[ELM1][NUM22][ELM6][NUM21]': 962,\n",
       " '[ELM1][NUM14][ELM6][NUM13]': 963,\n",
       " '[ELM1][NUM28][ELM6][NUM18]': 964,\n",
       " '[ELM1][NUM29][ELM6][NUM17]': 965,\n",
       " '[ELM1][NUM23][ELM6][NUM16]': 966,\n",
       " '[ELM1][NUM34][ELM6][NUM29]': 967,\n",
       " '[ELM1][NUM17][ELM6][NUM18]': 968,\n",
       " '[ELM1][NUM19][ELM6][NUM23]': 969,\n",
       " '[ELM1][NUM28][ELM6][NUM29]': 970,\n",
       " '[ELM1][NUM26][ELM6][NUM18]': 971,\n",
       " '[ELM1][NUM13][ELM6][NUM16]': 972,\n",
       " '[ELM1][NUM20][ELM6][NUM24]': 973,\n",
       " '[ELM1][NUM18][ELM6][NUM16]': 974,\n",
       " '[ELM1][NUM20][ELM6][NUM15]': 975,\n",
       " '[ELM1][NUM15][ELM6][NUM21]': 976,\n",
       " '[ELM1][NUM13][ELM6][NUM17]': 977,\n",
       " '[ELM1][NUM33][ELM6][NUM25]': 978,\n",
       " '[ELM1][NUM32][ELM6][NUM29]': 979,\n",
       " '[ELM1][NUM14][ELM6][NUM18]': 980,\n",
       " '[ELM1][NUM19][ELM6][NUM19]': 981,\n",
       " '[ELM1][NUM32][ELM6][NUM28]': 982,\n",
       " '[ELM1][NUM25][ELM6][NUM27]': 983,\n",
       " '[ELM1][NUM22][ELM6][NUM24]': 984,\n",
       " '[ELM1][NUM24][ELM6][NUM20]': 985,\n",
       " '[ELM1][NUM20][ELM6][NUM14]': 986,\n",
       " '[ELM1][NUM26][ELM6][NUM26]': 987,\n",
       " '[ELM1][NUM15][ELM6][NUM19]': 988,\n",
       " '[ELM1][NUM35][ELM6][NUM23]': 989,\n",
       " '[ELM1][NUM31][ELM6][NUM25]': 990,\n",
       " '[ELM1][NUM36][ELM6][NUM25]': 991,\n",
       " '[ELM1][NUM32][ELM6][NUM30]': 992,\n",
       " '[ELM1][NUM38][ELM6][NUM30]': 993,\n",
       " '[ELM1][NUM27][ELM6][NUM18]': 994,\n",
       " '[ELM1][NUM27][ELM6][NUM17]': 995,\n",
       " '[ELM1][NUM29][ELM6][NUM27]': 996,\n",
       " '[ELM1][NUM27][ELM6][NUM27]': 997,\n",
       " '[ELM1][NUM24][ELM6][NUM24]': 998,\n",
       " '[ELM1][NUM15][ELM6][NUM14]': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_seq',\n",
       " 'special_tokens',\n",
       " 'smiles_tokens',\n",
       " 'keys',\n",
       " 'n_token',\n",
       " 'vocab',\n",
       " 'stop_token',\n",
       " 'pad_token',\n",
       " 'clip_token',\n",
       " 'unk_token',\n",
       " 'smiles_token',\n",
       " 'suffix_token',\n",
       " 'middle_token',\n",
       " 'graph_token',\n",
       " 'formula_token',\n",
       " 'set_token',\n",
       " 'smiles_trie',\n",
       " 'special_trie',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " 'pre_tokenize',\n",
       " 'tokenize_text',\n",
       " 'batch_smiles',\n",
       " 'decode',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__new__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_is_full_backward_hook',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_version',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'bias',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'elementwise_affine',\n",
       " 'eps',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'normalized_shape',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'set_extra_state',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'weight',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.xformer.transformer.ln_f.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokens = torch.tensor(\n",
    "    [\n",
    "        tokenizer.tokenize_text(\"[SMILES]\" + s + \"[STOP]\", pad=True)\n",
    "        if s != \"*\"\n",
    "        else tokenizer.tokenize_text(\"[SMILES]C[STOP]\", pad=True)\n",
    "        for s in smiles\n",
    "    ],\n",
    "    device=\"cpu\",\n",
    "    dtype=torch.int,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 250])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.n_seq = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_seq',\n",
       " 'special_tokens',\n",
       " 'smiles_tokens',\n",
       " 'keys',\n",
       " 'n_token',\n",
       " 'vocab',\n",
       " 'stop_token',\n",
       " 'pad_token',\n",
       " 'clip_token',\n",
       " 'unk_token',\n",
       " 'smiles_token',\n",
       " 'suffix_token',\n",
       " 'middle_token',\n",
       " 'graph_token',\n",
       " 'formula_token',\n",
       " 'set_token',\n",
       " 'smiles_trie',\n",
       " 'special_trie',\n",
       " '__module__',\n",
       " '__doc__',\n",
       " '__init__',\n",
       " 'pre_tokenize',\n",
       " 'tokenize_text',\n",
       " 'batch_smiles',\n",
       " 'decode',\n",
       " '__dict__',\n",
       " '__weakref__',\n",
       " '__new__',\n",
       " '__repr__',\n",
       " '__hash__',\n",
       " '__str__',\n",
       " '__getattribute__',\n",
       " '__setattr__',\n",
       " '__delattr__',\n",
       " '__lt__',\n",
       " '__le__',\n",
       " '__eq__',\n",
       " '__ne__',\n",
       " '__gt__',\n",
       " '__ge__',\n",
       " '__reduce_ex__',\n",
       " '__reduce__',\n",
       " '__subclasshook__',\n",
       " '__init_subclass__',\n",
       " '__format__',\n",
       " '__sizeof__',\n",
       " '__dir__',\n",
       " '__class__']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_embeds = encoder.encode_tokens(batch_tokens, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_indices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Embeds the tokens, and projects into the latent space.\n",
      "\u001b[0;31mFile:\u001b[0m      /mnt/2547d4d7-6732-4154-b0e1-17b0c1e0c565/Document-2/Projet2/Stage/workspace/jump_models/src/coati/models/encoding/clip_e2e.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "encoder.encode_tokens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e3gnn_smiles_clip_e2e(\n",
       "  (point_encoder): e3gnn_clip(\n",
       "    (act_fn): SiLU()\n",
       "    (embedding): Linear(in_features=28, out_features=256, bias=True)\n",
       "    (embedding_norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (node_dec): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Identity()\n",
       "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (gcl_0): e_gcl_sparse(\n",
       "      (instance_norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=513, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): SiLU()\n",
       "        (5): Identity()\n",
       "      )\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (coord_mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (act_fn): SiLU()\n",
       "    )\n",
       "    (gcl_1): e_gcl_sparse(\n",
       "      (instance_norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=513, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): SiLU()\n",
       "        (5): Identity()\n",
       "      )\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (coord_mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (act_fn): SiLU()\n",
       "    )\n",
       "    (gcl_2): e_gcl_sparse(\n",
       "      (instance_norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=513, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): SiLU()\n",
       "        (5): Identity()\n",
       "      )\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (coord_mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (act_fn): SiLU()\n",
       "    )\n",
       "    (gcl_3): e_gcl_sparse(\n",
       "      (instance_norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=513, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): SiLU()\n",
       "        (5): Identity()\n",
       "      )\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (coord_mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (act_fn): SiLU()\n",
       "    )\n",
       "    (gcl_4): e_gcl_sparse(\n",
       "      (instance_norm): InstanceNorm1d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=513, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): SiLU()\n",
       "        (5): Identity()\n",
       "      )\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Identity()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (coord_mlp): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): SiLU()\n",
       "        (2): Linear(in_features=256, out_features=1, bias=False)\n",
       "      )\n",
       "      (act_fn): SiLU()\n",
       "    )\n",
       "  )\n",
       "  (xformer): RotarySmilesTransformer(\n",
       "    (norm_embed): Identity()\n",
       "    (emb): RotaryEmbedding(\n",
       "      (tok_emb): Embedding(10322, 256)\n",
       "    )\n",
       "    (transformer): ModuleDict(\n",
       "      (h): ModuleList(\n",
       "        (0-15): 16 x RotaryBlock(\n",
       "          (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): RotarySelfAttention(\n",
       "            (c_attn): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (c_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlpf): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (1): NewGELU()\n",
       "            (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=256, out_features=10322, bias=False)\n",
       "  )\n",
       "  (point_to_clip): Sequential(\n",
       "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (smiles_to_clip): Sequential(\n",
       "    (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (point_clip_to_special_tokens): Sequential(\n",
       "    (0): SiLU()\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  )\n",
       "  (clip_loss): clip_loss()\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5.1528,  3.8842, 41.5446,  4.8210,  7.4189,  2.2844,  2.4983,  0.7494,\n",
       "         21.5638,  5.3194], grad_fn=<SumBackward1>),\n",
       " tensor([True, True, True, True, True, True, True, True, True, True]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.batch_smiles_to_s2s_likelihood(smiles, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -4.7370,   0.3078,   1.6261,  ...,  -0.0516,  -3.1638,   0.5547],\n",
       "         [-11.4987,  -0.3192,  -1.5464,  ...,  -6.1698, -10.2218,  -3.1609],\n",
       "         [ -8.4435,   0.8021,  -0.8089,  ...,  -2.4167,  -7.5098,  -2.4759],\n",
       "         ...,\n",
       "         [-10.3736,   2.5105,  -0.7439,  ...,  -4.9863,  -8.6617,  -3.3883],\n",
       "         [-10.2333,   2.5897,  -0.6997,  ...,  -4.8988,  -8.5454,  -3.3025],\n",
       "         [-10.0865,   2.5194,  -0.6686,  ...,  -4.8681,  -8.4047,  -3.2709]],\n",
       "\n",
       "        [[ -4.7370,   0.3078,   1.6261,  ...,  -0.0516,  -3.1638,   0.5547],\n",
       "         [-11.6163,  -2.5803,  -1.9344,  ...,  -5.1848, -10.3400,  -5.3778],\n",
       "         [ -9.6973,   3.3149,  -1.9919,  ...,  -2.9876,  -7.5202,  -5.2770],\n",
       "         ...,\n",
       "         [-10.5352,   4.5065,  -0.2985,  ...,  -4.9456,  -8.7423,  -3.3941],\n",
       "         [-10.7862,   4.4251,  -0.2186,  ...,  -5.1446,  -8.9914,  -3.7423],\n",
       "         [-10.8848,   4.3139,  -0.1930,  ...,  -5.3303,  -9.0748,  -3.8258]],\n",
       "\n",
       "        [[ -4.7370,   0.3078,   1.6261,  ...,  -0.0516,  -3.1638,   0.5547],\n",
       "         [-11.2945,  -1.3544,  -2.2660,  ...,  -5.4751,  -9.9416,  -2.5143],\n",
       "         [ -8.5155,  -0.1764,  -1.4301,  ...,  -2.0406,  -7.0007,  -5.2418],\n",
       "         ...,\n",
       "         [-10.4769,   1.7416,  -0.3790,  ...,  -5.8606,  -8.8854,  -3.5118],\n",
       "         [-10.6162,   1.5881,  -0.4304,  ...,  -6.0501,  -9.0231,  -3.5678],\n",
       "         [-10.5246,   1.6435,  -0.4174,  ...,  -6.2020,  -8.9439,  -3.5919]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -4.7370,   0.3078,   1.6261,  ...,  -0.0516,  -3.1638,   0.5547],\n",
       "         [-10.4360,  -0.8232,  -1.6206,  ...,  -3.6111,  -8.8612,  -3.6012],\n",
       "         [-11.8625,  -1.8163,  -2.1352,  ...,  -4.0039, -10.4337,  -4.1952],\n",
       "         ...,\n",
       "         [-11.6257,   2.8077,  -0.2967,  ...,  -6.1792, -10.0194,  -4.0602],\n",
       "         [-11.6594,   2.7186,  -0.2889,  ...,  -6.1942, -10.0298,  -4.1958],\n",
       "         [-11.7370,   2.6455,  -0.3014,  ...,  -6.2925, -10.0717,  -4.3035]],\n",
       "\n",
       "        [[ -4.7370,   0.3078,   1.6261,  ...,  -0.0516,  -3.1638,   0.5547],\n",
       "         [-11.9132,   0.4160,  -0.3498,  ...,  -8.4536, -11.0736,  -6.6369],\n",
       "         [ -9.5690,   2.2645,  -2.6393,  ...,  -3.9659,  -8.7057,  -3.6713],\n",
       "         ...,\n",
       "         [ -8.5619,   5.5227,  -0.7811,  ...,  -3.9811,  -6.6036,  -2.8310],\n",
       "         [ -8.6347,   5.6740,  -0.7166,  ...,  -4.0606,  -6.7004,  -2.8271],\n",
       "         [ -8.5900,   5.7397,  -0.7063,  ...,  -4.0806,  -6.6832,  -2.7069]],\n",
       "\n",
       "        [[ -4.7370,   0.3078,   1.6261,  ...,  -0.0516,  -3.1638,   0.5547],\n",
       "         [ -9.4403,  -0.3705,  -0.9194,  ...,  -3.9224,  -8.0706,  -4.7252],\n",
       "         [ -6.9940,   1.4206,  -1.3331,  ...,  -2.0259,  -5.6786,  -2.0533],\n",
       "         ...,\n",
       "         [-10.8106,   3.6643,  -0.1279,  ...,  -6.1839,  -9.0310,  -3.8985],\n",
       "         [-10.9586,   3.6245,  -0.1119,  ...,  -6.3850,  -9.1505,  -4.1002],\n",
       "         [-10.9976,   3.5159,  -0.1578,  ...,  -6.5804,  -9.1571,  -4.1595]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.xformer.forward(batch_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GlobalHydra.instance().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=\"../configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- med_jump_cl\n",
      "- nlp_coati\n",
      "- clip_like\n",
      "- ${model.molecule_encoder.pretrained_name}\n",
      "- ${model.image_encoder.instance_model_name}\n",
      "train: true\n",
      "test: true\n",
      "evaluate: true\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 22123\n",
      "data:\n",
      "  compound_transform:\n",
      "    _target_: src.modules.compound_transforms.coati.COATITransform\n",
      "    compound_str_type: inchi\n",
      "    pretrained_name: ${model.molecule_encoder.pretrained_name}\n",
      "    padding_length: ${model.molecule_encoder.padding_length}\n",
      "    model_dir: ${paths.model_dir}\n",
      "  _target_: src.models.jump_cl.datamodule.BasicJUMPDataModule\n",
      "  batch_size: 4\n",
      "  num_workers: 12\n",
      "  pin_memory: null\n",
      "  prefetch_factor: 3\n",
      "  drop_last: true\n",
      "  transform:\n",
      "    _target_: src.modules.transforms.DefaultJUMPTransform\n",
      "    _convert_: object\n",
      "    size: 224\n",
      "    dim:\n",
      "    - -2\n",
      "    - -1\n",
      "  force_split: false\n",
      "  splitter:\n",
      "    _target_: src.splitters.ScaffoldSplitter\n",
      "    train: 24576\n",
      "    test: 3072\n",
      "    val: 2048\n",
      "    retrieval: 0\n",
      "  use_compond_cache: false\n",
      "  data_root_dir: ${paths.projects_dir}/\n",
      "  split_path: ${paths.split_path}/fp_med4/\n",
      "  dataloader_config:\n",
      "    train:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: true\n",
      "    val:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "    test:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "  image_metadata_path: ${paths.metadata_path}/images_metadata.parquet\n",
      "  compound_metadata_path: ${paths.metadata_path}/compound_dict.json\n",
      "  compound_col: Metadata_InChI\n",
      "  image_sampler: null\n",
      "  metadata_dir: ${paths.raw_metadata_path}/complete_metadata.csv\n",
      "  local_load_data_dir: ${paths.load_data_path}/final/\n",
      "  index_str: '{Metadata_Source}__{Metadata_Batch}__{Metadata_Plate}__{Metadata_Well}__{Metadata_Site}'\n",
      "  channels:\n",
      "  - DNA\n",
      "  - AGP\n",
      "  - ER\n",
      "  - Mito\n",
      "  - RNA\n",
      "  col_fstring: FileName_Orig{channel}\n",
      "  id_cols:\n",
      "  - Metadata_Source\n",
      "  - Metadata_Batch\n",
      "  - Metadata_Plate\n",
      "  - Metadata_Well\n",
      "  extra_cols:\n",
      "  - Metadata_PlateType\n",
      "  - Metadata_Site\n",
      "model:\n",
      "  image_encoder:\n",
      "    _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "    instance_model_name: vit_base_patch16_224.augreg2_in21k_ft_in1k\n",
      "    target_num: ${model.embedding_dim}\n",
      "    n_channels: 5\n",
      "    pretrained: true\n",
      "  molecule_encoder:\n",
      "    _target_: src.modules.molecules.coati.COATI\n",
      "    pretrained_name: grande_closed\n",
      "    out_dim: ${model.embedding_dim}\n",
      "    padding_length: 250\n",
      "    model_dir: ${paths.model_dir}\n",
      "  criterion:\n",
      "    _target_: src.modules.losses.contrastive_losses.RegNTXent\n",
      "    norm: true\n",
      "    temperature: 10\n",
      "    return_rank: true\n",
      "    temperature_requires_grad: true\n",
      "    alpha: 0.2\n",
      "    mse_reg: 0.5\n",
      "    uniformity_reg: 0\n",
      "    variance_reg: 1\n",
      "    covariance_reg: 0.25\n",
      "    temperature_min: 0\n",
      "    temperature_max: 100\n",
      "  optimizer:\n",
      "    _target_: torch.optim.Adam\n",
      "    _partial_: true\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 0.001\n",
      "    amsgrad: false\n",
      "    lr: ${model.lr}\n",
      "  scheduler:\n",
      "    _target_: src.modules.lr_schedulers.warmup_wrapper.WarmUpWrapper\n",
      "    _partial_: true\n",
      "    warmup_steps:\n",
      "    - 5\n",
      "    interpolation: linear\n",
      "    wrapped_scheduler: ReduceLROnPlateau\n",
      "    cooldown: 3\n",
      "    factor: 0.6\n",
      "    patience: 7\n",
      "    min_lr: 1.0e-06\n",
      "    threshold: 0.0001\n",
      "    mode: min\n",
      "    verbose: true\n",
      "  _target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "  embedding_dim: 256\n",
      "  lr: 0.0003\n",
      "  batch_size: ${data.batch_size}\n",
      "  example_input_path: null\n",
      "  monitor: val/loss\n",
      "  interval: epoch\n",
      "  frequency: 1\n",
      "  image_backbone: backbone\n",
      "  image_head: projection_head\n",
      "  molecule_backbone: backbone\n",
      "  molecule_head: projection_head\n",
      "callbacks:\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 2\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0\n",
      "    patience: 25\n",
      "    verbose: false\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  timer:\n",
      "    _target_: lightning.pytorch.callbacks.Timer\n",
      "    duration: 02:00:00:00\n",
      "    interval: epoch\n",
      "    verbose: true\n",
      "  nan_loss:\n",
      "    _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "  wandb_watcher:\n",
      "    _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "    watch: true\n",
      "    watch_log: all\n",
      "    log_freq: 100\n",
      "    log_graph: false\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "logger:\n",
      "  csv:\n",
      "    _target_: lightning.pytorch.loggers.csv_logs.CSVLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    name: csv/\n",
      "    prefix: ''\n",
      "  tensorboard:\n",
      "    _target_: lightning.pytorch.loggers.tensorboard.TensorBoardLogger\n",
      "    save_dir: ${paths.output_dir}/tensorboard/\n",
      "    name: null\n",
      "    log_graph: false\n",
      "    default_hp_metric: true\n",
      "    prefix: ''\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: coati_med\n",
      "    log_model: true\n",
      "    prefix: ''\n",
      "    group: null\n",
      "    tags: ${tags}\n",
      "    job_type: ''\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 5\n",
      "  max_epochs: 200\n",
      "  accelerator: gpu\n",
      "  detect_anomaly: true\n",
      "  devices:\n",
      "  - 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 1\n",
      "  num_sanity_val_steps: 1\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  projects_dir: ..\n",
      "  data_root_dir: ${paths.projects_dir}/cpjump1\n",
      "  metadata_path: ${paths.data_root_dir}/jump/models/metadata\n",
      "  raw_metadata_path: ${paths.data_root_dir}/jump/metadata\n",
      "  load_data_path: ${paths.data_root_dir}/jump/load_data\n",
      "  model_dir: ${paths.data_root_dir}/jump/s3_cache\n",
      "  split_path: ${paths.data_root_dir}/jump/models/splits\n",
      "  log_dir: ${paths.data_root_dir}/jump/logs\n",
      "  output_dir: ./tmp/21312FS12A\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: true\n",
      "  style: dim\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "eval:\n",
      "  phase_I:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.warmup_wrapper.WarmUpWrapper\n",
      "        _partial_: true\n",
      "        warmup_steps:\n",
      "        - 10\n",
      "        interpolation: linear\n",
      "        wrapped_scheduler: ReduceLROnPlateau\n",
      "        cooldown: 3\n",
      "        factor: 0.6\n",
      "        patience: 7\n",
      "        min_lr: 1.0e-06\n",
      "        threshold: 0.0001\n",
      "        mode: min\n",
      "        verbose: true\n",
      "      _target_: src.eval.clinical_prediction.module.HintClinicalModulePhaseI\n",
      "      lr: 0.001\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      example_input_path: ${model.example_input_path}\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/hint/phase_I/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 200\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.phase_I.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: hint/phase_I/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: hint/phase_I/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 4\n",
      "        log_graph: false\n",
      "        prefix: jump_moa/image/plots\n",
      "        cmap: Oranges_r\n",
      "        fmt: .2f\n",
      "        per_fmt: .1%\n",
      "        fz: 10\n",
      "        lw: 0.5\n",
      "        cbar: false\n",
      "        figsize:\n",
      "        - 16\n",
      "        - 16\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.clinical_prediction.datamodule.HintClinicalDataModulePhaseI\n",
      "      hint_dir: ${paths.data_root_dir}/hint/\n",
      "      smiless_col: smiless\n",
      "      label_col: label\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 3\n",
      "      drop_last: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      visualize_kwargs: null\n",
      "  phase_II:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.warmup_wrapper.WarmUpWrapper\n",
      "        _partial_: true\n",
      "        warmup_steps:\n",
      "        - 10\n",
      "        interpolation: linear\n",
      "        wrapped_scheduler: ReduceLROnPlateau\n",
      "        cooldown: 3\n",
      "        factor: 0.6\n",
      "        patience: 7\n",
      "        min_lr: 1.0e-06\n",
      "        threshold: 0.0001\n",
      "        mode: min\n",
      "        verbose: true\n",
      "      _target_: src.eval.clinical_prediction.module.HintClinicalModulePhaseII\n",
      "      lr: 0.001\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      example_input_path: ${model.example_input_path}\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/hint/phase_II/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 200\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.phase_II.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: hint/phase_I/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: hint/phase_I/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 4\n",
      "        log_graph: false\n",
      "        prefix: jump_moa/image/plots\n",
      "        cmap: Oranges_r\n",
      "        fmt: .2f\n",
      "        per_fmt: .1%\n",
      "        fz: 10\n",
      "        lw: 0.5\n",
      "        cbar: false\n",
      "        figsize:\n",
      "        - 16\n",
      "        - 16\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.clinical_prediction.datamodule.HintClinicalDataModulePhaseII\n",
      "      hint_dir: ${paths.data_root_dir}/hint/\n",
      "      smiless_col: smiless\n",
      "      label_col: label\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 3\n",
      "      drop_last: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      visualize_kwargs: null\n",
      "  phase_III:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.Adam\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.05\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.warmup_wrapper.WarmUpWrapper\n",
      "        _partial_: true\n",
      "        warmup_steps:\n",
      "        - 10\n",
      "        interpolation: linear\n",
      "        wrapped_scheduler: ReduceLROnPlateau\n",
      "        cooldown: 3\n",
      "        factor: 0.6\n",
      "        patience: 7\n",
      "        min_lr: 1.0e-06\n",
      "        threshold: 0.0001\n",
      "        mode: min\n",
      "        verbose: true\n",
      "      _target_: src.eval.clinical_prediction.module.HintClinicalModulePhaseIII\n",
      "      lr: 0.001\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      example_input_path: ${model.example_input_path}\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/hint/phase_III/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 200\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.phase_III.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: hint/phase_III/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: hint/phase_III/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 15\n",
      "        verbose: false\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 4\n",
      "        log_graph: false\n",
      "        prefix: jump_moa/image/plots\n",
      "        cmap: Oranges_r\n",
      "        fmt: .2f\n",
      "        per_fmt: .1%\n",
      "        fz: 10\n",
      "        lw: 0.5\n",
      "        cbar: false\n",
      "        figsize:\n",
      "        - 16\n",
      "        - 16\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.clinical_prediction.datamodule.HintClinicalDataModulePhaseIII\n",
      "      hint_dir: ${paths.data_root_dir}/hint/\n",
      "      smiless_col: smiless\n",
      "      label_col: label\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 3\n",
      "      drop_last: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      visualize_kwargs: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(\n",
    "    config_name=\"train.yaml\",\n",
    "    overrides=[\n",
    "        \"evaluate=true\",\n",
    "        \"eval=hint\",\n",
    "        \"paths.projects_dir=..\",\n",
    "        \"paths.output_dir=./tmp/21312FS12A\",\n",
    "        \"trainer.devices=1\",\n",
    "        \"seed=22123\",\n",
    "        \"experiment=coati/med\",\n",
    "        \"trainer=gpu\",\n",
    "        \"trainer.devices=[1]\",\n",
    "        \"trainer.max_epochs=200\",\n",
    "        \"data.num_workers=12\",\n",
    "        \"data.transform.size=224\",\n",
    "        \"data.batch_size=4\",\n",
    "        \"model.embedding_dim=256\",\n",
    "        \"model/image_encoder=vit_base_16_224\",\n",
    "        \"model/criterion=ntxent_reg\",\n",
    "        \"model.criterion.alpha=0.2\",\n",
    "        \"model.criterion.mse_reg=0.5\",\n",
    "        \"model.criterion.variance_reg=1\",\n",
    "        \"model.criterion.covariance_reg=0.25\",\n",
    "        \"model.criterion.temperature=10\",\n",
    "        \"model.criterion.temperature_requires_grad=True\",\n",
    "    ],\n",
    ")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_name not found in tokenizer_vocabs, trying to load from file\n"
     ]
    }
   ],
   "source": [
    "dm = instantiate(cfg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.prepare_data()\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 250])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"compound\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 224, 224])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"image\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02836ca32c5494eaa11ec294a1b9491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_name not found in tokenizer_vocabs, trying to load from file\n",
      "number of parameters: 12.64M\n",
      "number of parameters Total: 2.44M xformer: 17.92M Total: 20.36M \n"
     ]
    }
   ],
   "source": [
    "model = instantiate(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in b.items()}\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = model.forward(**bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[\"compound_emb\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs[\"image_emb\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_nce = InfoNCE(temperature=1, return_rank=True, norm=True, eps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = embs[\"compound_emb\"]\n",
    "z2 = embs[\"image_emb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(1.3974, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'x_to_y_top1': tensor(0., device='cuda:0'),\n",
       " 'x_to_y_top5': tensor(1., device='cuda:0'),\n",
       " 'x_to_y_top10': tensor(1., device='cuda:0'),\n",
       " 'x_to_y_mean_pos': tensor(3.2500, device='cuda:0'),\n",
       " 'x_to_y_mean_pos_normed': tensor(0.8125, device='cuda:0'),\n",
       " 'y_to_x_top1': tensor(0., device='cuda:0'),\n",
       " 'y_to_x_top5': tensor(1., device='cuda:0'),\n",
       " 'y_to_x_top10': tensor(1., device='cuda:0'),\n",
       " 'y_to_x_mean_pos': tensor(2.5000, device='cuda:0'),\n",
       " 'y_to_x_mean_pos_normed': tensor(0.6250, device='cuda:0')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_nce(z1, z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(3.4728, device='cuda:0', grad_fn=<NegBackward0>),\n",
       " 'x_to_y_top1': tensor(0., device='cuda:0'),\n",
       " 'x_to_y_top5': tensor(0.1875, device='cuda:0'),\n",
       " 'x_to_y_top10': tensor(0.3125, device='cuda:0'),\n",
       " 'x_to_y_mean_pos': tensor(17.2500, device='cuda:0'),\n",
       " 'y_to_x_top1': tensor(0.0312, device='cuda:0'),\n",
       " 'y_to_x_top5': tensor(0.2500, device='cuda:0'),\n",
       " 'y_to_x_mean_pos': tensor(17.8125, device='cuda:0')}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_nce(z2, z1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
