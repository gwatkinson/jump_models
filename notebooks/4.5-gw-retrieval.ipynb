{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from hydra import compose, initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.utils import instantiate\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import CSVLogger, WandbLogger\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.functional import pairwise_cosine_similarity, retrieval_hit_rate\n",
    "from torchmetrics.retrieval import (\n",
    "    RetrievalFallOut,\n",
    "    RetrievalHitRate,\n",
    "    RetrievalMAP,\n",
    "    RetrievalMRR,\n",
    "    RetrievalNormalizedDCG,\n",
    "    RetrievalPrecision,\n",
    "    RetrievalRPrecision,\n",
    ")\n",
    "\n",
    "from src import utils\n",
    "from src.eval.retrieval import IDRRetrievalDataModule, IDRRetrievalEvaluator, IDRRetrievalModule\n",
    "from src.modules.compound_transforms import DGLPretrainedFromSmiles\n",
    "from src.modules.images import CNNEncoder\n",
    "from src.modules.molecules import GINPretrainedWithLinearHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpjump1 already mounted.\n",
      "cpjump2 already mounted.\n",
      "cpjump3 already mounted.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    if not Path(f\"../cpjump{i}/jump/\").exists():\n",
    "        print(f\"Mounting cpjump{i}...\")\n",
    "        os.system(f\"sshfs bioclust:/projects/cpjump{i}/ ../cpjump{i}\")\n",
    "    else:\n",
    "        print(f\"cpjump{i} already mounted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalHydra.instance().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize(version_base=None, config_path=\"../configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_name: train\n",
      "tags:\n",
      "- final_experiments\n",
      "- pretrained\n",
      "- ntxent\n",
      "- single_view\n",
      "- resnet34\n",
      "- pna\n",
      "train: true\n",
      "load_first_bacth: true\n",
      "test: true\n",
      "evaluate: true\n",
      "compile: false\n",
      "ckpt_path: null\n",
      "seed: 12345\n",
      "data:\n",
      "  compound_transform:\n",
      "    _target_: src.modules.compound_transforms.pna.PNATransform\n",
      "    compound_str_type: inchi\n",
      "  transform:\n",
      "    _target_: src.modules.transforms.ComplexTransform\n",
      "    _convert_: object\n",
      "    size: 512\n",
      "    flip_p: 0.5\n",
      "    resize_p: 0.3\n",
      "    color_p: 0.2\n",
      "    resize_min_ratio: 0.9\n",
      "    intensity: 0.2\n",
      "    brightness: 0.1\n",
      "    fill_nan: true\n",
      "    use_flip: true\n",
      "    use_blur: false\n",
      "    use_color_jitter: true\n",
      "    use_drop: false\n",
      "    use_resized_crop: true\n",
      "  _target_: src.models.jump_cl.datamodule.BasicJUMPDataModule\n",
      "  batch_size: 4\n",
      "  num_workers: 16\n",
      "  pin_memory: null\n",
      "  prefetch_factor: 2\n",
      "  drop_last: true\n",
      "  force_split: false\n",
      "  splitter:\n",
      "    _target_: src.splitters.RandomSplitter\n",
      "    train: 4096\n",
      "    test: 8192\n",
      "    val: 4096\n",
      "    retrieval: 4096\n",
      "  use_compond_cache: false\n",
      "  data_root_dir: ${paths.projects_dir}/\n",
      "  split_path: ${paths.split_path}/random_split/\n",
      "  dataloader_config:\n",
      "    train:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: true\n",
      "    val:\n",
      "      batch_size: ${data.batch_size}\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "    test:\n",
      "      batch_size: 100\n",
      "      num_workers: ${data.num_workers}\n",
      "      pin_memory: ${data.pin_memory}\n",
      "      prefetch_factor: ${data.prefetch_factor}\n",
      "      drop_last: ${data.drop_last}\n",
      "      shuffle: false\n",
      "  image_metadata_path: ${paths.metadata_path}/images_metadata.parquet\n",
      "  compound_metadata_path: ${paths.metadata_path}/compound_dict.json\n",
      "  compound_col: Metadata_InChI\n",
      "  image_sampler: null\n",
      "  metadata_dir: ${paths.raw_metadata_path}/complete_metadata.csv\n",
      "  local_load_data_dir: ${paths.load_data_path}/final/\n",
      "  index_str: '{Metadata_Source}__{Metadata_Batch}__{Metadata_Plate}__{Metadata_Well}__{Metadata_Site}'\n",
      "  channels:\n",
      "  - DNA\n",
      "  - AGP\n",
      "  - ER\n",
      "  - Mito\n",
      "  - RNA\n",
      "  col_fstring: FileName_Orig{channel}\n",
      "  id_cols:\n",
      "  - Metadata_Source\n",
      "  - Metadata_Batch\n",
      "  - Metadata_Plate\n",
      "  - Metadata_Well\n",
      "  extra_cols:\n",
      "  - Metadata_PlateType\n",
      "  - Metadata_Site\n",
      "  train_ids_name: train_small\n",
      "model:\n",
      "  image_encoder:\n",
      "    _target_: src.modules.images.timm_pretrained.CNNEncoder\n",
      "    instance_model_name: resnet34\n",
      "    n_channels: 5\n",
      "    pretrained: true\n",
      "    dropout: 0.0\n",
      "  molecule_encoder:\n",
      "    _target_: src.modules.molecules.pna.PNA\n",
      "    ckpt_path: ${paths.projects_dir}/cpjump1/jump/s3_cache/best_checkpoint_35epochs.pt\n",
      "    target_dim: 256\n",
      "    hidden_dim: 200\n",
      "    mid_batch_norm: true\n",
      "    last_batch_norm: true\n",
      "    readout_batchnorm: true\n",
      "    batch_norm_momentum: 0.93\n",
      "    readout_hidden_dim: 200\n",
      "    readout_layers: 2\n",
      "    dropout: 0.2\n",
      "    mlp_dropout: 0.05\n",
      "    propagation_depth: 7\n",
      "    aggregators:\n",
      "    - mean\n",
      "    - max\n",
      "    - min\n",
      "    - std\n",
      "    scalers:\n",
      "    - identity\n",
      "    - amplification\n",
      "    - attenuation\n",
      "    readout_aggregators:\n",
      "    - min\n",
      "    - max\n",
      "    - mean\n",
      "    pretrans_layers: 2\n",
      "    posttrans_layers: 1\n",
      "    residual: true\n",
      "  criterion:\n",
      "    _target_: src.modules.losses.contrastive_losses.NTXent\n",
      "    norm: true\n",
      "    temperature: 0.5\n",
      "    return_rank: true\n",
      "    temperature_requires_grad: false\n",
      "    temperature_min: 0\n",
      "    temperature_max: 100\n",
      "  optimizer:\n",
      "    _target_: torch.optim.AdamW\n",
      "    _partial_: true\n",
      "    betas:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    eps: 1.0e-08\n",
      "    weight_decay: 0.01\n",
      "    amsgrad: false\n",
      "    lr: ${model.lr}\n",
      "  scheduler:\n",
      "    _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "    _partial_: true\n",
      "    warmup_epochs: 10\n",
      "    max_epochs: ${trainer.max_epochs}\n",
      "    warmup_start_lr: 1.0e-05\n",
      "    eta_min: 0.0\n",
      "    last_epoch: -1\n",
      "  _target_: src.models.jump_cl.module.BasicJUMPModule\n",
      "  embedding_dim: 512\n",
      "  lr: 0.0003\n",
      "  batch_size: ${data.batch_size}\n",
      "  example_input_path: null\n",
      "  monitor: val/loss\n",
      "  interval: epoch\n",
      "  frequency: 1\n",
      "  split_lr_in_groups: false\n",
      "  model:\n",
      "    criterion:\n",
      "      temperature: 0.3\n",
      "callbacks:\n",
      "  rich_progress_bar:\n",
      "    _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "  model_summary:\n",
      "    _target_: lightning.pytorch.callbacks.RichModelSummary\n",
      "    max_depth: 2\n",
      "  model_checkpoint:\n",
      "    _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "    dirpath: ${paths.output_dir}/checkpoints\n",
      "    filename: epoch_{epoch:03d}\n",
      "    monitor: val/loss\n",
      "    verbose: false\n",
      "    save_last: true\n",
      "    save_top_k: 1\n",
      "    mode: min\n",
      "    auto_insert_metric_name: false\n",
      "    save_weights_only: false\n",
      "    every_n_train_steps: null\n",
      "    train_time_interval: null\n",
      "    every_n_epochs: null\n",
      "    save_on_train_epoch_end: null\n",
      "  early_stopping:\n",
      "    _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "    monitor: val/loss\n",
      "    min_delta: 0\n",
      "    patience: 25\n",
      "    verbose: true\n",
      "    mode: min\n",
      "    strict: true\n",
      "    check_finite: true\n",
      "    stopping_threshold: null\n",
      "    divergence_threshold: null\n",
      "    check_on_train_epoch_end: null\n",
      "  timer:\n",
      "    _target_: lightning.pytorch.callbacks.Timer\n",
      "    duration: 07:00:00:00\n",
      "    interval: epoch\n",
      "    verbose: true\n",
      "  nan_loss:\n",
      "    _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "  wandb_watcher:\n",
      "    _target_: src.callbacks.wandb.WandbTrainingCallback\n",
      "    watch: true\n",
      "    watch_log: all\n",
      "    log_freq: 100\n",
      "    log_graph: false\n",
      "  temperature_logger:\n",
      "    _target_: src.callbacks.temperature_log.TemperatureLoggingCallback\n",
      "    attribute_name:\n",
      "    - criterion\n",
      "    - temperature\n",
      "    key: model/temperature\n",
      "    interval: step\n",
      "    frequency: 1\n",
      "  lr_monitor:\n",
      "    _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "    logging_interval: null\n",
      "    log_momentum: false\n",
      "logger:\n",
      "  wandb:\n",
      "    _target_: lightning.pytorch.loggers.wandb.WandbLogger\n",
      "    save_dir: ${paths.output_dir}\n",
      "    offline: false\n",
      "    id: null\n",
      "    anonymous: null\n",
      "    project: final_experiments\n",
      "    log_model: true\n",
      "    prefix: ''\n",
      "    group: dataset_experiment\n",
      "    tags: ${tags}\n",
      "    job_type: pretrain\n",
      "    name: small_dataset\n",
      "trainer:\n",
      "  _target_: lightning.pytorch.trainer.Trainer\n",
      "  default_root_dir: ${paths.output_dir}\n",
      "  min_epochs: 0\n",
      "  max_epochs: 200\n",
      "  accelerator: gpu\n",
      "  detect_anomaly: true\n",
      "  devices: 1\n",
      "  check_val_every_n_epoch: 1\n",
      "  deterministic: false\n",
      "  log_every_n_steps: 1\n",
      "  num_sanity_val_steps: 1\n",
      "paths:\n",
      "  root_dir: ${oc.env:PROJECT_ROOT}\n",
      "  projects_dir: ..\n",
      "  data_root_dir: ${paths.projects_dir}/cpjump1\n",
      "  metadata_path: ${paths.data_root_dir}/jump/models/metadata\n",
      "  raw_metadata_path: ${paths.data_root_dir}/jump/metadata\n",
      "  load_data_path: ${paths.data_root_dir}/jump/load_data\n",
      "  model_dir: ${paths.data_root_dir}/jump/s3_cache\n",
      "  split_path: ${paths.data_root_dir}/jump/models/splits\n",
      "  log_dir: ${paths.data_root_dir}/jump/logs\n",
      "  output_dir: ./tmp/21312FS12A\n",
      "  work_dir: ${hydra:runtime.cwd}\n",
      "extras:\n",
      "  ignore_warnings: true\n",
      "  style: dim\n",
      "  enforce_tags: true\n",
      "  print_config: true\n",
      "eval:\n",
      "  simple_retrieval:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/simple_retrieval/\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.simple_retrieval.evaluator.SimpleRetrievalEvaluator\n",
      "      name: IDRRetrieval\n",
      "      visualize_kwargs: null\n",
      "    model:\n",
      "      _target_: src.eval.simple_retrieval.module.SimpleRetrievalModule\n",
      "      example_input_path: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.simple_retrieval.datamodule.SimpleRetrievalDataModule\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      transform: ${data.transform}\n",
      "      batch_size: 100\n",
      "      num_workers: 12\n",
      "      pin_memory: null\n",
      "      prefetch_factor: null\n",
      "      drop_last: true\n",
      "      use_compond_cache: false\n",
      "      data_root_dir: ${paths.projects_dir}/\n",
      "      split_path: ${data.split_path}\n",
      "      channels:\n",
      "      - DNA\n",
      "      - AGP\n",
      "      - ER\n",
      "      - Mito\n",
      "      - RNA\n",
      "    callbacks: null\n",
      "  idr_graph_retrieval:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/retrieval/idr/\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "    model:\n",
      "      _target_: src.eval.retrieval.module.IDRRetrievalModule\n",
      "      example_input_path: null\n",
      "    datamodule:\n",
      "      _target_: src.eval.retrieval.datamodule.IDRRetrievalDataModule\n",
      "      image_metadata_path: ${paths.data_root_dir}/idr0033-rohban-pathways/processed_metadata.csv\n",
      "      excape_db_path: ${paths.data_root_dir}/excape-db/excape_db_df.csv\n",
      "      selected_group_path: ${paths.data_root_dir}/excape-db/processed_groups.json\n",
      "      data_root_dir: ${paths.data_root_dir}/screen_1751\n",
      "      image_batch_size: 128\n",
      "      compound_batch_size: 1\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      transform: ${data.transform}\n",
      "      image_gene_col: Gene Symbol\n",
      "      col_fstring: FileName_{channel}\n",
      "      channels: null\n",
      "      target_col: Activity_Flag\n",
      "      smiles_col: SMILES\n",
      "    evaluator:\n",
      "      _target_: src.eval.retrieval.evaluator.IDRRetrievalEvaluator\n",
      "      name: IDRRetrieval\n",
      "      visualize_kwargs: null\n",
      "    callbacks: null\n",
      "  batch_effect:\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/batch_effect/new\n",
      "      min_epochs: 5\n",
      "      max_epochs: 20\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.batch_effect.evaluator.BatchEffectEvaluator\n",
      "      dmso_normalize: false\n",
      "      normalize_cls: null\n",
      "      embedding_col: projection\n",
      "      test_size: 0.2\n",
      "      nruns: 5\n",
      "      plot: true\n",
      "      logistic: true\n",
      "      knn: true\n",
      "      batch_split: true\n",
      "      plate_split: true\n",
      "      source_split: true\n",
      "      well_split: true\n",
      "      fully_random_split: true\n",
      "      out_dir: ${paths.output_dir}/eval/batch_effect/new/\n",
      "      name: null\n",
      "      visualize_kwargs: null\n",
      "    model:\n",
      "      _target_: src.eval.batch_effect.module.TotalBatchEffectModule\n",
      "    datamodule:\n",
      "      _target_: src.eval.batch_effect.datamodule.TotalBatchEffectDataModule\n",
      "      target_load_df_path: ${paths.data_root_dir}/jump/models/eval/batch_effect/splits/target_load_df.csv\n",
      "      dmso_load_df_path: ${paths.data_root_dir}/jump/models/eval/batch_effect/splits/dmso_load_df.csv\n",
      "      subset_targets: 10\n",
      "      label_col: target\n",
      "      source_col: Metadata_Source\n",
      "      batch_col: Metadata_Batch\n",
      "      plate_col: Metadata_Plate\n",
      "      well_col: Metadata_Well\n",
      "      batch_size: 128\n",
      "      num_workers: 12\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      drop_last: false\n",
      "      transform:\n",
      "        _target_: src.modules.transforms.SimpleTransform\n",
      "        _convert_: object\n",
      "        size: ${data.transform.size}\n",
      "      metadata_path: ${paths.raw_metadata_path}\n",
      "      load_data_path: ${paths.load_data_path}\n",
      "      data_root_dir: null\n",
      "      random_state: 42\n",
      "    callbacks: null\n",
      "  plate_normalized:\n",
      "    batch_effect:\n",
      "      trainer:\n",
      "        _target_: lightning.pytorch.trainer.Trainer\n",
      "        default_root_dir: ${paths.output_dir}/eval/batch_effect/new\n",
      "        min_epochs: 5\n",
      "        max_epochs: 20\n",
      "        accelerator: gpu\n",
      "        detect_anomaly: true\n",
      "        devices: ${trainer.devices}\n",
      "        check_val_every_n_epoch: 1\n",
      "        deterministic: false\n",
      "      evaluator:\n",
      "        _target_: src.eval.batch_effect.evaluator.BatchEffectEvaluator\n",
      "        dmso_normalize: false\n",
      "        normalize_cls: null\n",
      "        embedding_col: projection\n",
      "        test_size: 0.2\n",
      "        nruns: 5\n",
      "        plot: true\n",
      "        logistic: true\n",
      "        knn: true\n",
      "        batch_split: true\n",
      "        plate_split: true\n",
      "        source_split: true\n",
      "        well_split: true\n",
      "        fully_random_split: true\n",
      "        out_dir: ${paths.output_dir}/eval/batch_effect/new/\n",
      "        name: null\n",
      "        visualize_kwargs: null\n",
      "      model:\n",
      "        _target_: src.eval.batch_effect.module.TotalBatchEffectModule\n",
      "      datamodule:\n",
      "        _target_: src.eval.batch_effect.datamodule.TotalBatchEffectDataModule\n",
      "        target_load_df_path: ${paths.data_root_dir}/jump/models/eval/batch_effect/splits/target_load_df.csv\n",
      "        dmso_load_df_path: ${paths.data_root_dir}/jump/models/eval/batch_effect/splits/dmso_load_df.csv\n",
      "        subset_targets: 10\n",
      "        label_col: target\n",
      "        source_col: Metadata_Source\n",
      "        batch_col: Metadata_Batch\n",
      "        plate_col: Metadata_Plate\n",
      "        well_col: Metadata_Well\n",
      "        batch_size: 128\n",
      "        num_workers: 12\n",
      "        pin_memory: false\n",
      "        prefetch_factor: 2\n",
      "        drop_last: false\n",
      "        transform:\n",
      "          _target_: src.modules.transforms.SimpleTransform\n",
      "          _convert_: object\n",
      "          size: ${data.transform.size}\n",
      "        metadata_path: ${paths.raw_metadata_path}\n",
      "        load_data_path: ${paths.load_data_path}\n",
      "        data_root_dir: null\n",
      "        random_state: 42\n",
      "      callbacks: null\n",
      "    evaluator:\n",
      "      _target_: src.eval.batch_effect.evaluator.BatchEffectEvaluator\n",
      "      dmso_normalize: plate\n",
      "      normalize_cls:\n",
      "        _target_: src.eval.batch_effect.spherize.ZCA_corr\n",
      "        _partial_: true\n",
      "  tox21:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 3\n",
      "        max_epochs: ${eval.tox21.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.Tox21Module\n",
      "      lr: 0.0001\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/tox21/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 50\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.tox21.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/tox21/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/tox21/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: ogb/tox21\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.Tox21DataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: Tox21Module\n",
      "      visualize_kwargs: null\n",
      "  lipo:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 3\n",
      "        max_epochs: ${eval.lipo.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.LipoModule\n",
      "      lr: 0.0001\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/lipo/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 50\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.lipo.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/lipo/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/lipo/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: ogb/lipo\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.LipoDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: LipoModule\n",
      "      visualize_kwargs: null\n",
      "  esol:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 3\n",
      "        max_epochs: ${eval.esol.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.EsolModule\n",
      "      lr: 0.0001\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/esol/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 50\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.esol.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/esol/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/esol/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: ogb/esol\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.EsolDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: EsolModule\n",
      "      visualize_kwargs: null\n",
      "  bbbp:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 3\n",
      "        max_epochs: ${eval.bbbp.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.BBBPModule\n",
      "      lr: 0.0001\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/bbbp/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 25\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.bbbp.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/bbbp/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/bbbp/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: ogb/bbbp\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.BBBPDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: BBBPModule\n",
      "      visualize_kwargs: null\n",
      "  hiv:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 3\n",
      "        max_epochs: ${eval.hiv.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.ogb.module.HIVModule\n",
      "      lr: 0.0001\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/ogb/hiv/\n",
      "      min_epochs: 0\n",
      "      max_epochs: 50\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.hiv.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: ogb/hiv/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: ogb/hiv/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: ogb/hiv\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.ogb.datamodule.HIVDataModule\n",
      "      root_dir: ${paths.data_root_dir}/ogb/\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      split_type: scaffold\n",
      "      smiles_col: smiles\n",
      "      targets: null\n",
      "      use_cache: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: HIVModule\n",
      "      visualize_kwargs: null\n",
      "  phaseI:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 5\n",
      "        max_epochs: ${eval.phaseI.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.clinical_prediction.module.HintClinicalModule\n",
      "      phase: I\n",
      "      lr: 0.0001\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/hint/default_hint\n",
      "      min_epochs: 0\n",
      "      max_epochs: 50\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.phaseI.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: hint/phase_I/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: hint/phase_I/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: hint/phase_I\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.clinical_prediction.datamodule.HintClinicalDataModule\n",
      "      phase: I\n",
      "      hint_dir: ${paths.data_root_dir}/hint-clinical-trial-outcome-prediction/data\n",
      "      smiless_col: smiless\n",
      "      label_col: label\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      drop_last: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: hint/phase_I\n",
      "      visualize_kwargs: null\n",
      "  phaseII:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 5\n",
      "        max_epochs: ${eval.phaseI.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.clinical_prediction.module.HintClinicalModule\n",
      "      phase: II\n",
      "      lr: 0.0001\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/hint/default_hint\n",
      "      min_epochs: 0\n",
      "      max_epochs: 50\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.phaseII.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: hint/phase_II/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: hint/phase_II/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: hint/phase_II\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.clinical_prediction.datamodule.HintClinicalDataModule\n",
      "      phase: II\n",
      "      hint_dir: ${paths.data_root_dir}/hint-clinical-trial-outcome-prediction/data\n",
      "      smiless_col: smiless\n",
      "      label_col: label\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      drop_last: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: hint/phase_II\n",
      "      visualize_kwargs: null\n",
      "  phaseIII:\n",
      "    model:\n",
      "      optimizer:\n",
      "        _target_: torch.optim.AdamW\n",
      "        _partial_: true\n",
      "        betas:\n",
      "        - 0.9\n",
      "        - 0.999\n",
      "        eps: 1.0e-08\n",
      "        weight_decay: 0.01\n",
      "        amsgrad: false\n",
      "      scheduler:\n",
      "        _target_: src.modules.lr_schedulers.cosine_lr.LinearWarmupCosineAnnealingLR\n",
      "        _partial_: true\n",
      "        warmup_epochs: 5\n",
      "        max_epochs: ${eval.phaseI.trainer.max_epochs}\n",
      "        warmup_start_lr: 1.0e-05\n",
      "        eta_min: 0.0\n",
      "        last_epoch: -1\n",
      "      _target_: src.eval.clinical_prediction.module.HintClinicalModule\n",
      "      phase: III\n",
      "      lr: 0.0001\n",
      "      compound_transform: ${data.compound_transform}\n",
      "      example_input_path: ${model.example_input_path}\n",
      "      split_lr_in_groups: false\n",
      "    trainer:\n",
      "      _target_: lightning.pytorch.trainer.Trainer\n",
      "      default_root_dir: ${paths.output_dir}/eval/hint/default_hint\n",
      "      min_epochs: 0\n",
      "      max_epochs: 50\n",
      "      accelerator: gpu\n",
      "      detect_anomaly: true\n",
      "      devices: ${trainer.devices}\n",
      "      check_val_every_n_epoch: 1\n",
      "      deterministic: false\n",
      "      log_every_n_steps: 1\n",
      "      num_sanity_val_steps: 1\n",
      "    callbacks:\n",
      "      rich_progress_bar:\n",
      "        _target_: lightning.pytorch.callbacks.RichProgressBar\n",
      "      model_checkpoint:\n",
      "        _target_: lightning.pytorch.callbacks.ModelCheckpoint\n",
      "        dirpath: ${eval.phaseIII.trainer.default_root_dir}/checkpoints\n",
      "        filename: null\n",
      "        monitor: hint/phase_III/val/loss\n",
      "        verbose: false\n",
      "        save_last: false\n",
      "        save_top_k: 1\n",
      "        mode: min\n",
      "        auto_insert_metric_name: null\n",
      "        save_weights_only: false\n",
      "        every_n_train_steps: null\n",
      "        train_time_interval: null\n",
      "        every_n_epochs: null\n",
      "        save_on_train_epoch_end: null\n",
      "      early_stopping:\n",
      "        _target_: lightning.pytorch.callbacks.EarlyStopping\n",
      "        monitor: hint/phase_III/val/loss\n",
      "        min_delta: 0\n",
      "        patience: 25\n",
      "        verbose: true\n",
      "        mode: min\n",
      "        strict: true\n",
      "        check_finite: true\n",
      "        stopping_threshold: null\n",
      "        divergence_threshold: null\n",
      "        check_on_train_epoch_end: null\n",
      "      wandb_plotter:\n",
      "        _target_: src.callbacks.wandb.WandbPlottingCallback\n",
      "        watch: false\n",
      "        watch_log: all\n",
      "        log_freq: 50\n",
      "        plot_every_n_epoch: 1\n",
      "        log_graph: false\n",
      "        prefix: hint/phase_III\n",
      "        fig_kws:\n",
      "          figsize:\n",
      "          - 16\n",
      "          - 16\n",
      "        plot_kws:\n",
      "          annot: true\n",
      "          cmap: Blues\n",
      "          cbar: false\n",
      "          square: true\n",
      "          robust: true\n",
      "          fmt: g\n",
      "      nan_loss:\n",
      "        _target_: src.callbacks.nan_loss.NaNLossCallback\n",
      "      lr_monitor:\n",
      "        _target_: lightning.pytorch.callbacks.LearningRateMonitor\n",
      "        logging_interval: null\n",
      "        log_momentum: false\n",
      "    datamodule:\n",
      "      _target_: src.eval.clinical_prediction.datamodule.HintClinicalDataModule\n",
      "      phase: III\n",
      "      hint_dir: ${paths.data_root_dir}/hint-clinical-trial-outcome-prediction/data\n",
      "      smiless_col: smiless\n",
      "      label_col: label\n",
      "      batch_size: 256\n",
      "      num_workers: 16\n",
      "      pin_memory: false\n",
      "      prefetch_factor: 2\n",
      "      drop_last: false\n",
      "    evaluator:\n",
      "      _target_: src.eval.evaluators.Evaluator\n",
      "      name: hint/phase_III\n",
      "      visualize_kwargs: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(\n",
    "    config_name=\"train.yaml\",\n",
    "    overrides=[\n",
    "        \"evaluate=true\",\n",
    "        \"eval=evaluators\",\n",
    "        \"paths.projects_dir=..\",\n",
    "        \"paths.output_dir=./tmp/21312FS12A\",\n",
    "        \"experiment=final/dataset_experiments/small.yaml\",\n",
    "        \"data.batch_size=4\",\n",
    "        \"trainer.devices=1\",\n",
    "    ],\n",
    ")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['simple_retrieval', 'idr_graph_retrieval', 'batch_effect', 'plate_normalized', 'tox21', 'lipo', 'esol', 'bbbp', 'hiv', 'phaseI', 'phaseII', 'phaseIII'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.eval.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}/eval/simple_retrieval/', 'min_epochs': 5, 'max_epochs': 20, 'accelerator': 'gpu', 'detect_anomaly': True, 'devices': '${trainer.devices}', 'check_val_every_n_epoch': 1, 'deterministic': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.eval.simple_retrieval.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.eval.simple_retrieval.datamodule.batch_size = 4\n",
    "cfg.eval.simple_retrieval.trainer.devices = 1\n",
    "\n",
    "with open_dict(cfg.eval.simple_retrieval.trainer):\n",
    "    cfg.eval.simple_retrieval.trainer.limit_predict_batches = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/gwatk/miniconda3/envs/jump_models/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "simple = utils.instantiate_evaluator(cfg.eval.simple_retrieval, cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2023-09-26 13:43:14,623\u001b[0m][\u001b[34msrc.eval.simple_retrieval.datamodule\u001b[0m][\u001b[32mINFO\u001b[0m] - Preparing retrieval dataset\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing retrieval dataset\n"
     ]
    }
   ],
   "source": [
    "simple.datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = simple.datamodule.predict_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataloader_idx': 0,\n",
       " 'batch_idx': 0,\n",
       " 'compound_str': ['InChI=1S/C10H10ClN3O2/c11-7-2-1-3-8(4-7)14-10(6-16)9(5-15)12-13-14/h1-4,15-16H,5-6H2',\n",
       "  'InChI=1S/C10H10ClN3O2S2/c11-9-1-2-10(17-9)18(15,16)14-4-3-7-8(5-14)13-6-12-7/h1-2,6H,3-5H2,(H,12,13)',\n",
       "  'InChI=1S/C10H10N2O3S2/c1-2-5-3-6-8(15)11-10(12-9(6)17-5)16-4-7(13)14/h3H,2,4H2,1H3,(H,13,14)(H,11,12,15)',\n",
       "  'InChI=1S/C10H10N4O2/c1-16-10(15)8-9(11)13-14(12-8)7-5-3-2-4-6-7/h2-6H,1H3,(H2,11,13)'],\n",
       " 'image_id': ['source_6__p210928CPU2OS48hw384exp030JUMP__110000296383__M17__5',\n",
       "  'source_5__JUMPCPE-20211001-Run33_20211001_152017__AEOJUM806__I07__7',\n",
       "  'source_1__Batch1_20221004__UL001643__Z17__2',\n",
       "  'source_9__20210915-Run10__GR00003307__Z43__1'],\n",
       " 'compound_emb': tensor([[-0.0327,  0.0117,  0.0466,  ...,  0.0163,  0.0128,  0.0203],\n",
       "         [ 0.0585,  0.0194,  0.0242,  ...,  0.0032,  0.0170, -0.0668],\n",
       "         [ 0.0341, -0.0110,  0.0852,  ...,  0.1249,  0.0764, -0.0036],\n",
       "         [ 0.0528,  0.0212,  0.0700,  ...,  0.0390,  0.0383,  0.0051]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " 'image_emb': tensor([[ 0.1889, -0.0938, -0.0255,  ..., -0.0303, -0.0113, -0.0688],\n",
       "         [ 0.1432, -0.0181, -0.0640,  ..., -0.0263,  0.0356, -0.0011],\n",
       "         [ 0.0676, -0.0901, -0.0606,  ...,  0.0577,  0.0072, -0.0194],\n",
       "         [ 0.0909, -0.0968, -0.0316,  ..., -0.0328, -0.0229, -0.0463]],\n",
       "        grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple.model.predict_step(b, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e4f40907e04e4dafb22991e31d9167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = simple.trainer.predict(simple.model, simple.datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dataloader_idx': 0,\n",
       "  'batch_idx': 0,\n",
       "  'compound_str': ['InChI=1S/C10H10ClN3O2/c11-7-2-1-3-8(4-7)14-10(6-16)9(5-15)12-13-14/h1-4,15-16H,5-6H2',\n",
       "   'InChI=1S/C10H10ClN3O2S2/c11-9-1-2-10(17-9)18(15,16)14-4-3-7-8(5-14)13-6-12-7/h1-2,6H,3-5H2,(H,12,13)',\n",
       "   'InChI=1S/C10H10N2O3S2/c1-2-5-3-6-8(15)11-10(12-9(6)17-5)16-4-7(13)14/h3H,2,4H2,1H3,(H,13,14)(H,11,12,15)',\n",
       "   'InChI=1S/C10H10N4O2/c1-16-10(15)8-9(11)13-14(12-8)7-5-3-2-4-6-7/h2-6H,1H3,(H2,11,13)'],\n",
       "  'image_id': ['source_6__p210928CPU2OS48hw384exp030JUMP__110000296383__M17__9',\n",
       "   'source_10__2021_08_09_U2OS_48_hr_run13__Dest210727-153138__P06__1',\n",
       "   'source_8__J4__A1166164__M09__4',\n",
       "   'source_11__Batch5__EC000080__N08__4'],\n",
       "  'compound_emb': tensor([[ 0.0163,  0.0241,  0.0165,  ...,  0.0816,  0.0436, -0.0081],\n",
       "          [ 0.0281,  0.0094,  0.0201,  ...,  0.0373,  0.0158,  0.0103],\n",
       "          [-0.0392, -0.0008,  0.0729,  ...,  0.0593,  0.0104, -0.0258],\n",
       "          [ 0.0009,  0.0181,  0.0571,  ...,  0.0711,  0.0079, -0.0134]]),\n",
       "  'image_emb': tensor([[ 0.0863, -0.0318, -0.0167,  ...,  0.0291,  0.0392, -0.1172],\n",
       "          [ 0.0793, -0.0447, -0.0323,  ...,  0.0033,  0.0031, -0.0919],\n",
       "          [ 0.0911, -0.0296, -0.0203,  ...,  0.0418,  0.0156, -0.1114],\n",
       "          [ 0.1270, -0.0573, -0.0168,  ...,  0.0009,  0.0026, -0.0698]])},\n",
       " {'dataloader_idx': 0,\n",
       "  'batch_idx': 1,\n",
       "  'compound_str': ['InChI=1S/C10H10N4O2/c1-6-9(7(2)13-12-6)10-8(14(15)16)4-3-5-11-10/h3-5H,1-2H3,(H,12,13)',\n",
       "   'InChI=1S/C10H10N4O3/c1-6-5-9(12-10(11-6)16-2)17-8-4-3-7(15)13-14-8/h3-5H,1-2H3,(H,13,15)',\n",
       "   'InChI=1S/C10H10N4O4S2/c1-4-7(5(2)18-14-4)8(17)11-9-12-13-10(20-9)19-3-6(15)16/h3H2,1-2H3,(H,15,16)(H,11,12,17)',\n",
       "   'InChI=1S/C10H10N6O4/c17-9(11-6-1-2-6)10-12-7(14-20-10)5-15-4-3-8(13-15)16(18)19/h3-4,6H,1-2,5H2,(H,11,17)'],\n",
       "  'image_id': ['source_8__J4__A1166166__H19__3',\n",
       "   'source_8__J4__A1166163__E06__2',\n",
       "   'source_3__CP_33_all_Phenix1__A12079bW__I17__1',\n",
       "   'source_11__Batch3__EC000142__M09__1'],\n",
       "  'compound_emb': tensor([[ 0.0525,  0.0070,  0.1053,  ...,  0.0853,  0.0572, -0.0035],\n",
       "          [ 0.0197,  0.0357,  0.0446,  ...,  0.0664,  0.0450, -0.0087],\n",
       "          [-0.0014,  0.0135,  0.0551,  ...,  0.0661,  0.0424, -0.0174],\n",
       "          [ 0.1004,  0.0936,  0.2372,  ...,  0.0911,  0.0595, -0.1048]]),\n",
       "  'image_emb': tensor([[ 0.1239, -0.0516, -0.0449,  ..., -0.0115, -0.0127, -0.0936],\n",
       "          [ 0.0978, -0.0466, -0.0359,  ..., -0.0152, -0.0083, -0.0954],\n",
       "          [ 0.0860, -0.0382,  0.0008,  ...,  0.0426,  0.0249, -0.1219],\n",
       "          [ 0.1099, -0.0344, -0.0283,  ...,  0.0397,  0.0236, -0.1076]])},\n",
       " {'dataloader_idx': 0,\n",
       "  'batch_idx': 2,\n",
       "  'compound_str': ['InChI=1S/C10H10O2/c1-7(11)10-6-8-4-2-3-5-9(8)12-10/h2-7,11H,1H3',\n",
       "   'InChI=1S/C10H11BrN4O/c1-6-9(11)7(2)15(13-6)10(16)8-4-5-12-14(8)3/h4-5H,1-3H3',\n",
       "   'InChI=1S/C10H11BrN4O/c11-8-7-13-10-9(12-1-2-15(8)10)14-3-5-16-6-4-14/h1-2,7H,3-6H2',\n",
       "   'InChI=1S/C10H11N3O2S3/c1-6(2)18(14,15)9-8(13)7(5-12)17-10(9)16-4-3-11/h6H,4,13H2,1-2H3'],\n",
       "  'image_id': ['source_10__2021_06_14_U2OS_48_hr_run5__Dest210614-163756__G08__3',\n",
       "   'source_10__2021_08_03_U2OS_48_hr_run12__Dest210726-163500__I16__2',\n",
       "   'source_2__20210808_Batch_4__1086292945__C05__2',\n",
       "   'source_8__J4__A1166167__O05__3'],\n",
       "  'compound_emb': tensor([[ 0.0778,  0.0431,  0.1223,  ...,  0.0938,  0.0760, -0.0098],\n",
       "          [-0.0139,  0.0031,  0.0590,  ...,  0.0772,  0.0404, -0.0195],\n",
       "          [ 0.0190,  0.0016,  0.0619,  ...,  0.0990,  0.0559, -0.0067],\n",
       "          [-0.0293, -0.2459,  1.1862,  ...,  0.4461, -0.9868, -0.0155]]),\n",
       "  'image_emb': tensor([[ 0.1009, -0.0327, -0.0480,  ...,  0.0360,  0.0047, -0.1027],\n",
       "          [ 0.1201, -0.0264, -0.0257,  ...,  0.0211,  0.0044, -0.1014],\n",
       "          [ 0.1100, -0.0409, -0.0257,  ...,  0.0306,  0.0066, -0.0988],\n",
       "          [ 0.0888, -0.0385, -0.0330,  ...,  0.0365,  0.0241, -0.1050]])}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = defaultdict(list)\n",
    "\n",
    "for batch_res in predictions:\n",
    "    # batch_res contains image_emb, compound_emb, compound_str, image_id\n",
    "    image_emb = batch_res[\"image_emb\"]\n",
    "    compound_emb = batch_res[\"compound_emb\"]\n",
    "\n",
    "    dist = simple.distance_metric(image_emb, compound_emb)  # Similarity matrix between images and compounds: 100 x 100\n",
    "\n",
    "    indexes_mol_to_img = torch.arange(dist.shape[1]).expand(\n",
    "        dist.shape\n",
    "    )  # 100 x 100 matrix with the indexes of the compounds\n",
    "    indexes_img_to_mol = indexes_mol_to_img.transpose(0, 1)  # 100 x 100 matrix with the indexes of the images\n",
    "    target = torch.eye(dist.shape[1])  # Identity matrix: 100 x 100\n",
    "\n",
    "    res_mol_to_img = simple.retrieval_metrics(\n",
    "        preds=dist, target=target, indexes=indexes_mol_to_img\n",
    "    )  # Dictionary with the metrics for mol to img\n",
    "    res_img_to_mol = simple.retrieval_metrics(\n",
    "        preds=dist, target=target, indexes=indexes_img_to_mol\n",
    "    )  # Dictionary with the metrics for img to mol\n",
    "\n",
    "    for metric in simple.metric_keys:\n",
    "        result_dict[f\"retrieval/1:100/mol_to_img/{metric}\"].append(res_mol_to_img[metric])\n",
    "        result_dict[f\"retrieval/1:100/img_to_mol/{metric}\"].append(res_img_to_mol[metric])\n",
    "        result_dict[f\"retrieval/1:100/avg/{metric}\"].append((res_mol_to_img[metric] + res_img_to_mol[metric]) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in simple.metric_keys:\n",
    "    result_dict[f\"retrieval/1:100/mol_to_img/{metric}_avg\"] = np.mean(\n",
    "        result_dict[f\"retrieval/1:100/mol_to_img/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:100/img_to_mol/{metric}_avg\"] = np.mean(\n",
    "        result_dict[f\"retrieval/1:100/img_to_mol/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:100/avg/{metric}_avg\"] = np.mean(result_dict[f\"retrieval/1:100/avg/{metric}\"])\n",
    "    result_dict[f\"retrieval/1:100/mol_to_img/{metric}_std\"] = np.std(\n",
    "        result_dict[f\"retrieval/1:100/mol_to_img/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:100/img_to_mol/{metric}_std\"] = np.std(\n",
    "        result_dict[f\"retrieval/1:100/img_to_mol/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:100/avg/{metric}_std\"] = np.std(result_dict[f\"retrieval/1:100/avg/{metric}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'retrieval/1:100/mol_to_img/RetrievalFallOut_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalFallOut_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/avg/RetrievalFallOut_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalFallOut_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalFallOut_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/avg/RetrievalFallOut_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_03': [tensor(0.7500),\n",
       "              tensor(0.7500),\n",
       "              tensor(0.7500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_03': [tensor(0.7500),\n",
       "              tensor(0.7500),\n",
       "              tensor(0.7500)],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_03': [tensor(0.7500),\n",
       "              tensor(0.7500),\n",
       "              tensor(0.7500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_10': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_10': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_10': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMAP_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMAP_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/avg/RetrievalMAP_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMAP_top_05': [tensor(0.5208),\n",
       "              tensor(0.5208),\n",
       "              tensor(0.5208)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMAP_top_05': [tensor(0.5208),\n",
       "              tensor(0.5625),\n",
       "              tensor(0.5208)],\n",
       "             'retrieval/1:100/avg/RetrievalMAP_top_05': [tensor(0.5208),\n",
       "              tensor(0.5417),\n",
       "              tensor(0.5208)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMRR': [tensor(0.5208),\n",
       "              tensor(0.5208),\n",
       "              tensor(0.5208)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMRR': [tensor(0.5208),\n",
       "              tensor(0.5625),\n",
       "              tensor(0.5208)],\n",
       "             'retrieval/1:100/avg/RetrievalMRR': [tensor(0.5208),\n",
       "              tensor(0.5417),\n",
       "              tensor(0.5208)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalNormalizedDCG': [tensor(0.6404),\n",
       "              tensor(0.6404),\n",
       "              tensor(0.6404)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalNormalizedDCG': [tensor(0.6404),\n",
       "              tensor(0.6731),\n",
       "              tensor(0.6404)],\n",
       "             'retrieval/1:100/avg/RetrievalNormalizedDCG': [tensor(0.6404),\n",
       "              tensor(0.6568),\n",
       "              tensor(0.6404)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_03': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_03': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_03': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_05': [tensor(0.2000),\n",
       "              tensor(0.2000),\n",
       "              tensor(0.2000)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_05': [tensor(0.2000),\n",
       "              tensor(0.2000),\n",
       "              tensor(0.2000)],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_05': [tensor(0.2000),\n",
       "              tensor(0.2000),\n",
       "              tensor(0.2000)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_10': [tensor(0.1000),\n",
       "              tensor(0.1000),\n",
       "              tensor(0.1000)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_10': [tensor(0.1000),\n",
       "              tensor(0.1000),\n",
       "              tensor(0.1000)],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_10': [tensor(0.1000),\n",
       "              tensor(0.1000),\n",
       "              tensor(0.1000)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_50': [tensor(0.0200),\n",
       "              tensor(0.0200),\n",
       "              tensor(0.0200)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_50': [tensor(0.0200),\n",
       "              tensor(0.0200),\n",
       "              tensor(0.0200)],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_50': [tensor(0.0200),\n",
       "              tensor(0.0200),\n",
       "              tensor(0.0200)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_01': [tensor(0.2500),\n",
       "              tensor(0.2500),\n",
       "              tensor(0.2500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_03': [tensor(0.7500),\n",
       "              tensor(0.7500),\n",
       "              tensor(0.7500)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_03': [tensor(0.7500),\n",
       "              tensor(0.7500),\n",
       "              tensor(0.7500)],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_03': [tensor(0.7500),\n",
       "              tensor(0.7500),\n",
       "              tensor(0.7500)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_05': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_10': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_10': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_10': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_50': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_50': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_50': [tensor(1.),\n",
       "              tensor(1.),\n",
       "              tensor(1.)],\n",
       "             'mol_to_img/RetrievalFallOut_top_01': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalFallOut_top_01_avg': 0.25,\n",
       "             'img_to_mol/RetrievalFallOut_top_01': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalFallOut_top_01_avg': 0.25,\n",
       "             'avg/RetrievalFallOut_top_01': [],\n",
       "             'retrieval/1:100/avg/RetrievalFallOut_top_01_avg': 0.25,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalFallOut_top_01_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalFallOut_top_01_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalFallOut_top_01_std': 0.0,\n",
       "             'mol_to_img/RetrievalFallOut_top_05': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalFallOut_top_05_avg': 1.0,\n",
       "             'img_to_mol/RetrievalFallOut_top_05': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalFallOut_top_05_avg': 1.0,\n",
       "             'avg/RetrievalFallOut_top_05': [],\n",
       "             'retrieval/1:100/avg/RetrievalFallOut_top_05_avg': 1.0,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalFallOut_top_05_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalFallOut_top_05_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalFallOut_top_05_std': 0.0,\n",
       "             'mol_to_img/RetrievalHitRate_top_01': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_01_avg': 0.25,\n",
       "             'img_to_mol/RetrievalHitRate_top_01': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_01_avg': 0.25,\n",
       "             'avg/RetrievalHitRate_top_01': [],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_01_avg': 0.25,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_01_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_01_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_01_std': 0.0,\n",
       "             'mol_to_img/RetrievalHitRate_top_03': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_03_avg': 0.75,\n",
       "             'img_to_mol/RetrievalHitRate_top_03': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_03_avg': 0.75,\n",
       "             'avg/RetrievalHitRate_top_03': [],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_03_avg': 0.75,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_03_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_03_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_03_std': 0.0,\n",
       "             'mol_to_img/RetrievalHitRate_top_05': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_05_avg': 1.0,\n",
       "             'img_to_mol/RetrievalHitRate_top_05': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_05_avg': 1.0,\n",
       "             'avg/RetrievalHitRate_top_05': [],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_05_avg': 1.0,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_05_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_05_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_05_std': 0.0,\n",
       "             'mol_to_img/RetrievalHitRate_top_10': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_10_avg': 1.0,\n",
       "             'img_to_mol/RetrievalHitRate_top_10': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_10_avg': 1.0,\n",
       "             'avg/RetrievalHitRate_top_10': [],\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_10_avg': 1.0,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalHitRate_top_10_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalHitRate_top_10_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalHitRate_top_10_std': 0.0,\n",
       "             'mol_to_img/RetrievalMAP_top_01': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMAP_top_01_avg': 0.25,\n",
       "             'img_to_mol/RetrievalMAP_top_01': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMAP_top_01_avg': 0.25,\n",
       "             'avg/RetrievalMAP_top_01': [],\n",
       "             'retrieval/1:100/avg/RetrievalMAP_top_01_avg': 0.25,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMAP_top_01_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMAP_top_01_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalMAP_top_01_std': 0.0,\n",
       "             'mol_to_img/RetrievalMAP_top_05': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMAP_top_05_avg': 0.5208334,\n",
       "             'img_to_mol/RetrievalMAP_top_05': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMAP_top_05_avg': 0.5347222,\n",
       "             'avg/RetrievalMAP_top_05': [],\n",
       "             'retrieval/1:100/avg/RetrievalMAP_top_05_avg': 0.5277778,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMAP_top_05_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMAP_top_05_std': 0.01964185,\n",
       "             'retrieval/1:100/avg/RetrievalMAP_top_05_std': 0.009820919,\n",
       "             'mol_to_img/RetrievalMRR': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMRR_avg': 0.5208334,\n",
       "             'img_to_mol/RetrievalMRR': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMRR_avg': 0.5347222,\n",
       "             'avg/RetrievalMRR': [],\n",
       "             'retrieval/1:100/avg/RetrievalMRR_avg': 0.5277778,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalMRR_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalMRR_std': 0.01964185,\n",
       "             'retrieval/1:100/avg/RetrievalMRR_std': 0.009820919,\n",
       "             'mol_to_img/RetrievalNormalizedDCG': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalNormalizedDCG_avg': 0.6404016,\n",
       "             'img_to_mol/RetrievalNormalizedDCG': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalNormalizedDCG_avg': 0.6513124,\n",
       "             'avg/RetrievalNormalizedDCG': [],\n",
       "             'retrieval/1:100/avg/RetrievalNormalizedDCG_avg': 0.64585704,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalNormalizedDCG_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalNormalizedDCG_std': 0.015430214,\n",
       "             'retrieval/1:100/avg/RetrievalNormalizedDCG_std': 0.0077151214,\n",
       "             'mol_to_img/RetrievalPrecision_top_01': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_01_avg': 0.25,\n",
       "             'img_to_mol/RetrievalPrecision_top_01': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_01_avg': 0.25,\n",
       "             'avg/RetrievalPrecision_top_01': [],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_01_avg': 0.25,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_01_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_01_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_01_std': 0.0,\n",
       "             'mol_to_img/RetrievalPrecision_top_03': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_03_avg': 0.25,\n",
       "             'img_to_mol/RetrievalPrecision_top_03': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_03_avg': 0.25,\n",
       "             'avg/RetrievalPrecision_top_03': [],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_03_avg': 0.25,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_03_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_03_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_03_std': 0.0,\n",
       "             'mol_to_img/RetrievalPrecision_top_05': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_05_avg': 0.2,\n",
       "             'img_to_mol/RetrievalPrecision_top_05': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_05_avg': 0.2,\n",
       "             'avg/RetrievalPrecision_top_05': [],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_05_avg': 0.2,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_05_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_05_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_05_std': 0.0,\n",
       "             'mol_to_img/RetrievalPrecision_top_10': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_10_avg': 0.1,\n",
       "             'img_to_mol/RetrievalPrecision_top_10': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_10_avg': 0.1,\n",
       "             'avg/RetrievalPrecision_top_10': [],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_10_avg': 0.1,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_10_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_10_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_10_std': 0.0,\n",
       "             'mol_to_img/RetrievalPrecision_top_50': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_50_avg': 0.02,\n",
       "             'img_to_mol/RetrievalPrecision_top_50': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_50_avg': 0.02,\n",
       "             'avg/RetrievalPrecision_top_50': [],\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_50_avg': 0.02,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalPrecision_top_50_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalPrecision_top_50_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalPrecision_top_50_std': 0.0,\n",
       "             'mol_to_img/RetrievalRecall_top_01': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_01_avg': 0.25,\n",
       "             'img_to_mol/RetrievalRecall_top_01': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_01_avg': 0.25,\n",
       "             'avg/RetrievalRecall_top_01': [],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_01_avg': 0.25,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_01_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_01_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_01_std': 0.0,\n",
       "             'mol_to_img/RetrievalRecall_top_03': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_03_avg': 0.75,\n",
       "             'img_to_mol/RetrievalRecall_top_03': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_03_avg': 0.75,\n",
       "             'avg/RetrievalRecall_top_03': [],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_03_avg': 0.75,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_03_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_03_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_03_std': 0.0,\n",
       "             'mol_to_img/RetrievalRecall_top_05': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_05_avg': 1.0,\n",
       "             'img_to_mol/RetrievalRecall_top_05': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_05_avg': 1.0,\n",
       "             'avg/RetrievalRecall_top_05': [],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_05_avg': 1.0,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_05_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_05_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_05_std': 0.0,\n",
       "             'mol_to_img/RetrievalRecall_top_10': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_10_avg': 1.0,\n",
       "             'img_to_mol/RetrievalRecall_top_10': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_10_avg': 1.0,\n",
       "             'avg/RetrievalRecall_top_10': [],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_10_avg': 1.0,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_10_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_10_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_10_std': 0.0,\n",
       "             'mol_to_img/RetrievalRecall_top_50': [],\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_50_avg': 1.0,\n",
       "             'img_to_mol/RetrievalRecall_top_50': [],\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_50_avg': 1.0,\n",
       "             'avg/RetrievalRecall_top_50': [],\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_50_avg': 1.0,\n",
       "             'retrieval/1:100/mol_to_img/RetrievalRecall_top_50_std': 0.0,\n",
       "             'retrieval/1:100/img_to_mol/RetrievalRecall_top_50_std': 0.0,\n",
       "             'retrieval/1:100/avg/RetrievalRecall_top_50_std': 0.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_from_list_of_dict_to_list(res, key):\n",
    "    out = np.concatenate([r[key] for r in res])\n",
    "    if out.ndim == 2:\n",
    "        return out.tolist()\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "\n",
    "def concat_from_list_of_dict_to_tensor(res, key):\n",
    "    if isinstance(res[0][key], torch.Tensor):\n",
    "        out = torch.cat([r[key] for r in res], dim=0)\n",
    "    elif isinstance(res[0][key], (int, float)):\n",
    "        out = [r[key] for r in res]\n",
    "    else:\n",
    "        out = concat_from_list_of_dict_to_list(res, key)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataloader_idx': 0,\n",
       " 'batch_idx': 0,\n",
       " 'compound_str': ['InChI=1S/C10H10ClN3O2/c11-7-2-1-3-8(4-7)14-10(6-16)9(5-15)12-13-14/h1-4,15-16H,5-6H2',\n",
       "  'InChI=1S/C10H10ClN3O2S2/c11-9-1-2-10(17-9)18(15,16)14-4-3-7-8(5-14)13-6-12-7/h1-2,6H,3-5H2,(H,12,13)',\n",
       "  'InChI=1S/C10H10N2O3S2/c1-2-5-3-6-8(15)11-10(12-9(6)17-5)16-4-7(13)14/h3H,2,4H2,1H3,(H,13,14)(H,11,12,15)',\n",
       "  'InChI=1S/C10H10N4O2/c1-16-10(15)8-9(11)13-14(12-8)7-5-3-2-4-6-7/h2-6H,1H3,(H2,11,13)'],\n",
       " 'image_id': ['source_6__p210928CPU2OS48hw384exp030JUMP__110000296383__M17__9',\n",
       "  'source_10__2021_08_09_U2OS_48_hr_run13__Dest210727-153138__P06__1',\n",
       "  'source_8__J4__A1166164__M09__4',\n",
       "  'source_11__Batch5__EC000080__N08__4'],\n",
       " 'compound_emb': tensor([[ 0.0163,  0.0241,  0.0165,  ...,  0.0816,  0.0436, -0.0081],\n",
       "         [ 0.0281,  0.0094,  0.0201,  ...,  0.0373,  0.0158,  0.0103],\n",
       "         [-0.0392, -0.0008,  0.0729,  ...,  0.0593,  0.0104, -0.0258],\n",
       "         [ 0.0009,  0.0181,  0.0571,  ...,  0.0711,  0.0079, -0.0134]]),\n",
       " 'image_emb': tensor([[ 0.0863, -0.0318, -0.0167,  ...,  0.0291,  0.0392, -0.1172],\n",
       "         [ 0.0793, -0.0447, -0.0323,  ...,  0.0033,  0.0031, -0.0919],\n",
       "         [ 0.0911, -0.0296, -0.0203,  ...,  0.0418,  0.0156, -0.1114],\n",
       "         [ 0.1270, -0.0573, -0.0168,  ...,  0.0009,  0.0026, -0.0698]])}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = defaultdict(list)\n",
    "keys = predictions[0].keys()\n",
    "\n",
    "n = len(predictions)\n",
    "for i in range(0, n, 10):\n",
    "    batch_res = {k: concat_from_list_of_dict_to_tensor(predictions[i : i + 10], k) for k in keys}\n",
    "\n",
    "    image_emb = batch_res[\"image_emb\"]\n",
    "    compound_emb = batch_res[\"compound_emb\"]\n",
    "\n",
    "    dist = simple.distance_metric(image_emb, compound_emb)  # Similarity matrix between images and compounds: 100 x 100\n",
    "\n",
    "    indexes_mol_to_img = torch.arange(dist.shape[1]).expand(\n",
    "        dist.shape\n",
    "    )  # 100 x 100 matrix with the indexes of the compounds\n",
    "    indexes_img_to_mol = indexes_mol_to_img.transpose(0, 1)  # 100 x 100 matrix with the indexes of the images\n",
    "    target = torch.eye(dist.shape[1])  # Identity matrix: 100 x 100\n",
    "\n",
    "    res_mol_to_img = simple.retrieval_metrics(\n",
    "        preds=dist, target=target, indexes=indexes_mol_to_img\n",
    "    )  # Dictionary with the metrics for mol to img\n",
    "    res_img_to_mol = simple.retrieval_metrics(\n",
    "        preds=dist, target=target, indexes=indexes_img_to_mol\n",
    "    )  # Dictionary with the metrics for img to mol\n",
    "\n",
    "    for metric in simple.metric_keys:\n",
    "        result_dict[f\"retrieval/1:1000/mol_to_img/{metric}\"].append(res_mol_to_img[metric])\n",
    "        result_dict[f\"retrieval/1:1000/img_to_mol/{metric}\"].append(res_img_to_mol[metric])\n",
    "        result_dict[f\"retrieval/1:1000/avg/{metric}\"].append((res_mol_to_img[metric] + res_img_to_mol[metric]) / 2)\n",
    "\n",
    "for metric in simple.metric_keys:\n",
    "    result_dict[f\"retrieval/1:1000/mol_to_img/{metric}_avg\"] = np.mean(\n",
    "        result_dict[f\"retrieval/1:1000/mol_to_img/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:1000/img_to_mol/{metric}_avg\"] = np.mean(\n",
    "        result_dict[f\"retrieval/1:1000/img_to_mol/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:1000/avg/{metric}_avg\"] = np.mean(result_dict[f\"retrieval/1:1000/avg/{metric}\"])\n",
    "    result_dict[f\"retrieval/1:1000/mol_to_img/{metric}_std\"] = np.std(\n",
    "        result_dict[f\"retrieval/1:1000/mol_to_img/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:1000/img_to_mol/{metric}_std\"] = np.std(\n",
    "        result_dict[f\"retrieval/1:1000/img_to_mol/{metric}\"]\n",
    "    )\n",
    "    result_dict[f\"retrieval/1:1000/avg/{metric}_std\"] = np.std(result_dict[f\"retrieval/1:1000/avg/{metric}\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hint evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.eval.phaseI.datamodule.batch_size = 4\n",
    "cfg.eval.phaseI.trainer.devices = 1\n",
    "\n",
    "with open_dict(cfg.eval.phaseI.trainer):\n",
    "    cfg.eval.phaseI.trainer.limit_train_batches = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "hint = utils.instantiate_evaluator(cfg.eval.phaseI, cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hint.datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = hint.datamodule.train_dataloader()\n",
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = copy.deepcopy(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = b1[\"smiles_list\"]\n",
    "targets = b1[\"label\"]\n",
    "\n",
    "compound_embeddings = hint.model.forward_smiles_lst_lst(smiles_list)\n",
    "logits = hint.model.head(compound_embeddings)\n",
    "\n",
    "loss = hint.model.criterion(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1056,  0.0534],\n",
       "         [ 0.0530, -0.0058],\n",
       "         [ 0.0882, -0.0338],\n",
       "         [ 0.0678,  0.0005]], grad_fn=<AddmmBackward0>),\n",
       " tensor([0, 0, 0, 1]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OGB evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.eval.hiv.datamodule.batch_size = 4\n",
    "cfg.eval.hiv.trainer.devices = 1\n",
    "\n",
    "with open_dict(cfg.eval.hiv.trainer):\n",
    "    cfg.eval.hiv.trainer.limit_train_batches = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "tox = utils.instantiate_evaluator(cfg.eval.hiv, cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox.datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = tox.datamodule.train_dataloader()\n",
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 0, 0], dtype=torch.int32),\n",
       " tensor([[ 0.0538,  0.0796],\n",
       "         [-0.2209, -0.0526],\n",
       "         [-0.1225, -0.1160],\n",
       "         [ 0.0763, -0.0974]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7409, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]),\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.eval.esol.datamodule.batch_size = 4\n",
    "cfg.eval.esol.trainer.devices = 1\n",
    "\n",
    "with open_dict(cfg.eval.esol.trainer):\n",
    "    cfg.eval.esol.trainer.limit_train_batches = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "esol = utils.instantiate_evaluator(cfg.eval.esol, cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "esol.datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = esol.datamodule.train_dataloader()\n",
    "b = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = copy.deepcopy(b)\n",
    "\n",
    "compound = b1[\"compound\"]\n",
    "targets = b1[\"label\"]\n",
    "\n",
    "logits = esol.model.model(compound)\n",
    "\n",
    "loss = esol.model.criterion(logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.5233, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jump_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
