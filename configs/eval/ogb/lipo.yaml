defaults:
  - /model/optimizer/adamw.yaml@lipo.model.optimizer
  - /model/scheduler/cosine_annealing_with_warmup.yaml@lipo.model.scheduler
  - /trainer/gpu.yaml@lipo.trainer
  - /callbacks/eval/ogb.yaml@lipo.callbacks

lipo:
  model:
    _target_: src.eval.ogb.module.LipoModule

    lr: 1e-4

    scheduler:
      warmup_epochs: 3
      max_epochs: ${eval.lipo.trainer.max_epochs}

    example_input_path: ${model.example_input_path}

    split_lr_in_groups: False


  datamodule:
    _target_: src.eval.ogb.datamodule.LipoDataModule

    root_dir: ${paths.data_root_dir}/ogb/

    batch_size: 256
    num_workers: 16
    pin_memory: False
    prefetch_factor: 2

    compound_transform: ${data.compound_transform}

    split_type: scaffold

    smiles_col: smiles
    targets: null
    # collate_fn: null

    use_cache: False


  trainer:
    default_root_dir: ${paths.output_dir}/eval/ogb/lipo/
    devices: ${trainer.devices}
    min_epochs: 0
    max_epochs: 50
    log_every_n_steps: 1
    num_sanity_val_steps: 1
    check_val_every_n_epoch: 1

  evaluator:
    _target_: src.eval.evaluators.Evaluator
    name: LipoModule
    visualize_kwargs: null


  callbacks:
    early_stopping:
      monitor: ogb/lipo/val/loss

    model_checkpoint:
      monitor: ogb/lipo/val/loss
      dirpath: ${eval.lipo.trainer.default_root_dir}/checkpoints

    wandb_plotter:
      prefix: ogb/lipo
