defaults:
  - /model/optimizer/adam.yaml@lipo.model.optimizer
  - /model/scheduler/cosine_annealing_warm_restart.yaml@lipo.model.scheduler
  - /trainer/gpu.yaml@lipo.trainer
  - /callbacks/eval/ogb.yaml@lipo.callbacks

lipo:
  evaluator:
    _target_: src.eval.evaluators.Evaluator
    name: LipoModule
    visualize_kwargs: null


  callbacks:
    molecule_freezer:
      unfreeze_backbone_at_epoch: 11
      group_name: lipo_molecule_unfrozen

    early_stopping:
      monitor: ogb/lipo/image/val/loss

    model_checkpoint:
      monitor: ogb/lipo/image/val/loss
      dirpath: ${eval.lipo.trainer.default_root_dir}/checkpoints


  model:
    _target_: src.eval.ogb.module.LipoModule

    lr: 1e-2

    scheduler:
      T_0: 10
      T_mult: 5

    example_input_path: ${paths.data_root_dir}/jump/models/eval/test/example.pt


  datamodule:
    _target_: src.eval.ogb.datamodule.LipoDataModule

    root_dir: ${paths.data_root_dir}/ogb/

    batch_size: 256
    num_workers: 16
    pin_memory: False
    prefetch_factor: 2

    compound_transform: ${data.compound_transform}

    split_type: scaffold

    smiles_col: smiles
    targets: null
    # collate_fn: null

    use_cache: True


  trainer:
    default_root_dir: ${paths.output_dir}/eval/ogb/lipo/
    devices: ${trainer.devices}
    min_epochs: 0
    max_epochs: 100
    log_every_n_steps: 1
    gradient_clip_val: 0.5
    num_sanity_val_steps: 1
