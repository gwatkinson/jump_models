# @package _global_

# to execute this experiment run:
# python train.py experiment=jump_cl

defaults:
  - override /data: jump_cl.yaml
  - override /model: jump_cl.yaml
  - override /callbacks: default.yaml
  - override /trainer: gpu-16.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

tags: ["small_jump_cl", "jump", "simple_contrastive_training", "first_try", "pretrained_gin", "pretrained_resnet50"]

seed: 12345

compile: True

trainer:
  min_epochs: 20
  max_epochs: 50
  log_every_n_steps: 2
  gradient_clip_val: 0.5
  num_sanity_val_steps: 2

data:
  batch_size: 128
  split_path: ${paths.split_path}/small_jump_cl/

logger:
  wandb:
    tags: ${tags}
    group: "jump_models"
